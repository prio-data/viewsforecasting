{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e27b8652",
   "metadata": {},
   "source": [
    "# ViEWS 3 ensembles: future predictions\n",
    "\n",
    "ViEWS monthly updates, cm level Fatalities002 version\n",
    "\n",
    "This notebook produces future predictions for a set of models defined in the list of dictionaries ModelList, produced by the notebook pgm_constituentmodels in this repository.\n",
    "\n",
    "The notebook draws on the following .py script files in this repository:\n",
    "\n",
    "Ensembling.py\n",
    "\n",
    "FetchData.py\n",
    "\n",
    "It also requires the list of models included in the ensemble, in the following file:\n",
    "ModelDefinitions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf471b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3c1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "# sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Views 3\n",
    "from viewser.operations import fetch\n",
    "from viewser import Queryset, Column\n",
    "import views_runs\n",
    "from views_partitioning import data_partitioner, legacy\n",
    "from stepshift import views\n",
    "from views_runs import storage, ModelMetadata\n",
    "from views_runs.storage import store, retrieve, fetch_metadata\n",
    "from views_forecasts.extensions import *\n",
    "import views_mapper2\n",
    "from views_mapper2.mapper2 import Mapper2\n",
    "from views_mapper2 import color\n",
    "from views_mapper2.label_writer import vid2date\n",
    "from views_mapper2.dictionary_writer import standard_scale\n",
    "\n",
    "# Mapper\n",
    "import geopandas as gpd\n",
    "\n",
    "import sqlalchemy as sa\n",
    "#from ingester3.config import source_db_path\n",
    "\n",
    "# Other packages\n",
    "import pickle as pkl\n",
    "\n",
    "#Parallelization\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "# Packages from this repository, Tools folder\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../Tools')\n",
    "sys.path.append('../Intermediates')\n",
    "sys.path.append('../SystemUpdates')\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Predicting fatalities scripts\n",
    "from Ensembling import CalibratePredictions, RetrieveStoredPredictions, mean_sd_calibrated, gam_calibrated, fetch_df_pg_id_c_id, calibrate_pg_with_c\n",
    "\n",
    "from FetchData import FetchData, RetrieveFromList, ReturnQsList, index_check\n",
    "from ViewsEstimators import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ec2d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common parameters:\n",
    "\n",
    "dev_id = 'Fatalities002'\n",
    "run_id = dev_id \n",
    "EndOfHistory = 530\n",
    "prod_id = '2024_02_t01'\n",
    "level = 'pgm'\n",
    "WriteToOverleaf = False\n",
    "get_future = False\n",
    "\n",
    "username = os.getlogin()\n",
    "\n",
    "depvar = \"ln_ged_sb_dep\"\n",
    "\n",
    "steps = [*range(1, 36+1, 1)] # Which steps to train and predict for\n",
    "\n",
    "#steps = [1,2,3,4,5,6,7,8,9,10,11,12,15,18,21,24] # Which steps to train and predict for\n",
    "#fi_steps = [1,3,6,12,36] # Which steps to present feature importances for\n",
    "#steps = [1,12,24,36]\n",
    "fi_steps = [1,3,6,12,36]\n",
    "#steps = [1,6,36]\n",
    "#fi_steps = [1,6,36]\n",
    "\n",
    "# Specifying partitions\n",
    "\n",
    "calib_partitioner_dict = {\"train\":(121,408),\"predict\":(409,456)}\n",
    "test_partitioner_dict = {\"train\":(121,456),\"predict\":(457,504)}\n",
    "future_partitioner_dict = {\"train\":(121,504),\"predict\":(505,516)}\n",
    "calib_partitioner =  views_runs.DataPartitioner({\"calib\":calib_partitioner_dict})\n",
    "test_partitioner =  views_runs.DataPartitioner({\"test\":test_partitioner_dict})\n",
    "future_partitioner =  views_runs.DataPartitioner({\"future\":future_partitioner_dict})\n",
    "\n",
    "Mydropbox = f'/Users/{username}/Dropbox (ViEWS)/ViEWS/'\n",
    "localgitpath = f'/Users/{username}/views3/'\n",
    "notebookpath = os.getcwd()\n",
    "\n",
    "if WriteToOverleaf:\n",
    "    if EndOfHistory==508:\n",
    "        overleafpath = f'/Users/{username}/Dropbox (ViEWS)/Apps/Overleaf/ViEWS_Presentations_2021/Figures/Forecasts/Apr2022/'\n",
    "    if EndOfHistory==509:\n",
    "        overleafpath = f'/Users/{username}/Dropbox (ViEWS)/Apps/Overleaf/ViEWS_Presentations_2021/Figures/Forecasts/Apr2022/'\n",
    "    \n",
    "    print('Overleaf path set to',overleafpath)\n",
    "\n",
    "print('Dropbox path set to',Mydropbox)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6349154a",
   "metadata": {},
   "source": [
    "# Retrieve models and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9144d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ModelDefinitions import DefineEnsembleModels\n",
    "\n",
    "ModelList = DefineEnsembleModels(level)\n",
    "    \n",
    "i = 0\n",
    "for model in ModelList:\n",
    "    print(i, model['modelname'], model['data_train'])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70052d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gitname = 'EnsembleMetaData_pgm_' + dev_id + '.csv'\n",
    "#EnsembleMetaData = pd.read_csv(gitname)\n",
    "#ModelList = EnsembleMetaData.to_dict('records')\n",
    "#i = 0\n",
    "#for model in ModelList:\n",
    "#    print(i, model['modelname'])\n",
    "#    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c433cc7b",
   "metadata": {},
   "source": [
    "# Retrieve and calibrate predictions and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edabbed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the predictions for calibration and test partitions\n",
    "# The ModelList contains the predictions organized by model\n",
    "\n",
    "ModelList = RetrieveStoredPredictions(ModelList, steps, EndOfHistory, run_id, level, get_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eb1a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qslist = ReturnQsList(level)\n",
    "from FetchData import fetch_pgm_data_from_model_def\n",
    "\n",
    "Datasets=fetch_pgm_data_from_model_def(qslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bffe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from views_runs import Storage, StepshiftedModels\n",
    "from views_partitioning.data_partitioner import DataPartitioner\n",
    "from viewser import Queryset, Column\n",
    "from views_runs import operations\n",
    "from views_runs.run_result import RunResult\n",
    "\n",
    "\n",
    "RewritePredictions = True # Set this to True to rewrite predictions even if they exist\n",
    "force_retrain = True\n",
    "calibrate_const_models=True\n",
    "\n",
    "if calibrate_const_models:\n",
    "    cm_ensemble=ViewsMetadata().with_name('cm_genetic_ensemble_f'+str(EndOfHistory)).fetch()\n",
    "    calib_run_id=ViewsMetadata().get_run_id_from_name(run_id)\n",
    "    cm_predictions_future = pd.DataFrame.forecasts.read_store(run=calib_run_id, name='cm_genetic_ensemble_f'+str(EndOfHistory))\n",
    "    df_pg_id_c_id=fetch_df_pg_id_c_id()\n",
    "\n",
    "def RetrainAndPredict(modelname):\n",
    "    modelstore = storage.Storage()\n",
    "    # Predictions for true future\n",
    "    ct = datetime.now()\n",
    "    print('Future', ct)\n",
    "    modelstore = storage.Storage()\n",
    "    model['RunResult_future']  = RunResult.retrain_or_retrieve(\n",
    "            retrain            = force_retrain,\n",
    "            store              = modelstore,\n",
    "            partitioner        = DataPartitioner({\"test\":future_partitioner_dict}),\n",
    "            stepshifted_models = StepshiftedModels(model['algorithm'], steps, model['depvar']),\n",
    "            dataset            = RetrieveFromList(Datasets,model['data_train']),\n",
    "            queryset_name      = model['queryset'],\n",
    "            partition_name     = \"test\",\n",
    "            timespan_name      = \"train\",\n",
    "            storage_name       = model['modelname'] + '_future',\n",
    "            author_name        = \"JED\",\n",
    "    )       \n",
    "    predictions_future = model['RunResult_future'].run.future_point_predict(EndOfHistory,model['RunResult_future'].data)\n",
    "    return predictions_future\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "print('Computing predictions, production run ' + prod_id + ', development run ' + run_id)\n",
    "for model in ModelList[:]:\n",
    "\n",
    "    # Loop that checks whether (1) this a model trained outside the main system, \n",
    "    # (2) retrieves the prediction if it exists in prediction storage,\n",
    "    # (3) if not checks whether the trained model exists, retrains if not, \n",
    "    # Then calibrates the predictions and stores them if they have not been stored before for this run.\n",
    "    # To do: set the data_preprocessing to the function in the model dictionary\n",
    "    \n",
    "#    model['predstorename_ncal'] = level +  '_' + model['modelname'] + '_noncalibrated' + '_f' + str(EndOfHistory)\n",
    "    model['predstorename_ncal'] = level +  '_' + model['modelname'] + '_f' + str(EndOfHistory)\n",
    "    model['predstorename_cal'] = level +  '_' + model['modelname'] + '_calibrated' + '_f' + str(EndOfHistory)\n",
    "\n",
    "    print(i, model['modelname'])\n",
    "\n",
    "    ct = datetime.now()\n",
    "    print('Trying to retrieve non-calibrated predictions', ct)\n",
    "    if RewritePredictions:\n",
    "        print(model['predstorename_ncal'])\n",
    "        model['future_df_noncalibrated'] = RetrainAndPredict(model['modelname'])\n",
    "    else:\n",
    "        try:\n",
    "            model['future_df_noncalibrated'] = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstorename_ncal'])\n",
    "            print('Predictions for ', model['predstorename_ncal'], ', run', run_id, 'exist, retrieving from prediction storage')\n",
    "\n",
    "        except KeyError:\n",
    "            print(model['predstorename_ncal'], ', run', run_id, 'does not exist, predicting')\n",
    "            model['future_df_noncalibrated'] = RetrainAndPredict(model['predstorename_ncal'])\n",
    "\n",
    "    # Calibrating and storing   \n",
    "    # Storing non-calibrated\n",
    "        \n",
    "    model['future_df_noncalibrated'].forecasts.set_run(run_id)\n",
    "    model['future_df_noncalibrated'].forecasts.to_store(name=model['predstorename_ncal'], overwrite=True)   \n",
    "        \n",
    "    if calibrate_const_models:\n",
    "        print('Calibrating')\n",
    "        model['future_df_calibrated'] = model['future_df_noncalibrated'].copy()\n",
    "            \n",
    "        model['future_df_calibrated']['step_combined']=calibrate_pg_with_c(model['future_df_calibrated'],cm_predictions_future,'step_combined',df_pg_id_c_id=df_pg_id_c_id,log_feature=True,super_calibrate=False)    \n",
    "        # Storing calibrated\n",
    "        model['future_df_calibrated'].forecasts.set_run(run_id)\n",
    "        model['future_df_calibrated'].forecasts.to_store(name=model['predstorename_cal'], overwrite=True)   \n",
    "            \n",
    "    i = i + 1\n",
    "\n",
    "print('All done')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e78a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnsembleList = [] # Separate list of dictionaries for ensembles!\n",
    "\n",
    "Ensemble = {\n",
    "    'modelname':            'ensemble_cm_calib',\n",
    "    'algorithm':            [],\n",
    "    'depvar':               depvar,\n",
    "    'data_train':           [],\n",
    "    'Algorithm_text':       '',\n",
    "    'calibration_gams':     [],\n",
    "    'future_df_calibrated': [],\n",
    "}\n",
    "EnsembleList.append(Ensemble)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42948b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_ensemble=ViewsMetadata().with_name('cm_genetic_ensemble_f'+str(EndOfHistory)).fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cc1430",
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_run_id=ViewsMetadata().get_run_id_from_name(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5e4645",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_predictions_calib = pd.DataFrame.forecasts.read_store(run=calib_run_id, name='cm_ensemble_genetic_calib')\n",
    "cm_predictions_test = pd.DataFrame.forecasts.read_store(run=calib_run_id, name='cm_ensemble_genetic_test')\n",
    "cm_predictions_future = pd.DataFrame.forecasts.read_store(run=calib_run_id, name='cm_genetic_ensemble_f'+str(EndOfHistory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec1ad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_predictions_calib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd6ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stepcols=['step_pred_' + str(step) for step in steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56c18c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = len(ModelList)\n",
    "\n",
    "targetcalib=ModelList[0]['predictions_calib_df'][depvar]\n",
    "targettest=ModelList[0]['predictions_test_df'][depvar]\n",
    "\n",
    "valscalib=ModelList[0]['predictions_calib_df'][stepcols].values.copy()\n",
    "valstest=ModelList[0]['predictions_test_df'][stepcols].values.copy()\n",
    "valsfuture=ModelList[0]['future_df_noncalibrated'].values.copy()\n",
    "\n",
    "trimmed_calib=ModelList[0]['predictions_calib_df'][stepcols].copy()\n",
    "index_calib=trimmed_calib.index\n",
    "columns_calib=trimmed_calib.columns\n",
    "\n",
    "trimmed_test=ModelList[0]['predictions_test_df'][stepcols].copy()\n",
    "index_test=trimmed_test.index\n",
    "columns_test=trimmed_test.columns\n",
    "\n",
    "trimmed_future=ModelList[0]['future_df_noncalibrated'].copy()\n",
    "index_future=trimmed_future.index\n",
    "columns_future=trimmed_future.columns\n",
    "\n",
    "for model in ModelList[1:]:\n",
    "    print('adding',model['modelname'])\n",
    "\n",
    "    valscalib+=model['predictions_calib_df'][stepcols].values.copy()\n",
    "    valstest+=model['predictions_test_df'][stepcols].values.copy()\n",
    "    valsfuture+=model['future_df_noncalibrated'].values.copy()\n",
    "\n",
    "    valscalib/=n_models\n",
    "    valstest/=n_models\n",
    "    valsfuture/=n_models\n",
    "\n",
    "    Ensemble['predictions_calib_df']=pd.DataFrame(data=valscalib, index=index_calib, columns=columns_calib)\n",
    "    Ensemble['predictions_test_df']=pd.DataFrame(data=valstest, index=index_test, columns=columns_test)\n",
    "    Ensemble['predictions_future_df']=pd.DataFrame(data=valsfuture, index=index_future, columns=columns_future)\n",
    "    \n",
    "df_pg_id_c_id=fetch_df_pg_id_c_id()\n",
    "    \n",
    "for col in stepcols:\n",
    "\n",
    "    thisstep=int(''.join([''+str(f) for f in filter(str.isdigit, col)]))\n",
    "    thismonth = EndOfHistory + thisstep\n",
    "\n",
    "#    Ensemble['predictions_calib_df'][col]=calibrate_pg_with_c(Ensemble['predictions_calib_df'],cm_predictions_calib,col,df_pg_id_c_id=df_pg_id_c_id,log_feature=True,super_calibrate=False)\n",
    "\n",
    "#    Ensemble['predictions_test_df'][col]=calibrate_pg_with_c(Ensemble['predictions_test_df'],cm_predictions_test,col,df_pg_id_c_id=df_pg_id_c_id,log_feature=True,super_calibrate=False)\n",
    "    \n",
    "future_calib=calibrate_pg_with_c(Ensemble['predictions_future_df'],cm_predictions_future,'step_combined',df_pg_id_c_id=df_pg_id_c_id,log_feature=True,super_calibrate=False)    \n",
    "    \n",
    "Ensemble['predictions_future_df']['step_combined']=future_calib['step_combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4867f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble['predictions_calib_df'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f00851",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble['predictions_test_df'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc04c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble['predictions_future_df'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e583c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble['predictions_calib_df'][depvar]=targetcalib\n",
    "Ensemble['predictions_test_df'][depvar]=targettest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afb97c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetcalib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ccc4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ensemble predictions\n",
    "predstore_calib = level +  '_' + Ensemble['modelname'] + '_calib'\n",
    "Ensemble['predictions_calib_df'].forecasts.set_run(run_id)\n",
    "Ensemble['predictions_calib_df'].forecasts.to_store(name=predstore_calib, overwrite = True)\n",
    "predstore_test = level +  '_' + Ensemble['modelname'] + '_test'\n",
    "Ensemble['predictions_test_df'].forecasts.set_run(run_id)\n",
    "Ensemble['predictions_test_df'].forecasts.to_store(name=predstore_test, overwrite = True)\n",
    "predstore_future = level +  '_' + Ensemble['modelname'] + '_f'+str(EndOfHistory)\n",
    "Ensemble['predictions_future_df'].forecasts.set_run(run_id)\n",
    "Ensemble['predictions_future_df'].forecasts.to_store(name=predstore_future, overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5355ad4d",
   "metadata": {},
   "source": [
    "# Use ensemble predictions for test partition to create categorical predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48672578",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_df=Ensemble['predictions_test_df'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17be8760-152e-4c05-a98a-ddcaa964c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble['predictions_test_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64984aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble['predictions_calib_df'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b04634",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble['predictions_test_df'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbba3611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dichotomous version of dependent variable\n",
    "ensemble_test_df['ged_gte_1'] = ensemble_test_df['ln_ged_sb_dep'].apply(lambda x: 1 if x >= np.log1p(1) else 0)\n",
    "# Generate multiclass version for uncertainty estimation\n",
    "def ged_categorical(x):\n",
    "    if x < np.log1p(0.5):\n",
    "        return 0\n",
    "    elif x < np.log1p(10):\n",
    "        return 1\n",
    "    elif x < np.log1p(100):\n",
    "        return 2\n",
    "    elif x < np.log1p(1000):\n",
    "        return 3\n",
    "    else :\n",
    "        return 4\n",
    "\n",
    "ensemble_test_df['ged_multi'] = ensemble_test_df['ln_ged_sb_dep'].apply(ged_categorical)\n",
    "\n",
    "ensemble_test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7a17d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ensemble_test_df['ln_ged_sb_dep'],ensemble_test_df['ged_multi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e85509-4aaf-4106-909a-691e4ed34851",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in steps:\n",
    "    if ensemble_test_df[f'step_pred_{step}'].isnull().sum().sum() != 0:\n",
    "        print('****WARNING***** - detected',ensemble_test_df[f'step_pred_{step}'].isnull().sum().sum(),'Nan(s) in column step_pred_'+str(step))\n",
    "        print('Replacing with zeros')\n",
    "        ensemble_test_df[f'step_pred_{step}']=ensemble_test_df[f'step_pred_{step}'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d86f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model to transform predictions from  fatalities to (1) dichotomous and (2) multiclass\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "dichotomous_classifiers = []\n",
    "multi_classifiers = []\n",
    "for step in steps:\n",
    "    X = np.array(ensemble_test_df[f'step_pred_{step}'])\n",
    "    X = X.reshape(-1,1)\n",
    "    # Dichotomous\n",
    "    y_dich = np.array(ensemble_test_df['ged_gte_1']).reshape(-1, 1)\n",
    "    dich_clf = LogisticRegression(random_state=0).fit(X, y_dich)\n",
    "    dichotomous_classifiers.append(dich_clf)\n",
    "    p_dich = dich_clf.predict_proba(X)\n",
    "    ensemble_test_df['dich_step_{step}_logit'] = p_dich[:,1].ravel()\n",
    "    # Multiclass\n",
    "    y_multi = np.array(ensemble_test_df['ged_multi']).reshape(-1, 1)\n",
    "    multi_clf = LogisticRegression(random_state=0).fit(X, y_multi)\n",
    "    multi_classifiers.append(multi_clf)\n",
    "    p_multi = multi_clf.predict_proba(X)\n",
    "    for cls in [0,1,2,3,4]:\n",
    "        ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
    "\n",
    "ensemble_test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cb221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnsembleList[0]['future_df_dichotomous'] = EnsembleList[0]['predictions_future_df'].copy() # Copy from baseline\n",
    "\n",
    "for step in steps:\n",
    "    month = EndOfHistory + step\n",
    "#    weightcol = 'step_pred_' + str(step)\n",
    "#    weights = np.array(pd.DataFrame(i_weights_df[weightcol]))\n",
    "#    EnsembleList[0]['future_df_calibrated'].loc[month] = ConstituentModels_df_w.loc[month].dot(weights).values\n",
    "    x_d = np.array(EnsembleList[0]['predictions_future_df'].loc[month]).reshape(-1,1)\n",
    "    pred_step = dichotomous_classifiers[step-1].predict_proba(x_d)\n",
    "    EnsembleList[0]['future_df_dichotomous']['step_combined'].loc[month] = pred_step[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11082c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predstore_future_dich = level +  '_' + EnsembleList[0]['modelname'] + '_dich_f' + str(EndOfHistory)\n",
    "EnsembleList[0]['future_df_dichotomous'].forecasts.set_run(run_id)\n",
    "EnsembleList[0]['future_df_dichotomous'].forecasts.to_store(name=predstore_future_dich, overwrite = True) "
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e9667f5656e3a61c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
