{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4141fbca",
   "metadata": {},
   "source": [
    "\n",
    "# ViEWS 3 constituent models \n",
    "\n",
    "## ViEWS production system, pgm level\n",
    "\n",
    "\n",
    "This notebook trains a set of regression models for use in the monthly updated ViEWS predicting fatalities ensemble\n",
    "\n",
    "The notebook does the following: \n",
    "1. Retrieves data through querysets and stores in DataSets, a list of dictionaries\n",
    "2. Specifies the metadata of a number of models, stores in ModelList, a list of dictionaries\n",
    "3. Trains the models in ModelList, stores the trained objects in model storage and prediction storage\n",
    "4. Saves part of ModelList as csv and the rest as pickles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c9c55f",
   "metadata": {},
   "source": [
    "## Importing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c9b18d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:40:47.214696Z",
     "start_time": "2024-03-28T19:40:44.122384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  |:---------------------------------|:-----------------------------------------------------------------------------------------|\r\n",
      "  | RETRY_FREQUENCY                  | 5                                                                                        |\r\n",
      "  | LOG_LEVEL                        | INFO                                                                                     |\r\n",
      "  | HANDSHAKE_PATH                   |                                                                                          |\r\n",
      "  | REPO_URL                         | https://www.github.com/prio-data/viewser                                                 |\r\n",
      "  | LATEST_KNOWN_VERSION             | 0.0.0                                                                                    |\r\n",
      "  | NOTEBOOK_SERVER_IMAGE_REPOSITORY | prio-data/viewserspace                                                                   |\r\n",
      "  | NOTEBOOK_SERVER_IMAGE_REGISTRY   | viewsregistry.azurecr.io                                                                 |\r\n",
      "  | ERROR_DUMP_DIRECTORY             | /Users/sofia/.views/dumps                                                                |\r\n",
      "  | MODEL_OBJECT_SFTP_USER           | predictions                                                                              |\r\n",
      "  | MODEL_OBJECT_SFTP_PORT           | 22222                                                                                    |\r\n",
      "  | MODEL_OBJECT_SFTP_HOSTNAME       | hermes                                                                                   |\r\n",
      "  | MODEL_OBJECT_KEY_DB_HOSTNAME     | janus                                                                                    |\r\n",
      "  | MODEL_OBJECT_KEY_DB_DBNAME       | pred3_certs                                                                              |\r\n",
      "  | QUERYSET_MAX_RETRIES             | 500                                                                                      |\r\n",
      "  | QUERYSET_REMOTE_PATH             | querysets                                                                                |\r\n",
      "  | REMOTE_URL                       | https://viewser.viewsforecasting.org                                                     |\r\n",
      "  | MODEL_METADATA_DATABASE_HOSTNAME | gjoll.muspelheim.local                                                                   |\r\n",
      "  | MODEL_METADATA_DATABASE_NAME     | forecasts3                                                                               |\r\n",
      "  | MODEL_METADATA_DATABASE_SCHEMA   | forecasts                                                                                |\r\n",
      "  | MODEL_METADATA_DATABASE_TABLE    | model                                                                                    |\r\n",
      "  | AZURE_BLOB_STORAGE_ACCOUNT_KEY   | ilP95e+ci1mRVqFnqoKBRWzN8W99KWshw3YV9gup4MskVf4KiDZeFtcwtX9e5Ej0vsSF8DXOF+DBosTj8wgjwg== |\r\n",
      "  | AZURE_BLOB_STORAGE_ACCOUNT_NAME  | viewsblobs                                                                               |\r\n",
      "  ---------------------------------------------------------------------------------------------------------------------------------\r\n",
      "\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "! viewser config list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e2f7e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:40:47.251127Z",
     "start_time": "2024-03-28T19:40:47.218731Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f560a3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:40:53.734139Z",
     "start_time": "2024-03-28T19:40:47.252319Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.cbook as cbook\n",
    "# sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRFRegressor, XGBRFClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "\n",
    "# Views 3\n",
    "from viewser.operations import fetch\n",
    "import views_runs\n",
    "from views_partitioning import data_partitioner, legacy\n",
    "from stepshift import views\n",
    "from views_runs import storage\n",
    "from views_runs.storage import store, retrieve, fetch_metadata\n",
    "\n",
    "from views_forecasts.extensions import *\n",
    "\n",
    "# Other packages\n",
    "import pickle as pkl\n",
    "\n",
    "# Packages from Predicting Fatalies repository\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../Tools')\n",
    "sys.path.append('../Intermediates')\n",
    "from FetchData import FetchData, RetrieveFromList, document_queryset, ReturnQsList, document_ensemble,data_integrity_check\n",
    "from ViewsEstimators import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ced9d3",
   "metadata": {},
   "source": [
    "## Common parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cda79d03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:40:53.803274Z",
     "start_time": "2024-03-28T19:40:53.735686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Mydropbox to /Users/root/Dropbox (ViEWS)/ViEWS\n"
     ]
    }
   ],
   "source": [
    "# Common parameters:\n",
    "dev_id = 'Fatalities002'\n",
    "run_id = dev_id\n",
    "\n",
    "# Generating a new run if necessary\n",
    "\n",
    "#try:\n",
    "#    ViewsMetadata().new_run(name=run_id,description='pgm_level_fatalities',min_month=1,max_month=999)\n",
    "#except KeyError:\n",
    "#    if 'devel' not in run_id:\n",
    "#        warnings.warn('You are overwriting a production system')\n",
    "\n",
    "depvar=\"ln_ged_sb_dep\"\n",
    "\n",
    "RerunQuerysets = True\n",
    "        \n",
    "FutureStart = 518\n",
    "steps = [*range(1, 36+1, 1)] # Which steps to train and predict for\n",
    "fi_steps = [1,3,6,12,36] # Which steps to present feature importances for\n",
    "#steps = [1,3,6,12,36]\n",
    "#fi_steps = [1,3,6,12,36]\n",
    "\n",
    "# Specifying partitions\n",
    "calib_partitioner_dict = {\"train\":(121,408),\"predict\":(409,456)}\n",
    "test_partitioner_dict = {\"train\":(121,456),\"predict\":(457,504)}\n",
    "future_partitioner_dict = {\"train\":(121,504),\"predict\":(505,516)}\n",
    "calib_partitioner =  views_runs.DataPartitioner({\"calib\":calib_partitioner_dict})\n",
    "test_partitioner =  views_runs.DataPartitioner({\"test\":test_partitioner_dict})\n",
    "future_partitioner =  views_runs.DataPartitioner({\"future\":future_partitioner_dict})\n",
    "\n",
    "Mydropbox = f'/Users/{os.getlogin()}/Dropbox (ViEWS)/ViEWS'\n",
    "print('Setting Mydropbox to',Mydropbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237b6488",
   "metadata": {},
   "source": [
    "## Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7884d73b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:40:54.122672Z",
     "start_time": "2024-03-28T19:40:53.807505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  fatalities002_pgm_baseline\n",
      "Model:  fatalities002_pgm_conflictlong\n",
      "Model:  fatalities002_pgm_escwa_drought\n",
      "Model:  fatalities002_pgm_natsoc\n",
      "Model:  fatalities002_pgm_broad\n",
      "Model:  fatalities002_pgm_conflict_history\n",
      "Model:  fatalities002_pgm_conflict_treelag\n",
      "Model:  fatalities002_pgm_conflict_sptime_dist\n"
     ]
    }
   ],
   "source": [
    "# Create Markdown documentation of all querysets used\n",
    "level = 'pgm'\n",
    "qslist = ReturnQsList(level)\n",
    "document_queryset(qslist,dev_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bf4e211",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:40:54.178624Z",
     "start_time": "2024-03-28T19:40:54.123930Z"
    }
   },
   "outputs": [],
   "source": [
    "#if RerunQuerysets:\n",
    "#    import pgm_querysets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "145fb2dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T20:25:16.255587Z",
     "start_time": "2024-03-28T19:40:54.180345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32: \"Queryset fatalities002_pgm_conflict_treelag *transform in progress* - 2 of 31 jobs remaining\"        \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297M/297M [00:41<00:00, 7.12MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_pgm_conflict_treelag read successfully                                      \n",
      "conflicttreelag: A dataset with 8 columns, with data between t = 1 and 852; 13110 units.\n",
      "112: \"Queryset fatalities002_pgm_broad *transform in progress* - 4 of 105 jobs remaining\"       \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316M/316M [00:44<00:00, 7.07MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_pgm_broad read successfully                                        \n",
      "broad: A dataset with 23 columns, with data between t = 1 and 852; 13110 units.\n",
      "88: \"Queryset fatalities002_pgm_conflict_sptime_dist *transform in progress* - 6 of 43 jobs remaining\"       \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109M/109M [00:09<00:00, 11.1MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_pgm_conflict_sptime_dist read successfully                                      \n",
      "conflictsptime_dist: A dataset with 11 columns, with data between t = 1 and 852; 13110 units.\n",
      "15: \"Queryset fatalities002_pgm_conflictlong *transform in progress* - 2 of 121 jobs remaining\"       \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112M/112M [00:10<00:00, 10.7MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_pgm_conflictlong read successfully                                       \n",
      "conflictlong: A dataset with 19 columns, with data between t = 1 and 852; 13110 units.\n",
      "61: \"Queryset fatalities002_pgm_conflict_history *transform in progress* - 6 of 169 jobs remaining\"        \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.3M/26.3M [00:02<00:00, 10.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_pgm_conflict_history read successfully                                       \n",
      "conflicthist: A dataset with 30 columns, with data between t = 1 and 852; 13110 units.\n",
      "8: \"Queryset fatalities002_pgm_baseline *transform in progress* - 4 of 50 jobs remaining\"        \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106M/106M [00:09<00:00, 10.8MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_pgm_baseline read successfully                                     \n",
      "baseline: A dataset with 8 columns, with data between t = 1 and 852; 13110 units.\n",
      "46: \"Queryset fatalities002_pgm_natsoc *transform in progress* - 3 of 119 jobs remaining\"        \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231M/231M [00:27<00:00, 8.45MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_pgm_natsoc read successfully                                       \n",
      "natsoc: A dataset with 24 columns, with data between t = 1 and 852; 13110 units.\n",
      "59: \"Queryset fatalities002_pgm_escwa_drought *transform in progress* - 8 of 106 jobs remaining\"        \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264M/264M [00:25<00:00, 10.2MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_pgm_escwa_drought read successfully                                       \n",
      "escwa_drought: A dataset with 29 columns, with data between t = 1 and 852; 13110 units.\n"
     ]
    }
   ],
   "source": [
    "from FetchData import fetch_pgm_data_from_model_def\n",
    "\n",
    "Datasets=fetch_pgm_data_from_model_def(qslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5faa811",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T20:25:46.494199Z",
     "start_time": "2024-03-28T20:25:16.268157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reordering columns in model conflicttreelag\n",
      "Reordering columns in model broad\n",
      "Reordering columns in model conflictsptime_dist\n",
      "Reordering columns in model escwa_drought\n"
     ]
    }
   ],
   "source": [
    "for ds in Datasets:\n",
    "\n",
    "    data_integrity_check(ds,depvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902a558c",
   "metadata": {},
   "source": [
    "# Generating predictions\n",
    "Using the ViEWS3 partitioning/stepshifting syntax. Training models for A: calibration partition and B: test partition, to test out some calibration routines. Most models trained with ln_ged_sb_best as outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63851566",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T20:25:46.678417Z",
     "start_time": "2024-03-28T20:25:46.504229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Fatalities002'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0912abb1",
   "metadata": {},
   "source": [
    "# Specify models in ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9ae391d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T20:25:46.827284Z",
     "start_time": "2024-03-28T20:25:46.687355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fatalities002_pgm_baseline_lgbm baseline\n",
      "1 fatalities002_pgm_conflictlong_lgbm conflictlong\n",
      "2 fatalities002_pgm_conflictlong_hurdle_lgbm conflictlong\n",
      "3 fatalities002_pgm_escwa_drought_hurdle_lgbm escwa_drought\n",
      "4 fatalities002_pgm_escwa_drought_lgbm escwa_drought\n",
      "5 fatalities002_pgm_natsoc_hurdle_lgbm natsoc\n",
      "6 fatalities002_pgm_natsoc_lgbm natsoc\n",
      "7 fatalities002_pgm_broad_hurdle_lgbm broad\n",
      "8 fatalities002_pgm_broad_lgbm broad\n",
      "9 fatalities002_pgm_conflict_history_xgb conflicthist\n",
      "10 fatalities002_pgm_conflict_treelag_hurdle conflicttreelag\n",
      "11 fatalities002_pgm_conflict_sptime_dist_hurdle conflictsptime_dist\n"
     ]
    }
   ],
   "source": [
    "from ModelDefinitions import DefineEnsembleModels\n",
    "\n",
    "ModelList = DefineEnsembleModels('pgm')\n",
    "    \n",
    "\n",
    "for imodel,model in enumerate(ModelList):\n",
    "    print(imodel, model['modelname'], model['data_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ece718b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T20:25:47.064086Z",
     "start_time": "2024-03-28T20:25:46.830938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fatalities002_pgm_baseline_lgbm baseline\n",
      "1 fatalities002_pgm_conflictlong_lgbm conflictlong\n",
      "2 fatalities002_pgm_conflictlong_hurdle_lgbm conflictlong\n",
      "3 fatalities002_pgm_escwa_drought_hurdle_lgbm escwa_drought\n",
      "4 fatalities002_pgm_escwa_drought_lgbm escwa_drought\n",
      "5 fatalities002_pgm_natsoc_hurdle_lgbm natsoc\n",
      "6 fatalities002_pgm_natsoc_lgbm natsoc\n",
      "7 fatalities002_pgm_broad_hurdle_lgbm broad\n",
      "8 fatalities002_pgm_broad_lgbm broad\n",
      "9 fatalities002_pgm_conflict_history_xgb conflicthist\n",
      "10 fatalities002_pgm_conflict_treelag_hurdle conflicttreelag\n",
      "11 fatalities002_pgm_conflict_sptime_dist_hurdle conflictsptime_dist\n"
     ]
    }
   ],
   "source": [
    "document_ensemble(ModelList,'sb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e73418bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T21:34:55.622696Z",
     "start_time": "2024-03-28T20:25:47.065727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fatalities002_pgm_conflict_treelag_hurdle\n",
      "Calibration partition 2024-03-28 21:25:47.241331\n",
      " * == Performing a run: \"fatalities002_pgm_conflict_treelag_hurdle_calib\" == * \n",
      "Model object named \"fatalities002_pgm_conflict_treelag_hurdle_calib\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_pgm_conflict_treelag_hurdle_calib\"\n",
      "Training model(s)...\n",
      "Storing \"fatalities002_pgm_conflict_treelag_hurdle_calib\"\n",
      "pgm_fatalities002_pgm_conflict_treelag_hurdle_calib , run Fatalities002 force_rewrite=True, predicting\n",
      "Test partition 2024-03-28 21:41:15.595800\n",
      " * == Performing a run: \"fatalities002_pgm_conflict_treelag_hurdle_test\" == * \n",
      "Model object named \"fatalities002_pgm_conflict_treelag_hurdle_test\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_pgm_conflict_treelag_hurdle_test\"\n",
      "Training model(s)...\n",
      "Storing \"fatalities002_pgm_conflict_treelag_hurdle_test\"\n",
      "pgm_fatalities002_pgm_conflict_treelag_hurdle_test , run Fatalities002 force_rewrite=True, predicting\n",
      "1 fatalities002_pgm_conflict_sptime_dist_hurdle\n",
      "Calibration partition 2024-03-28 21:59:11.193288\n",
      " * == Performing a run: \"fatalities002_pgm_conflict_sptime_dist_hurdle_calib\" == * \n",
      "Model object named \"fatalities002_pgm_conflict_sptime_dist_hurdle_calib\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_pgm_conflict_sptime_dist_hurdle_calib\"\n",
      "Training model(s)...\n",
      "Storing \"fatalities002_pgm_conflict_sptime_dist_hurdle_calib\"\n",
      "pgm_fatalities002_pgm_conflict_sptime_dist_hurdle_calib , run Fatalities002 force_rewrite=True, predicting\n",
      "Test partition 2024-03-28 22:15:31.777408\n",
      " * == Performing a run: \"fatalities002_pgm_conflict_sptime_dist_hurdle_test\" == * \n",
      "Model object named \"fatalities002_pgm_conflict_sptime_dist_hurdle_test\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_pgm_conflict_sptime_dist_hurdle_test\"\n",
      "Training model(s)...\n",
      "Storing \"fatalities002_pgm_conflict_sptime_dist_hurdle_test\"\n",
      "pgm_fatalities002_pgm_conflict_sptime_dist_hurdle_test , run Fatalities002 force_rewrite=True, predicting\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "# Loop that checks whether the model exists, retrains if not, \n",
    "# and stores the predictions if they have not been stored before for this run.\n",
    "# To do: set the data_preprocessing to the function in the model dictionary\n",
    "\n",
    "level = 'pgm'\n",
    "includeFuture = False\n",
    "force_rewrite = True\n",
    "force_retrain = True\n",
    "store_remote = False\n",
    "\n",
    "from views_runs import Storage, StepshiftedModels\n",
    "from views_partitioning.data_partitioner import DataPartitioner\n",
    "from viewser import Queryset, Column\n",
    "from views_runs import operations\n",
    "from views_runs.run_result import RunResult\n",
    "\n",
    "i = 0\n",
    "for model in ModelList[10:]:\n",
    "    modelstore = storage.Storage()\n",
    "    ct = datetime.now()\n",
    "    print(i, model['modelname'])\n",
    "    print('Calibration partition', ct)\n",
    "    model['Algorithm_text'] = str(model['algorithm'])\n",
    "    model['RunResult_calib'] = RunResult.retrain_or_retrieve(\n",
    "            retrain            = force_retrain,\n",
    "            store              = modelstore,\n",
    "            partitioner        = DataPartitioner({\"calib\":calib_partitioner_dict}),\n",
    "            stepshifted_models = StepshiftedModels(model['algorithm'], steps, model['depvar']),\n",
    "            dataset            = RetrieveFromList(Datasets,model['data_train']),\n",
    "            queryset_name      = model['queryset'],\n",
    "            partition_name     = \"calib\",\n",
    "            timespan_name      = \"train\",\n",
    "            storage_name       = model['modelname'] + '_calib',\n",
    "            author_name        = \"JED\",\n",
    "    )\n",
    "\n",
    "    model['predstore_calib'] = level +  '_' + model['modelname'] + '_calib'\n",
    "    ct = datetime.now()\n",
    "    if force_rewrite:\n",
    "        print(model['predstore_calib'], ', run',  run_id, 'force_rewrite=True, predicting')\n",
    "        predictions_calib = model['RunResult_calib'].run.predict(\"calib\",\"predict\", model['RunResult_calib'].data)\n",
    "\n",
    "        predictions_calib.to_parquet(model['predstore_calib']+'.parquet')\n",
    "        if store_remote:\n",
    "            predictions_calib.forecasts.set_run(run_id)\n",
    "            predictions_calib.forecasts.to_store(name=model['predstore_calib'],overwrite=True)\n",
    "    else:\n",
    "        print('Trying to retrieve predictions', ct)\n",
    "        try:\n",
    "            predictions_calib = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstore_calib'])\n",
    "        except KeyError:\n",
    "            print(model['predstore_calib'], ', run',  run_id, 'does not exist, predicting')\n",
    "            predictions_calib = model['RunResult_calib'].run.predict(\"calib\",\"predict\", model['RunResult_calib'].data)\n",
    "            predictions_calib.forecasts.set_run(run_id)\n",
    "            predictions_calib.forecasts.to_store(name=model['predstore_calib'])\n",
    "                \n",
    "    ct = datetime.now()\n",
    "    print('Test partition', ct)\n",
    "    modelstore = storage.Storage()\n",
    "    model['RunResult_test'] = RunResult.retrain_or_retrieve(\n",
    "            retrain            = force_retrain,\n",
    "            store              = modelstore,\n",
    "            partitioner        = DataPartitioner({\"test\":test_partitioner_dict}),\n",
    "            stepshifted_models = StepshiftedModels(model['algorithm'], steps, model['depvar']),\n",
    "            dataset            = RetrieveFromList(Datasets,model['data_train']),\n",
    "            queryset_name      = model['queryset'],\n",
    "            partition_name     = \"test\",\n",
    "            timespan_name      = \"train\",\n",
    "            storage_name       = model['modelname'] + '_test',\n",
    "            author_name        = \"JED\",\n",
    "    )\n",
    "    ct = datetime.now()\n",
    "    if force_rewrite:\n",
    "        print(model['predstore_test'], ', run',  run_id, 'force_rewrite=True, predicting')\n",
    "        predictions_test = model['RunResult_test'].run.predict(\"test\",\"predict\", model['RunResult_test'].data)\n",
    "        \n",
    "        predictions_test.to_parquet(model['predstore_test']+'.parquet')\n",
    "        if store_remote:\n",
    "            predictions_test.forecasts.set_run(run_id)\n",
    "            predictions_test.forecasts.to_store(name=model['predstore_test'],overwrite=True)\n",
    "    else:\n",
    "        print('Trying to retrieve predictions', ct)\n",
    "    #    model['predstore_test'] = level +  '_' + model['modelname'] + '_test'\n",
    "        try:\n",
    "            predictions_test = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstore_test'])\n",
    "        except KeyError:\n",
    "            print(model['predstore_test'], ', run', run_id, 'does not exist, predicting')\n",
    "            predictions_test = model['RunResult_test'].run.predict(\"test\",\"predict\",model['RunResult_test'].data)\n",
    "            predictions_test.forecasts.set_run(run_id)\n",
    "            predictions_test.forecasts.to_store(name=model['predstore_test'])\n",
    "    # Predictions for true future\n",
    "    if includeFuture:\n",
    "        ct = datetime.now()\n",
    "        print('Future', ct)\n",
    "        modelstore = storage.Storage()\n",
    "        model['RunResult_future'] = RunResult.retrain_or_retrieve(\n",
    "                retrain            = force_retrain,\n",
    "                store              = modelstore,\n",
    "                partitioner        = DataPartitioner({\"test\":future_partitioner_dict}),\n",
    "                stepshifted_models = StepshiftedModels(model['algorithm'], steps, model['depvar']),\n",
    "                dataset            = RetrieveFromList(Datasets,model['data_train']),\n",
    "                queryset_name      = model['queryset'],\n",
    "                partition_name     = \"test\",\n",
    "                timespan_name      = \"train\",\n",
    "                storage_name       = model['modelname'] + '_future',\n",
    "                author_name        = \"JED\",\n",
    "        )\n",
    "        ct = datetime.now()\n",
    "        if force_rewrite:\n",
    "            print(model['predstore_future'], ', run',  run_id, 'force_rewrite=True, predicting')\n",
    "            predictions_future = model['RunResult_future'].run.predict(FutureStart, model['RunResult_future'].data)\n",
    "            predictions_future.to_parquet(model['predstore_future']+'.parquet')\n",
    "\n",
    "            if store_remote:\n",
    "                predictions_future.forecasts.set_run(run_id)\n",
    "                predictions_future.forecasts.to_store(name=model['predstore_future'],overwrite=True)\n",
    "        else:\n",
    "            print('Trying to retrieve predictions', ct)\n",
    "            model['predstore_future'] = level +  '_' + model['modelname'] + '_f' + str(FutureStart)\n",
    "            try:\n",
    "                predictions_future = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstore_future'])\n",
    "            except KeyError:\n",
    "                print(model['predstore_future'], ', run', run_id, 'does not exist, predicting')\n",
    "                predictions_future = model['RunResult_future'].run.future_point_predict(FutureStart,model['RunResult_future'].data)\n",
    "                predictions_future.forecasts.set_run(run_id)\n",
    "                predictions_future.forecasts.to_store(name=model['predstore_future'])  \n",
    "#    model['algorithm'] = []\n",
    "    i = i + 1\n",
    "\n",
    "print('All done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0550b8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T21:34:56.058457Z",
     "start_time": "2024-03-28T21:34:55.625089Z"
    }
   },
   "outputs": [],
   "source": [
    "ModelMetaData = pd.DataFrame(ModelList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51906edf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T21:34:56.149302Z",
     "start_time": "2024-03-28T21:34:56.066775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                        modelname  \\\n0                 fatalities002_pgm_baseline_lgbm   \n1             fatalities002_pgm_conflictlong_lgbm   \n2      fatalities002_pgm_conflictlong_hurdle_lgbm   \n3     fatalities002_pgm_escwa_drought_hurdle_lgbm   \n4            fatalities002_pgm_escwa_drought_lgbm   \n5            fatalities002_pgm_natsoc_hurdle_lgbm   \n6                   fatalities002_pgm_natsoc_lgbm   \n7             fatalities002_pgm_broad_hurdle_lgbm   \n8                    fatalities002_pgm_broad_lgbm   \n9          fatalities002_pgm_conflict_history_xgb   \n10      fatalities002_pgm_conflict_treelag_hurdle   \n11  fatalities002_pgm_conflict_sptime_dist_hurdle   \n\n                                            algorithm         depvar  \\\n0                     LGBMRegressor(n_estimators=200)  ln_ged_sb_dep   \n1                     LGBMRegressor(n_estimators=200)  ln_ged_sb_dep   \n2   HurdleRegression(clf_name='LGBMClassifier', cl...  ln_ged_sb_dep   \n3   HurdleRegression(clf_name='LGBMClassifier', cl...  ln_ged_sb_dep   \n4                     LGBMRegressor(n_estimators=200)  ln_ged_sb_dep   \n5   HurdleRegression(clf_name='LGBMClassifier', cl...  ln_ged_sb_dep   \n6                     LGBMRegressor(n_estimators=200)  ln_ged_sb_dep   \n7   HurdleRegression(clf_name='LGBMClassifier', cl...  ln_ged_sb_dep   \n8                     LGBMRegressor(n_estimators=200)  ln_ged_sb_dep   \n9   XGBRegressor(base_score=None, booster=None, ca...  ln_ged_sb_dep   \n10  HurdleRegression(clf_name='XGBClassifier',\\n  ...  ln_ged_sb_dep   \n11  HurdleRegression(clf_name='XGBClassifier',\\n  ...  ln_ged_sb_dep   \n\n                                  queryset           data_train level  \\\n0               fatalities002_pgm_baseline             baseline   pgm   \n1           fatalities002_pgm_conflictlong         conflictlong   pgm   \n2           fatalities002_pgm_conflictlong         conflictlong   pgm   \n3          fatalities002_pgm_escwa_drought        escwa_drought   pgm   \n4          fatalities002_pgm_escwa_drought        escwa_drought   pgm   \n5                 fatalities002_pgm_natsoc               natsoc   pgm   \n6                 fatalities002_pgm_natsoc               natsoc   pgm   \n7                  fatalities002_pgm_broad                broad   pgm   \n8                  fatalities002_pgm_broad                broad   pgm   \n9       fatalities002_pgm_conflict_history         conflicthist   pgm   \n10      fatalities002_pgm_conflict_treelag      conflicttreelag   pgm   \n11  fatalities002_pgm_conflict_sptime_dist  conflictsptime_dist   pgm   \n\n   preprocessing description long_description  \\\n0       float_it                                \n1       float_it                                \n2       float_it                                \n3       float_it                                \n4       float_it                                \n5       float_it                                \n6       float_it                                \n7       float_it                                \n8       float_it                                \n9       float_it                                \n10      float_it                                \n11      float_it                                \n\n                                      predstore_calib  \\\n0           pgm_fatalities002_pgm_baseline_lgbm_calib   \n1       pgm_fatalities002_pgm_conflictlong_lgbm_calib   \n2   pgm_fatalities002_pgm_conflictlong_hurdle_lgbm...   \n3   pgm_fatalities002_pgm_escwa_drought_hurdle_lgb...   \n4      pgm_fatalities002_pgm_escwa_drought_lgbm_calib   \n5      pgm_fatalities002_pgm_natsoc_hurdle_lgbm_calib   \n6             pgm_fatalities002_pgm_natsoc_lgbm_calib   \n7       pgm_fatalities002_pgm_broad_hurdle_lgbm_calib   \n8              pgm_fatalities002_pgm_broad_lgbm_calib   \n9    pgm_fatalities002_pgm_conflict_history_xgb_calib   \n10  pgm_fatalities002_pgm_conflict_treelag_hurdle_...   \n11  pgm_fatalities002_pgm_conflict_sptime_dist_hur...   \n\n                                       predstore_test  \\\n0            pgm_fatalities002_pgm_baseline_lgbm_test   \n1        pgm_fatalities002_pgm_conflictlong_lgbm_test   \n2   pgm_fatalities002_pgm_conflictlong_hurdle_lgbm...   \n3   pgm_fatalities002_pgm_escwa_drought_hurdle_lgb...   \n4       pgm_fatalities002_pgm_escwa_drought_lgbm_test   \n5       pgm_fatalities002_pgm_natsoc_hurdle_lgbm_test   \n6              pgm_fatalities002_pgm_natsoc_lgbm_test   \n7        pgm_fatalities002_pgm_broad_hurdle_lgbm_test   \n8               pgm_fatalities002_pgm_broad_lgbm_test   \n9     pgm_fatalities002_pgm_conflict_history_xgb_test   \n10  pgm_fatalities002_pgm_conflict_treelag_hurdle_...   \n11  pgm_fatalities002_pgm_conflict_sptime_dist_hur...   \n\n                                       Algorithm_text  \\\n0                                                 NaN   \n1                                                 NaN   \n2                                                 NaN   \n3                                                 NaN   \n4                                                 NaN   \n5                                                 NaN   \n6                                                 NaN   \n7                                                 NaN   \n8                                                 NaN   \n9                                                 NaN   \n10  HurdleRegression(clf_name='XGBClassifier',\\n  ...   \n11  HurdleRegression(clf_name='XGBClassifier',\\n  ...   \n\n                          RunResult_calib  \\\n0                                     NaN   \n1                                     NaN   \n2                                     NaN   \n3                                     NaN   \n4                                     NaN   \n5                                     NaN   \n6                                     NaN   \n7                                     NaN   \n8                                     NaN   \n9                                     NaN   \n10  RunResult(training_date = 2023-03-30)   \n11  RunResult(training_date = 2023-02-16)   \n\n                           RunResult_test  \n0                                     NaN  \n1                                     NaN  \n2                                     NaN  \n3                                     NaN  \n4                                     NaN  \n5                                     NaN  \n6                                     NaN  \n7                                     NaN  \n8                                     NaN  \n9                                     NaN  \n10  RunResult(training_date = 2023-03-30)  \n11  RunResult(training_date = 2023-02-17)  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>modelname</th>\n      <th>algorithm</th>\n      <th>depvar</th>\n      <th>queryset</th>\n      <th>data_train</th>\n      <th>level</th>\n      <th>preprocessing</th>\n      <th>description</th>\n      <th>long_description</th>\n      <th>predstore_calib</th>\n      <th>predstore_test</th>\n      <th>Algorithm_text</th>\n      <th>RunResult_calib</th>\n      <th>RunResult_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fatalities002_pgm_baseline_lgbm</td>\n      <td>LGBMRegressor(n_estimators=200)</td>\n      <td>ln_ged_sb_dep</td>\n      <td>fatalities002_pgm_baseline</td>\n      <td>baseline</td>\n      <td>pgm</td>\n      <td>float_it</td>\n      <td></td>\n      <td></td>\n      <td>pgm_fatalities002_pgm_baseline_lgbm_calib</td>\n      <td>pgm_fatalities002_pgm_baseline_lgbm_test</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fatalities002_pgm_conflictlong_lgbm</td>\n      <td>LGBMRegressor(n_estimators=200)</td>\n      <td>ln_ged_sb_dep</td>\n      <td>fatalities002_pgm_conflictlong</td>\n      <td>conflictlong</td>\n      <td>pgm</td>\n      <td>float_it</td>\n      <td></td>\n      <td></td>\n      <td>pgm_fatalities002_pgm_conflictlong_lgbm_calib</td>\n      <td>pgm_fatalities002_pgm_conflictlong_lgbm_test</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>fatalities002_pgm_conflictlong_hurdle_lgbm</td>\n      <td>HurdleRegression(clf_name='LGBMClassifier', cl...</td>\n      <td>ln_ged_sb_dep</td>\n      <td>fatalities002_pgm_conflictlong</td>\n      <td>conflictlong</td>\n      <td>pgm</td>\n      <td>float_it</td>\n      <td></td>\n      <td></td>\n      <td>pgm_fatalities002_pgm_conflictlong_hurdle_lgbm...</td>\n      <td>pgm_fatalities002_pgm_conflictlong_hurdle_lgbm...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>fatalities002_pgm_escwa_drought_hurdle_lgbm</td>\n      <td>HurdleRegression(clf_name='LGBMClassifier', cl...</td>\n      <td>ln_ged_sb_dep</td>\n      <td>fatalities002_pgm_escwa_drought</td>\n      <td>escwa_drought</td>\n      <td>pgm</td>\n      <td>float_it</td>\n      <td></td>\n      <td></td>\n      <td>pgm_fatalities002_pgm_escwa_drought_hurdle_lgb...</td>\n      <td>pgm_fatalities002_pgm_escwa_drought_hurdle_lgb...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>fatalities002_pgm_escwa_drought_lgbm</td>\n      <td>LGBMRegressor(n_estimators=200)</td>\n      <td>ln_ged_sb_dep</td>\n      <td>fatalities002_pgm_escwa_drought</td>\n      <td>escwa_drought</td>\n      <td>pgm</td>\n      <td>float_it</td>\n      <td></td>\n      <td></td>\n      <td>pgm_fatalities002_pgm_escwa_drought_lgbm_calib</td>\n      <td>pgm_fatalities002_pgm_escwa_drought_lgbm_test</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>fatalities002_pgm_natsoc_hurdle_lgbm</td>\n      <td>HurdleRegression(clf_name='LGBMClassifier', cl...</td>\n      <td>ln_ged_sb_dep</td>\n      <td>fatalities002_pgm_natsoc</td>\n      <td>natsoc</td>\n      <td>pgm</td>\n      <td>float_it</td>\n      <td></td>\n      <td></td>\n      <td>pgm_fatalities002_pgm_natsoc_hurdle_lgbm_calib</td>\n      <td>pgm_fatalities002_pgm_natsoc_hurdle_lgbm_test</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>fatalities002_pgm_natsoc_lgbm</td>\n      <td>LGBMRegressor(n_estimators=200)</td>\n      <td>ln_ged_sb_dep</td>\n      <td>fatalities002_pgm_natsoc</td>\n      <td>natsoc</td>\n      <td>pgm</td>\n      <td>float_it</td>\n      <td></td>\n      <td></td>\n      <td>pgm_fatalities002_pgm_natsoc_lgbm_calib</td>\n      <td>pgm_fatalities002_pgm_natsoc_lgbm_test</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>fatalities002_pgm_broad_hurdle_lgbm</td>\n      <td>HurdleRegression(clf_name='LGBMClassifier', cl...</td>\n      <td>ln_ged_sb_dep</td>\n      <td>fatalities002_pgm_broad</td>\n      <td>broad</td>\n      <td>pgm</td>\n      <td>float_it</td>\n      <td></td>\n      <td></td>\n      <td>pgm_fatalities002_pgm_broad_hurdle_lgbm_calib</td>\n      <td>pgm_fatalities002_pgm_broad_hurdle_lgbm_test</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>fatalities002_pgm_broad_lgbm</td>\n      <td>LGBMRegressor(n_estimators=200)</td>\n      <td>ln_ged_sb_dep</td>\n      <td>fatalities002_pgm_broad</td>\n      <td>broad</td>\n      <td>pgm</td>\n      <td>float_it</td>\n      <td></td>\n      <td></td>\n      <td>pgm_fatalities002_pgm_broad_lgbm_calib</td>\n      <td>pgm_fatalities002_pgm_broad_lgbm_test</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>fatalities002_pgm_conflict_history_xgb</td>\n      <td>XGBRegressor(base_score=None, booster=None, ca...</td>\n      <td>ln_ged_sb_dep</td>\n      <td>fatalities002_pgm_conflict_history</td>\n      <td>conflicthist</td>\n      <td>pgm</td>\n      <td>float_it</td>\n      <td></td>\n      <td></td>\n      <td>pgm_fatalities002_pgm_conflict_history_xgb_calib</td>\n      <td>pgm_fatalities002_pgm_conflict_history_xgb_test</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>fatalities002_pgm_conflict_treelag_hurdle</td>\n      <td>HurdleRegression(clf_name='XGBClassifier',\\n  ...</td>\n      <td>ln_ged_sb_dep</td>\n      <td>fatalities002_pgm_conflict_treelag</td>\n      <td>conflicttreelag</td>\n      <td>pgm</td>\n      <td>float_it</td>\n      <td></td>\n      <td></td>\n      <td>pgm_fatalities002_pgm_conflict_treelag_hurdle_...</td>\n      <td>pgm_fatalities002_pgm_conflict_treelag_hurdle_...</td>\n      <td>HurdleRegression(clf_name='XGBClassifier',\\n  ...</td>\n      <td>RunResult(training_date = 2023-03-30)</td>\n      <td>RunResult(training_date = 2023-03-30)</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>fatalities002_pgm_conflict_sptime_dist_hurdle</td>\n      <td>HurdleRegression(clf_name='XGBClassifier',\\n  ...</td>\n      <td>ln_ged_sb_dep</td>\n      <td>fatalities002_pgm_conflict_sptime_dist</td>\n      <td>conflictsptime_dist</td>\n      <td>pgm</td>\n      <td>float_it</td>\n      <td></td>\n      <td></td>\n      <td>pgm_fatalities002_pgm_conflict_sptime_dist_hur...</td>\n      <td>pgm_fatalities002_pgm_conflict_sptime_dist_hur...</td>\n      <td>HurdleRegression(clf_name='XGBClassifier',\\n  ...</td>\n      <td>RunResult(training_date = 2023-02-16)</td>\n      <td>RunResult(training_date = 2023-02-17)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelMetaData"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
