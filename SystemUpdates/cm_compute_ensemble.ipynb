{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c567d3bf",
   "metadata": {},
   "source": [
    "# Notebook to define ensemble for production, cm level\n",
    "Version developed for ViEWS monthly updates: Fatalities002\n",
    "## Including ensemble weighting\n",
    "\n",
    "This notebook defines the ensemble used for production: selects a set of pre-trained models, retrieves and calibrates them, computes weights, and computes and stores the ensemble model predictions.\n",
    "\n",
    "Models are stored in model storage and most of them specified in the notebook fat_cm_constituentmodels\n",
    "\n",
    "The notebook draws on the following files in this repository:\n",
    "\n",
    "Script file: \n",
    "    Ensembling.py\n",
    "    FetchData.py\n",
    "\n",
    "Lists of models:\n",
    "    ModelList_cm_{dev_id}.csv (not yet functional)\n",
    "    List of pickles at local directory (will rewrite to drop dependence on this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3f0f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "# Views 3\n",
    "from viewser.operations import fetch\n",
    "from viewser import Queryset, Column\n",
    "import views_runs\n",
    "from views_partitioning import data_partitioner, legacy\n",
    "from stepshift import views\n",
    "from views_runs import storage, ModelMetadata\n",
    "from views_runs.storage import store, retrieve, fetch_metadata\n",
    "from views_forecasts.extensions import *\n",
    "# Other packages\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e8c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages from this repository, Tools folder\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../Tools')\n",
    "sys.path.append('../Intermediates')\n",
    "import os\n",
    "\n",
    "from Ensembling import CalibratePredictions, RetrieveStoredPredictions, mean_sd_calibrated, gam_calibrated, get_genetic_weights, make_run_from_step\n",
    "from FetchData import FetchData, RetrieveFromList\n",
    "from ViewsEstimators import *\n",
    "\n",
    "# Parallel processing and genetic algorithm\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "from functools import partial\n",
    "from genetic2 import *\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89992da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common parameters:\n",
    "\n",
    "dev_id = 'Fatalities002'\n",
    "run_id = 'Fatalities002'\n",
    "EndOfHistory = 517\n",
    "RunGeneticAlgo = False\n",
    "level = 'cm'\n",
    "get_future = False\n",
    "\n",
    "username = os.getlogin()\n",
    "\n",
    "steps = [*range(1, 36+1, 1)] # Which steps to train and predict for\n",
    "\n",
    "fi_steps = [1,3,6,12,36]\n",
    "# Specifying partitions\n",
    "\n",
    "calib_partitioner_dict = {\"train\":(121,408),\"predict\":(409,456)}\n",
    "test_partitioner_dict = {\"train\":(121,456),\"predict\":(457,504)}\n",
    "future_partitioner_dict = {\"train\":(121,504),\"predict\":(505,516)}\n",
    "calib_partitioner =  views_runs.DataPartitioner({\"calib\":calib_partitioner_dict})\n",
    "test_partitioner =  views_runs.DataPartitioner({\"test\":test_partitioner_dict})\n",
    "future_partitioner =  views_runs.DataPartitioner({\"future\":future_partitioner_dict})\n",
    "\n",
    "Mydropbox = f'/Users/{username}ViEWS Dropbox/ViEWS/'\n",
    "localpath = f'/Users/{username}/Pickles/'\n",
    "overleafpath = f'/Users/{username}/ViEWS Dropbox/Apps/Overleaf/ViEWS predicting fatalities/Tables/'\n",
    "\n",
    "\n",
    "print('Dropbox path set to',Mydropbox)\n",
    "print('Overleaf path set to',overleafpath)\n",
    "print('Local path set to',localpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaeb840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ModelDefinitions import DefineEnsembleModels\n",
    "\n",
    "ModelList = DefineEnsembleModels(level)\n",
    "    \n",
    "i = 0\n",
    "for model in ModelList:\n",
    "    print(i, model['modelname'], model['data_train'])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ec1bfa",
   "metadata": {},
   "source": [
    "# Retrieve and calibrate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1a4ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the predictions for calibration and test partitions\n",
    "# The ModelList contains the predictions organized by model\n",
    "\n",
    "ModelList = RetrieveStoredPredictions(ModelList, steps, EndOfHistory, dev_id, level, get_future)\n",
    "\n",
    "ModelList = CalibratePredictions(ModelList, EndOfHistory, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baddf32d-7b89-47d6-a243-199b8258f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelList[-2].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73ae353-9d64-4cc7-9834-cf194a5a52eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelList[-2]['calib_df_calibrated'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81687a8e",
   "metadata": {},
   "source": [
    "# Genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b415a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "super_walrus_genes = np.array([0, 0.010, 0.015, 0.020, 0.025, 0.030, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10, 0.12, 0.14, 0.16, 0.18, 0.20, 0.25, 0.30])\n",
    "steps_to_optimize = [1,2,3,4,6,9,12,15,18,24,30,36]\n",
    "generations = 100\n",
    "\n",
    "RunGeneticAlgo = True\n",
    "\n",
    "cpus = cpu_count()-2 if cpu_count()>2 else 1\n",
    "cpus - len(steps_to_optimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5038024",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_weights_df = get_genetic_weights(run_algorithm=RunGeneticAlgo,mlist=ModelList, steps=steps, steps_to_optimize=steps_to_optimize, generations=generations, cpus=cpus, gene_set=super_walrus_genes)\n",
    "i_weights_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dd1636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "palette = 'vlag'\n",
    "palette = sns.color_palette('BrBG',n_colors=50)\n",
    "palette = sns.cubehelix_palette(start=2, rot=0, dark=0, light=1, n_colors=100)\n",
    "\n",
    "fig, ax =plt.subplots(1,figsize=(16,11))\n",
    "ax = sns.heatmap(i_weights_df, xticklabels=2, linewidths=.5, cmap=palette,square=True)\n",
    "filename = overleafpath + 'genetic_weights.png'\n",
    "plt.savefig(filename, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5048101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing dfs to hold the predictions\n",
    "# A list of dictionaries organizing predictions and information as one step per entry,\n",
    "# including a dataframe for each step with one column per prediction model\n",
    "StepEnsembles = []\n",
    "\n",
    "stepcols = ['ln_ged_sb_dep']\n",
    "for step in steps:\n",
    "    stepcols.append('step_pred_' + str(step))\n",
    "for col in stepcols[1:]:  # Use the baseline as template to construct object\n",
    "    Step_prediction = {\n",
    "        'step_pred': col,\n",
    "        'df_calib': pd.DataFrame(ModelList[0]['calib_df_calibrated']['ln_ged_sb_dep']), \n",
    "        'df_test': pd.DataFrame(ModelList[0]['test_df_calibrated']['ln_ged_sb_dep']),\n",
    "        'ensembles_calib': pd.DataFrame(ModelList[0]['calib_df_calibrated']['ln_ged_sb_dep']),\n",
    "        'ensembles_test': pd.DataFrame(ModelList[0]['test_df_calibrated']['ln_ged_sb_dep'])\n",
    "    }\n",
    "    for model in ModelList:\n",
    "        modelname = model['modelname']\n",
    "        Step_prediction['df_calib'][modelname] = model['calib_df_calibrated'][col]\n",
    "        Step_prediction['df_test'][modelname] = model['test_df_calibrated'][col]\n",
    "    StepEnsembles.append(Step_prediction)\n",
    "\n",
    "# Calculating unweighted average ensembles\n",
    "i = 0\n",
    "for col in stepcols[1:]:\n",
    "    # Unweighted average\n",
    "    StepEnsembles[i]['ensembles_test']['unweighted_average'] = StepEnsembles[i]['df_test'].drop('ln_ged_sb_dep', axis=1).mean(axis=1)\n",
    "    StepEnsembles[i]['ensembles_calib']['unweighted_average'] = StepEnsembles[i]['df_calib'].drop('ln_ged_sb_dep', axis=1).mean(axis=1)\n",
    "#    StepEnsembles[i]['ensembles_calib'].loc['unweighted_average'] = StepEnsembles[i]['df_calib'].drop('ln_ged_sb_dep', axis=1).mean(axis=1)\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2503c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelList[-1]['calib_df_calibrated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10128a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "StepEnsembles[0]['ensembles_calib']['unweighted_average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2748913",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_weights_df.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ad53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculating weighted average ensembles\n",
    "# Based on the weights_df dataframe filled with Mihai's weights above\n",
    "\n",
    "def ensemble_predictions(yhats, weights):\n",
    "    # make predictions\n",
    "    yhats = np.array(yhats)\n",
    "    # weighted sum across ensemble members\n",
    "    result = np.dot(weights,yhats)\n",
    "    return result\n",
    "\n",
    "# normalize a vector to have unit norm\n",
    "def normalize(weights):\n",
    "    # calculate l1 vector norm\n",
    "    result = norm(weights, 1)\n",
    "    # check for a vector of all zeros\n",
    "    if result == 0.0:\n",
    "        return weights\n",
    "    # return normalized vector (unit norm)\n",
    "    return weights / result\n",
    "\n",
    "mult_dict={i_weights_df.index.values[i]:i_weights_df['step_pred_1'][i] for i in range(len(i_weights_df['step_pred_1']))}\n",
    "\n",
    "i = 0\n",
    "for col in stepcols[1:]:\n",
    "    # Unweighted average\n",
    "    df_calib = StepEnsembles[i]['df_calib'].drop('ln_ged_sb_dep', axis=1)\n",
    "    df_test = StepEnsembles[i]['df_test'].drop('ln_ged_sb_dep', axis=1)\n",
    "    StepEnsembles[i]['ensembles_calib']['weighted_average'] = (df_calib.mul(mult_dict,axis='columns')).sum(axis=1)\n",
    "    StepEnsembles[i]['ensembles_test']['weighted_average'] =  (df_test.mul(mult_dict,axis='columns')).sum(axis=1)\n",
    "    print('calib_sum',(df_calib.mul(mult_dict,axis='columns')).sum(axis=1))\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012feb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "StepEnsembles[0]['df_calib']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f085da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_weights_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a99d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the ensemble predictions\n",
    "EnsembleList = []\n",
    "genetic = {\n",
    "        'modelname': 'ensemble_genetic',\n",
    "        'algorithm': '',\n",
    "        'depvar': \"ln_ged_sb_dep\",\n",
    "        'calib_df_calibrated': ModelList[0]['calib_df_calibrated'].copy(),\n",
    "        'test_df_calibrated': ModelList[0]['test_df_calibrated'].copy(),\n",
    "    }    \n",
    "\n",
    "for step in StepEnsembles:\n",
    "    colname = step['step_pred']\n",
    "    print(colname)\n",
    "    genetic['calib_df_calibrated'][colname] = step['ensembles_calib']['weighted_average']\n",
    "    genetic['test_df_calibrated'][colname] = step['ensembles_test']['weighted_average']\n",
    "\n",
    "EnsembleList.append(genetic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a5744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "step['ensembles_test'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5204593",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9106d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "StepEnsembles[35]['ensembles_calib']['unweighted_average'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daadab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ensemble predictions\n",
    "predstore_calib = level +  '_' + genetic['modelname'] + '_calib'\n",
    "genetic['calib_df_calibrated'].forecasts.set_run(run_id)\n",
    "genetic['calib_df_calibrated'].forecasts.to_store(name=predstore_calib, overwrite = True)\n",
    "predstore_test = level +  '_' + genetic['modelname'] + '_test'\n",
    "genetic['test_df_calibrated'].forecasts.set_run(run_id)\n",
    "genetic['test_df_calibrated'].forecasts.to_store(name=predstore_test, overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e890a89-cb57-4b55-951a-131336edac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "genetic['test_df_calibrated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7858c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "genetic['test_df_calibrated'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305072e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which genetic ensembles are in prediction storage\n",
    "ViewsMetadata().with_name('genetic').fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146054eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
