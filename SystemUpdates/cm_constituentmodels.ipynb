{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1098f7cb",
   "metadata": {},
   "source": [
    "\n",
    "# ViEWS 3 constituent models \n",
    "## ViEWS production system, cm level\n",
    "\n",
    "\n",
    "This notebook trains a set of regression models for use in the monthly updated ViEWS predicting fatalities ensemble\n",
    "\n",
    "The notebook does the following: \n",
    "1. Retrieves data through querysets and stores in DataSets, a list of dictionaries\n",
    "2. Specifies the metadata of a number of models, stores in ModelList, a list of dictionaries\n",
    "3. Trains the models in ModelList, stores the trained objects in model storage and prediction storage\n",
    "4. Saves part of ModelList as csv and the rest as pickles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f7cba",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8855fab3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T13:21:26.377365Z",
     "start_time": "2024-03-28T13:21:26.345858Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef27dd3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T13:21:37.948455Z",
     "start_time": "2024-03-28T13:21:26.379704Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.cbook as cbook\n",
    "# sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRFRegressor, XGBRFClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "\n",
    "# Views 3\n",
    "from viewser.operations import fetch\n",
    "import views_runs\n",
    "from views_partitioning import data_partitioner, legacy\n",
    "from stepshift import views\n",
    "from views_runs import storage\n",
    "from views_runs.storage import store, retrieve, fetch_metadata\n",
    "\n",
    "from views_forecasts.extensions import *\n",
    "\n",
    "# Other packages\n",
    "import pickle as pkl\n",
    "\n",
    "# Packages from viewsforecasting repository\n",
    "\n",
    "#from Ensembling import CalibratePredictions, RetrieveStoredPredictions, mean_sd_calibrated, gam_calibrated\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../Tools')\n",
    "sys.path.append('../Intermediates')\n",
    "from FetchData import FetchData, RetrieveFromList, document_queryset, ReturnQsList, document_ensemble\n",
    "from ViewsEstimators import *\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T13:21:38.027428Z",
     "start_time": "2024-03-28T13:21:37.950375Z"
    }
   },
   "id": "bda6692757e9c224",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "3300ea25",
   "metadata": {},
   "source": [
    "## Common parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ae8aac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T13:21:38.087854Z",
     "start_time": "2024-03-28T13:21:38.028946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Mydropbox to /Users/root/Dropbox (ViEWS)/ViEWS\n"
     ]
    }
   ],
   "source": [
    "# Common parameters:\n",
    "dev_id = 'Fatalities002'\n",
    "run_id = dev_id\n",
    "\n",
    "# Generating a new run if necessary\n",
    "\n",
    "#try:\n",
    "#    ViewsMetadata().new_run(name=run_id,description='Developing the fatalities model for FCDO',min_month=1,max_month=999)\n",
    "#except KeyError:\n",
    "#    if 'devel' not in run_id:\n",
    "#        warnings.warn('You are overwriting a production system')\n",
    "\n",
    "RerunQuerysets = True\n",
    "\n",
    "EndOfHistory = 517\n",
    "steps = [*range(1, 36+1, 1)] # Which steps to train and predict for\n",
    "fi_steps = [1,3,6,12,36] # Which steps to present feature importances for\n",
    "#steps = [1,3,6,12,36]\n",
    "#fi_steps = [1,3,6,12,36]\n",
    "\n",
    "# Specifying partitions\n",
    "calib_partitioner_dict = {\"train\":(121,408),\"predict\":(409,456)}\n",
    "test_partitioner_dict = {\"train\":(121,456),\"predict\":(457,504)}\n",
    "future_partitioner_dict = {\"train\":(121,504),\"predict\":(505,516)}\n",
    "calib_partitioner =  views_runs.DataPartitioner({\"calib\":calib_partitioner_dict})\n",
    "test_partitioner =  views_runs.DataPartitioner({\"test\":test_partitioner_dict})\n",
    "future_partitioner =  views_runs.DataPartitioner({\"future\":future_partitioner_dict})\n",
    "\n",
    "Mydropbox = f'/Users/{os.getlogin()}/Dropbox (ViEWS)/ViEWS'\n",
    "print('Setting Mydropbox to',Mydropbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf0208",
   "metadata": {},
   "source": [
    "# Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1a0acf1-ede9-463b-bfe5-2e5a274c7bee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T13:21:38.291395Z",
     "start_time": "2024-03-28T13:21:38.091018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sofia/mambaforge/envs/viewser_vimur/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "! which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a457b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T13:35:40.319218Z",
     "start_time": "2024-03-28T13:21:38.293919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32: \"Queryset fatalities002_topics *transform in progress* - 22 of 452 jobs remaining\"       \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46.0M/46.0M [00:18<00:00, 2.50MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_topics read successfully                                        \n",
      "2: \"Queryset fatalities002_aquastat *dispatched to transform queue* - columns to compute: 11\"  \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.37M/2.37M [00:00<00:00, 3.19MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_aquastat read successfully                                             \n",
      "21: \"Queryset fatalities002_conflict_history *transform in progress* - 26 of 178 jobs remaining\"       \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.41M/4.41M [00:01<00:00, 2.99MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_conflict_history read successfully                                        \n",
      "32: \"Queryset fatalities002_conflict_history_long *transform in progress* - 86 of 364 jobs remaining\"      \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8.47M/8.47M [00:04<00:00, 1.81MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_conflict_history_long read successfully                                        \n",
      "13: \"Queryset fatalities002_vdem_short *transform in progress* - 65 of 331 jobs remaining\"       \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.01M/4.01M [00:01<00:00, 2.71MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_vdem_short read successfully                                        \n",
      "22: \"Queryset fatalities002_wdi_short *transform in progress* - 18 of 180 jobs remaining\"       \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.18M/5.18M [00:01<00:00, 3.34MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_wdi_short read successfully                                        \n",
      "2: \"Queryset fatalities002_joint_broad *dispatched to transform queue* - columns to compute: 7\"  \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13.9M/13.9M [00:04<00:00, 2.84MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_joint_broad read successfully                                            \n",
      "3: \"Queryset fatalities002_faostat *dispatched to transform queue* - columns to compute: 35\"  \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3.59M/3.59M [00:01<00:00, 2.22MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_faostat read successfully                                             \n",
      "2: \"Queryset fatalities002_faoprices *dispatched to transform queue* - columns to compute: 10\"  \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.03M/2.03M [00:01<00:00, 1.86MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_faoprices read successfully                                             \n",
      "2: \"Queryset fatalities002_imfweo *dispatched to transform queue* - columns to compute: 4\"  \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.42M/1.42M [00:00<00:00, 3.42MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_imfweo read successfully                                            \n",
      "Model:  fatalities002_baseline\n",
      "Model:  fatalities002_topics\n",
      "Model:  fatalities002_aquastat\n",
      "Model:  fatalities002_conflict_history\n",
      "Model:  fatalities002_conflict_history_long\n",
      "Model:  fatalities002_vdem_short\n",
      "Model:  fatalities002_wdi_short\n",
      "Model:  fatalities002_all_features\n",
      "Model:  fatalities002_joint_narrow\n",
      "Model:  fatalities002_joint_broad\n",
      "Model:  fatalities002_faostat\n",
      "Model:  fatalities002_faoprices\n",
      "Model:  fatalities002_imfweo\n"
     ]
    }
   ],
   "source": [
    "# Create Markdown documentation of all querysets used\n",
    "level = 'cm'\n",
    "qslist = ReturnQsList(level)\n",
    "document_queryset(qslist,dev_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7e75122",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-03-28T13:38:25.607598Z",
     "start_time": "2024-03-28T13:35:40.321517Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.42M/1.42M [00:00<00:00, 1.98MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_imfweo read successfully \n",
      "imfweo: A dataset with 11 columns, with data between t = 1 and 852; 213 units.\n",
      "2: \"Queryset fatalities002_joint_narrow *dispatched to transform queue* - columns to compute: 2\"  \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3.81M/3.81M [00:01<00:00, 1.95MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_joint_narrow read successfully                                            \n",
      "joint_narrow: A dataset with 31 columns, with data between t = 1 and 852; 213 units.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8.47M/8.47M [00:02<00:00, 3.41MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_conflict_history_long read successfully \n",
      "conflictlong_ln: A dataset with 62 columns, with data between t = 1 and 852; 213 units.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.03M/2.03M [00:00<00:00, 2.32MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_faoprices read successfully \n",
      "faoprices: A dataset with 17 columns, with data between t = 1 and 852; 213 units.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.28M/1.28M [00:00<00:00, 2.37MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_baseline read successfully \n",
      "baseline002: A dataset with 6 columns, with data between t = 1 and 852; 213 units.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.37M/2.37M [00:01<00:00, 1.94MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_aquastat read successfully \n",
      "aquastat: A dataset with 17 columns, with data between t = 1 and 852; 213 units.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13.9M/13.9M [00:06<00:00, 2.21MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_joint_broad read successfully \n",
      "joint_broad: A dataset with 80 columns, with data between t = 1 and 852; 213 units.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.41M/4.41M [00:01<00:00, 3.53MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_conflict_history read successfully \n",
      "conflict_ln: A dataset with 30 columns, with data between t = 1 and 852; 213 units.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56.5M/56.5M [00:19<00:00, 2.83MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_all_features read successfully \n",
      "all_features: A dataset with 189 columns, with data between t = 1 and 852; 213 units.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3.59M/3.59M [00:01<00:00, 2.24MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_faostat read successfully \n",
      "faostat: A dataset with 41 columns, with data between t = 1 and 852; 213 units.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.18M/5.18M [00:02<00:00, 2.57MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_wdi_short read successfully \n",
      "wdi_short: A dataset with 34 columns, with data between t = 1 and 852; 213 units.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.01M/4.01M [00:01<00:00, 2.01MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_vdem_short read successfully \n",
      "vdem_short: A dataset with 64 columns, with data between t = 1 and 852; 213 units.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46.0M/46.0M [00:16<00:00, 2.77MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_topics read successfully \n",
      "topics_002: A dataset with 70 columns, with data between t = 1 and 852; 213 units.\n",
      "all_features [9.99999702e-01 2.97648790e-07 2.71474294e-13 5.36004218e-16\n",
      " 5.98000121e-17 4.93573610e-17 1.26320806e-17 9.90132683e-18\n",
      " 2.68556820e-18 5.72507731e-19 1.72781911e-19 3.75338064e-20\n",
      " 1.80545456e-20 1.00420723e-20 4.16086375e-21 1.56095069e-21\n",
      " 1.11980632e-21 9.61684717e-22 1.30640993e-23 1.13025407e-23]\n",
      "[2.87777559e+16 1.57003398e+13 1.49941326e+10 6.66255939e+08\n",
      " 2.22539765e+08 2.02177562e+08 1.02280875e+08 9.05531762e+07\n",
      " 4.71601397e+07 2.17744737e+07 1.19620641e+07 5.57530069e+06\n",
      " 3.86678719e+06 2.88382340e+06 1.85630245e+06 1.13697675e+06\n",
      " 9.63004788e+05 8.92428327e+05 1.04015180e+05 9.67486756e+04]\n",
      "topics [9.99999781e-01 1.82814384e-07 3.23193459e-08 2.74300212e-09\n",
      " 1.01924676e-09 1.96394121e-16 8.29242922e-17 1.69048090e-17\n",
      " 5.71992410e-18 4.57968849e-18]\n",
      "[3.56143189e+10 1.52275443e+07 6.40259413e+06 1.86525306e+06\n",
      " 1.13701020e+06 4.99101565e+02 3.24313911e+02 1.46429920e+02\n",
      " 8.51765065e+01 7.62153871e+01]\n",
      "vdem [9.99997989e-01 2.01087702e-06 5.59655917e-14 8.25433962e-16\n",
      " 3.16555452e-16 1.81649601e-16 1.30581213e-16 5.87327846e-17\n",
      " 4.79151306e-17 3.85700586e-17 3.41253928e-17 1.27430118e-17\n",
      " 8.90285256e-18 7.32590727e-18 6.51748070e-18]\n",
      "[3.56143188e+10 5.05030764e+07 8.42530494e+03 1.02321346e+03\n",
      " 6.33650785e+02 4.80001177e+02 4.06972841e+02 2.72938861e+02\n",
      " 2.46525255e+02 2.21182228e+02 2.08048174e+02 1.27133827e+02\n",
      " 1.06264859e+02 9.63952839e+01 9.09211573e+01]\n",
      "wdi [9.99999702e-01 2.97648790e-07 2.71474291e-13 5.35929161e-16\n",
      " 5.97755972e-17 4.93435483e-17 1.26228626e-17 9.89612393e-18\n",
      " 2.68311934e-18 1.87127161e-20 1.07351965e-23 7.29698441e-25\n",
      " 2.30429781e-25 4.08862217e-26 3.77124558e-26]\n",
      "[2.87777559e+16 1.57003398e+13 1.49941325e+10 6.66209290e+08\n",
      " 2.22494332e+08 2.02149270e+08 1.02243549e+08 9.05293813e+07\n",
      " 4.71386331e+07 3.93663731e+06 9.42892082e+04 2.45826501e+04\n",
      " 1.38142176e+04 5.81896144e+03 5.58855330e+03]\n"
     ]
    }
   ],
   "source": [
    "from FetchData import fetch_cm_data_from_model_def\n",
    "\n",
    "Datasets=fetch_cm_data_from_model_def(qslist, EndOfHistory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a925bdb3",
   "metadata": {},
   "source": [
    "# Generating predictions\n",
    "Using the ViEWS3 partitioning/stepshifting syntax. Training models for A: calibration partition and B: test partition, to test out some calibration routines. Most models trained with ln_ged_sb_best as outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "990574dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T13:38:25.932483Z",
     "start_time": "2024-03-28T13:38:25.609573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ln_ged_sb_dep', 'ln_ged_sb', 'wdi_sp_pop_totl', 'topic_tokens_t1',\n",
      "       'topic_tokens_t2', 'topic_tokens_t13', 'topic_ste_theta0_stock_t1',\n",
      "       'topic_ste_theta0_stock_t2', 'topic_ste_theta0_stock_t13',\n",
      "       'topic_ste_theta1_stock_t1', 'topic_ste_theta1_stock_t2',\n",
      "       'topic_ste_theta1_stock_t13', 'topic_ste_theta2_stock_t1',\n",
      "       'topic_ste_theta2_stock_t2', 'topic_ste_theta2_stock_t13',\n",
      "       'topic_ste_theta3_stock_t1', 'topic_ste_theta3_stock_t2',\n",
      "       'topic_ste_theta3_stock_t13', 'topic_ste_theta4_stock_t1',\n",
      "       'topic_ste_theta4_stock_t2', 'topic_ste_theta4_stock_t13',\n",
      "       'topic_ste_theta5_stock_t1', 'topic_ste_theta5_stock_t2',\n",
      "       'topic_ste_theta5_stock_t13', 'topic_ste_theta6_stock_t1',\n",
      "       'topic_ste_theta6_stock_t2', 'topic_ste_theta6_stock_t13',\n",
      "       'topic_ste_theta7_stock_t1', 'topic_ste_theta7_stock_t2',\n",
      "       'topic_ste_theta7_stock_t13', 'topic_ste_theta8_stock_t1',\n",
      "       'topic_ste_theta8_stock_t2', 'topic_ste_theta8_stock_t13',\n",
      "       'topic_ste_theta9_stock_t1', 'topic_ste_theta9_stock_t2',\n",
      "       'topic_ste_theta9_stock_t13', 'topic_ste_theta10_stock_t1',\n",
      "       'topic_ste_theta10_stock_t2', 'topic_ste_theta10_stock_t13',\n",
      "       'topic_ste_theta11_stock_t1', 'topic_ste_theta11_stock_t2',\n",
      "       'topic_ste_theta11_stock_t13', 'topic_ste_theta12_stock_t1',\n",
      "       'topic_ste_theta12_stock_t2', 'topic_ste_theta12_stock_t13',\n",
      "       'topic_ste_theta13_stock_t1', 'topic_ste_theta13_stock_t2',\n",
      "       'topic_ste_theta13_stock_t13', 'topic_ste_theta14_stock_t1',\n",
      "       'topic_ste_theta14_stock_t2', 'topic_ste_theta14_stock_t13',\n",
      "       'decay_ged_sb_5', 'decay_ged_os_5', 'splag_1_decay_ged_sb_5',\n",
      "       'topic_tokens_t1_splag', 'topic_ste_theta0_stock_t1_splag',\n",
      "       'topic_ste_theta1_stock_t1_splag', 'topic_ste_theta2_stock_t1_splag',\n",
      "       'topic_ste_theta3_stock_t1_splag', 'topic_ste_theta4_stock_t1_splag',\n",
      "       'topic_ste_theta5_stock_t1_splag', 'topic_ste_theta6_stock_t1_splag',\n",
      "       'topic_ste_theta7_stock_t1_splag', 'topic_ste_theta8_stock_t1_splag',\n",
      "       'topic_ste_theta9_stock_t1_splag', 'topic_ste_theta10_stock_t1_splag',\n",
      "       'topic_ste_theta11_stock_t1_splag', 'topic_ste_theta12_stock_t1_splag',\n",
      "       'topic_ste_theta13_stock_t1_splag', 'topic_ste_theta14_stock_t1_splag'],\n",
      "      dtype='object')\n",
      "Index(['ln_ged_sb_dep', 'ln_ged_sb', 'decay_ged_sb_5', 'decay_ged_os_5',\n",
      "       'splag_1_decay_ged_sb_5', 'wdi_sp_pop_totl', 'pc1', 'pc2', 'pc3', 'pc4',\n",
      "       'pc5', 'pc6', 'pc7', 'pc8', 'pc9', 'pc10'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for ds in Datasets:\n",
    "    if 'topics' in ds['Name']:\n",
    "        print(ds['df'].columns)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf49bd2",
   "metadata": {},
   "source": [
    "## Checking missingness and infinity values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfe61e37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T13:38:37.122993Z",
     "start_time": "2024-03-28T13:38:25.934443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imfweo\n",
      "imfweo_ngdp_rpch_tcurrent 158230 missing: 0 infinity: 0\n",
      "imfweo_ngdp_rpch_tmin1 158230 missing: 0 infinity: 0\n",
      "imfweo_ngdp_rpch_tplus1 158230 missing: 0 infinity: 0\n",
      "imfweo_ngdp_rpch_tplus2 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "gleditsch_ward 158230 missing: 0 infinity: 0\n",
      "wdi_sp_pop_totl 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_5 158230 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "joint_narrow\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "gleditsch_ward 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "reign_tenure_months 158230 missing: 0 infinity: 0\n",
      "wdi_sp_pop_totl 158230 missing: 2242 infinity: 0\n",
      "wdi_ag_lnd_frst_k2 158230 missing: 2620 infinity: 0\n",
      "wdi_nv_agr_totl_kn 158230 missing: 5053 infinity: 0\n",
      "wdi_sh_sta_maln_zs 158230 missing: 30885 infinity: 0\n",
      "wdi_sl_tlf_totl_fe_zs 158230 missing: 11586 infinity: 0\n",
      "wdi_sm_pop_refg_or 158230 missing: 4664 infinity: 0\n",
      "wdi_sp_dyn_imrt_in 158230 missing: 2242 infinity: 0\n",
      "wdi_sp_pop_14_fe_zs 158230 missing: 2242 infinity: 0\n",
      "wdi_sp_pop_grow 158230 missing: 2242 infinity: 0\n",
      "vdem_v2xcl_dmove 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xcl_rol 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xeg_eqdr 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xpe_exlpol 158230 missing: 15400 infinity: 0\n",
      "vdem_v2xpe_exlsocgr 158230 missing: 15400 infinity: 0\n",
      "ln_ged_sb_tlag_1 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_2 158230 missing: 5 infinity: 0\n",
      "splag_wdi_ag_lnd_frst_k2 158230 missing: 0 infinity: 0\n",
      "splag_wdi_sl_tlf_totl_fe_zs 158230 missing: 0 infinity: 0\n",
      "splag_wdi_sm_pop_netm 158230 missing: 0 infinity: 0\n",
      "splag_vdem_v2xpe_exlsocgr 158230 missing: 0 infinity: 0\n",
      "splag_vdem_v2xcl_rol 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_5 158230 missing: 0 infinity: 0\n",
      "decay_acled_os_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_100 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_500 158230 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "conflictlong_ln\n",
      "gleditsch_ward 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "ln_ged_ns 158230 missing: 0 infinity: 0\n",
      "ln_ged_os 158230 missing: 0 infinity: 0\n",
      "ln_acled_sb 158230 missing: 1437 infinity: 0\n",
      "ln_acled_sb_count 158230 missing: 1437 infinity: 0\n",
      "ln_acled_os 158230 missing: 1437 infinity: 0\n",
      "splag_1_ged_sb 158230 missing: 0 infinity: 0\n",
      "splag_2_ged_sb 158230 missing: 0 infinity: 0\n",
      "splag_1_ged_os 158230 missing: 0 infinity: 0\n",
      "splag_1_ged_ns 158230 missing: 0 infinity: 0\n",
      "ln_acled_prx_count 158230 missing: 1437 infinity: 0\n",
      "ln_acled_pr_count 158230 missing: 1437 infinity: 0\n",
      "ln_acled_prx_fat 158230 missing: 1437 infinity: 0\n",
      "ln_acled_sb_gov 158230 missing: 1437 infinity: 0\n",
      "ln_acled_sb_reb 158230 missing: 1437 infinity: 0\n",
      "ln_acled_ns 158230 missing: 1437 infinity: 0\n",
      "wdi_sp_pop_totl 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb_tlag_1 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_2 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_3 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_4 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_5 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_6 158230 missing: 11 infinity: 0\n",
      "ln_ged_sb_tsum_24 158230 missing: 0 infinity: 0\n",
      "ln_ged_os_tlag_1 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tsum_12 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb_tsum_48 158230 missing: 0 infinity: 0\n",
      "ln_ged_ns_tlag_1 158230 missing: 5 infinity: 0\n",
      "ln_ged_ns_tlag_2 158230 missing: 5 infinity: 0\n",
      "ln_ged_os_tlag_2 158230 missing: 5 infinity: 0\n",
      "ln_acled_sb_tlag_1 158230 missing: 1437 infinity: 0\n",
      "ln_acled_sb_tlag_2 158230 missing: 1437 infinity: 0\n",
      "ln_acled_os_tlag_1 158230 missing: 1437 infinity: 0\n",
      "ln_acled_os_tlag_2 158230 missing: 1437 infinity: 0\n",
      "ln_acled_ns_tlag_1 158230 missing: 1437 infinity: 0\n",
      "ln_acled_ns_tlag_2 158230 missing: 1437 infinity: 0\n",
      "decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_100 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_500 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_100 158230 missing: 0 infinity: 0\n",
      "decay_ged_ns_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_ns_100 158230 missing: 0 infinity: 0\n",
      "decay_acled_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_acled_os_5 158230 missing: 0 infinity: 0\n",
      "decay_acled_ns_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_1 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_25 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_1 158230 missing: 0 infinity: 0\n",
      "faoprices\n",
      "fao_wheat_price 158230 missing: 0 infinity: 0\n",
      "fao_mp_price 158230 missing: 0 infinity: 0\n",
      "fao_sugar_price 158230 missing: 0 infinity: 0\n",
      "fao_meat_price 158230 missing: 0 infinity: 0\n",
      "fao_milk_price 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "gleditsch_ward 158230 missing: 0 infinity: 0\n",
      "delta_fao_wheat_price 158230 missing: 0 infinity: 0\n",
      "delta_fao_mp_price 158230 missing: 0 infinity: 0\n",
      "delta_fao_sugar_price 158230 missing: 0 infinity: 0\n",
      "delta_fao_meat_price 158230 missing: 0 infinity: 0\n",
      "delta_fao_milk_price 158230 missing: 0 infinity: 0\n",
      "wdi_sp_pop_totl 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_5 158230 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "baseline002\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "wdi_sp_pop_totl 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_5 158230 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "aquastat\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "wdi_sp_pop_totl 158230 missing: 0 infinity: 0\n",
      "agr_withdrawal_pct_t48 158230 missing: 32 infinity: 0\n",
      "dam_cap_pcap_t48 158230 missing: 32 infinity: 0\n",
      "groundwater_export_t48 158230 missing: 32 infinity: 0\n",
      "fresh_withdrawal_pct_t48 158230 missing: 32 infinity: 0\n",
      "ind_efficiency_t48 158230 missing: 32 infinity: 0\n",
      "irr_agr_efficiency_t48 158230 missing: 32 infinity: 0\n",
      "services_efficiency_t48 158230 missing: 32 infinity: 0\n",
      "general_efficiency_t48 158230 missing: 32 infinity: 0\n",
      "water_stress_t48 158230 missing: 32 infinity: 0\n",
      "renewable_internal_pcap_t48 158230 missing: 32 infinity: 0\n",
      "renewable_pcap_t48 158230 missing: 32 infinity: 0\n",
      "decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_5 158230 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "joint_broad\n",
      "gleditsch_ward 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "ln_ged_ns 158230 missing: 0 infinity: 0\n",
      "ln_ged_os 158230 missing: 0 infinity: 0\n",
      "ln_acled_sb 158230 missing: 1437 infinity: 0\n",
      "ln_acled_sb_count 158230 missing: 1437 infinity: 0\n",
      "ln_acled_os 158230 missing: 1437 infinity: 0\n",
      "wdi_sm_pop_netm 158230 missing: 2242 infinity: 0\n",
      "wdi_sm_pop_refg_or 158230 missing: 4664 infinity: 0\n",
      "wdi_dt_oda_odat_pc_zs 158230 missing: 29607 infinity: 0\n",
      "wdi_ms_mil_xpnd_gd_zs 158230 missing: 24108 infinity: 0\n",
      "wdi_sl_tlf_totl_fe_zs 158230 missing: 11586 infinity: 0\n",
      "wdi_nv_agr_totl_kn 158230 missing: 5053 infinity: 0\n",
      "wdi_sp_pop_grow 158230 missing: 2242 infinity: 0\n",
      "wdi_se_enr_prim_fm_zs 158230 missing: 3448 infinity: 0\n",
      "wdi_sp_urb_totl_in_zs 158230 missing: 2242 infinity: 0\n",
      "wdi_sh_sta_maln_zs 158230 missing: 30885 infinity: 0\n",
      "wdi_sp_dyn_imrt_fe_in 158230 missing: 2242 infinity: 0\n",
      "wdi_ny_gdp_mktp_kd 158230 missing: 4071 infinity: 0\n",
      "wdi_sh_sta_stnt_zs 158230 missing: 30885 infinity: 0\n",
      "vdem_v2x_horacc 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xnp_client 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_veracc 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_divparctrl 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xpe_exlpol 158230 missing: 15400 infinity: 0\n",
      "vdem_v2x_diagacc 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xpe_exlgeo 158230 missing: 15400 infinity: 0\n",
      "vdem_v2xpe_exlgender 158230 missing: 15400 infinity: 0\n",
      "vdem_v2xpe_exlsocgr 158230 missing: 15400 infinity: 0\n",
      "vdem_v2x_ex_party 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_genpp 158230 missing: 15391 infinity: 0\n",
      "vdem_v2xeg_eqdr 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xcl_prpty 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xeg_eqprotec 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_ex_military 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xcl_dmove 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_clphy 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_hosabort 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xnp_regcorr 158230 missing: 15145 infinity: 0\n",
      "wdi_sp_pop_totl 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb_tlag_1 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_2 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_3 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_4 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_5 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_6 158230 missing: 11 infinity: 0\n",
      "ln_ged_os_tlag_1 158230 missing: 5 infinity: 0\n",
      "topic_tokens_t1 158230 missing: 5 infinity: 0\n",
      "topic_tokens_t2 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta4_stock_t1 158230 missing: 5 infinity: 0\n",
      "conflict_ln\n",
      "gleditsch_ward 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "ln_ged_ns 158230 missing: 0 infinity: 0\n",
      "ln_ged_os 158230 missing: 0 infinity: 0\n",
      "ln_acled_sb 158230 missing: 1437 infinity: 0\n",
      "ln_acled_sb_count 158230 missing: 1437 infinity: 0\n",
      "ln_acled_os 158230 missing: 1437 infinity: 0\n",
      "wdi_sp_pop_totl 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb_tlag_1 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_2 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_3 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_4 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_5 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_6 158230 missing: 11 infinity: 0\n",
      "ln_ged_sb_tsum_24 158230 missing: 0 infinity: 0\n",
      "ln_ged_os_tlag_1 158230 missing: 5 infinity: 0\n",
      "decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_100 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_500 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_100 158230 missing: 0 infinity: 0\n",
      "decay_ged_ns_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_ns_100 158230 missing: 0 infinity: 0\n",
      "decay_acled_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_acled_os_5 158230 missing: 0 infinity: 0\n",
      "decay_acled_ns_5 158230 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_os_5 158230 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_ns_5 158230 missing: 0 infinity: 0\n",
      "all_features\n",
      "gleditsch_ward 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "ln_ged_ns 158230 missing: 0 infinity: 0\n",
      "ln_ged_os 158230 missing: 0 infinity: 0\n",
      "ln_acled_sb 158230 missing: 1437 infinity: 0\n",
      "ln_acled_sb_count 158230 missing: 1437 infinity: 0\n",
      "ln_acled_os 158230 missing: 1437 infinity: 0\n",
      "wdi_ag_lnd_frst_k2 158230 missing: 2620 infinity: 0\n",
      "wdi_dt_oda_odat_pc_zs 158230 missing: 29607 infinity: 0\n",
      "wdi_ms_mil_xpnd_gd_zs 158230 missing: 24108 infinity: 0\n",
      "wdi_ms_mil_xpnd_zs 158230 missing: 28621 infinity: 0\n",
      "wdi_nv_agr_totl_kd 158230 missing: 6597 infinity: 0\n",
      "wdi_nv_agr_totl_kn 158230 missing: 5053 infinity: 0\n",
      "wdi_ny_gdp_pcap_kd 158230 missing: 4071 infinity: 0\n",
      "wdi_sp_dyn_le00_in 158230 missing: 3094 infinity: 0\n",
      "wdi_se_enr_prim_fm_zs 158230 missing: 3448 infinity: 0\n",
      "wdi_se_enr_prsc_fm_zs 158230 missing: 5152 infinity: 0\n",
      "wdi_se_prm_nenr 158230 missing: 6365 infinity: 0\n",
      "wdi_sh_sta_maln_zs 158230 missing: 30885 infinity: 0\n",
      "wdi_sh_sta_stnt_zs 158230 missing: 30885 infinity: 0\n",
      "wdi_sl_tlf_totl_fe_zs 158230 missing: 11586 infinity: 0\n",
      "wdi_sm_pop_refg_or 158230 missing: 4664 infinity: 0\n",
      "wdi_sm_pop_netm 158230 missing: 2242 infinity: 0\n",
      "wdi_sm_pop_totl_zs 158230 missing: 2641 infinity: 0\n",
      "wdi_sp_dyn_imrt_in 158230 missing: 2242 infinity: 0\n",
      "wdi_sh_dyn_mort_fe 158230 missing: 2242 infinity: 0\n",
      "wdi_sp_pop_14_fe_zs 158230 missing: 2242 infinity: 0\n",
      "wdi_sp_pop_1564_fe_zs 158230 missing: 2242 infinity: 0\n",
      "wdi_sp_pop_65up_fe_zs 158230 missing: 2242 infinity: 0\n",
      "wdi_sp_pop_grow 158230 missing: 2242 infinity: 0\n",
      "wdi_sp_urb_totl_in_zs 158230 missing: 2242 infinity: 0\n",
      "vdem_v2x_delibdem 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_egaldem 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_libdem 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_libdem_48 158230 missing: 15166 infinity: 0\n",
      "vdem_v2x_partip 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_partipdem 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_accountability 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_civlib 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_clphy 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_cspart 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_divparctrl 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_edcomp_thick 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_egal 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_execorr 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_frassoc_thick 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_gencs 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_gender 158230 missing: 15391 infinity: 0\n",
      "vdem_v2x_genpp 158230 missing: 15391 infinity: 0\n",
      "vdem_v2x_horacc 158230 missing: 15145 infinity: 0\n",
      "faostat\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "gleditsch_ward 158230 missing: 0 infinity: 0\n",
      "consumer_prices_food_indices 158230 missing: 1437 infinity: 0\n",
      "consumer_prices_general_indices 158230 missing: 1437 infinity: 0\n",
      "food_price_inflation 158230 missing: 1437 infinity: 0\n",
      "avg_adequate_diet 158230 missing: 1437 infinity: 0\n",
      "avg_animalprotein_pcap_day 158230 missing: 1437 infinity: 0\n",
      "avg_fprod_value 158230 missing: 1437 infinity: 0\n",
      "avg_protein_pcap_day 158230 missing: 1437 infinity: 0\n",
      "gdp_pc_ppp 158230 missing: 1437 infinity: 0\n",
      "kcal_pcap_day 158230 missing: 1437 infinity: 0\n",
      "kcal_pcap_day_cerotu 158230 missing: 1437 infinity: 0\n",
      "pcap_fprod_var 158230 missing: 1437 infinity: 0\n",
      "pcap_fsupply_var 158230 missing: 1437 infinity: 0\n",
      "pct_arable_land 158230 missing: 1437 infinity: 0\n",
      "pct_cereal_import 158230 missing: 1437 infinity: 0\n",
      "pct_fimport_merch 158230 missing: 1437 infinity: 0\n",
      "pct_modsevere_finsecurity 158230 missing: 1437 infinity: 0\n",
      "pct_pop_basicdrink 158230 missing: 1437 infinity: 0\n",
      "pct_pop_basicsani 158230 missing: 1437 infinity: 0\n",
      "pct_pop_safedrink 158230 missing: 1437 infinity: 0\n",
      "pct_pop_safesani 158230 missing: 1437 infinity: 0\n",
      "pct_severe_finsecurity 158230 missing: 1437 infinity: 0\n",
      "pct_und5_overweight 158230 missing: 1437 infinity: 0\n",
      "pct_und5_stunted 158230 missing: 1437 infinity: 0\n",
      "pct_und5_wasting 158230 missing: 1437 infinity: 0\n",
      "pct_undernourished 158230 missing: 1437 infinity: 0\n",
      "pol_stability 158230 missing: 1437 infinity: 0\n",
      "pop_modsevere_finsecurity 158230 missing: 1437 infinity: 0\n",
      "pop_severe_finsecurity 158230 missing: 1437 infinity: 0\n",
      "pop_undernourished 158230 missing: 1437 infinity: 0\n",
      "prev_adult_obesity 158230 missing: 1437 infinity: 0\n",
      "prev_infant_bfeed 158230 missing: 1437 infinity: 0\n",
      "prev_lowbweight 158230 missing: 1437 infinity: 0\n",
      "prev_repr_anemia 158230 missing: 1437 infinity: 0\n",
      "rail_density 158230 missing: 1437 infinity: 0\n",
      "wdi_sp_pop_totl 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_5 158230 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "wdi_short\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "wdi_ag_lnd_frst_k2 158230 missing: 2620 infinity: 0\n",
      "wdi_dt_oda_odat_pc_zs 158230 missing: 29607 infinity: 0\n",
      "wdi_ms_mil_xpnd_gd_zs 158230 missing: 24108 infinity: 0\n",
      "wdi_ms_mil_xpnd_zs 158230 missing: 28621 infinity: 0\n",
      "wdi_nv_agr_totl_kd 158230 missing: 6597 infinity: 0\n",
      "wdi_nv_agr_totl_kn 158230 missing: 5053 infinity: 0\n",
      "wdi_ny_gdp_pcap_kd 158230 missing: 4071 infinity: 0\n",
      "wdi_sp_dyn_le00_in 158230 missing: 3094 infinity: 0\n",
      "wdi_se_enr_prim_fm_zs 158230 missing: 3448 infinity: 0\n",
      "wdi_se_enr_prsc_fm_zs 158230 missing: 5152 infinity: 0\n",
      "wdi_se_prm_nenr 158230 missing: 6365 infinity: 0\n",
      "wdi_sh_sta_maln_zs 158230 missing: 30885 infinity: 0\n",
      "wdi_sh_sta_stnt_zs 158230 missing: 30885 infinity: 0\n",
      "wdi_sl_tlf_totl_fe_zs 158230 missing: 11586 infinity: 0\n",
      "wdi_sm_pop_refg_or 158230 missing: 4664 infinity: 0\n",
      "wdi_sm_pop_netm 158230 missing: 2242 infinity: 0\n",
      "wdi_sm_pop_totl_zs 158230 missing: 2641 infinity: 0\n",
      "wdi_sp_dyn_imrt_in 158230 missing: 2242 infinity: 0\n",
      "wdi_sh_dyn_mort_fe 158230 missing: 2242 infinity: 0\n",
      "wdi_sp_pop_14_fe_zs 158230 missing: 2242 infinity: 0\n",
      "wdi_sp_pop_1564_fe_zs 158230 missing: 2242 infinity: 0\n",
      "wdi_sp_pop_65up_fe_zs 158230 missing: 2242 infinity: 0\n",
      "wdi_sp_pop_grow 158230 missing: 2242 infinity: 0\n",
      "wdi_sp_urb_totl_in_zs 158230 missing: 2242 infinity: 0\n",
      "wdi_sp_pop_totl 158230 missing: 0 infinity: 0\n",
      "splag_wdi_sl_tlf_totl_fe_zs 158230 missing: 0 infinity: 0\n",
      "splag_wdi_sm_pop_refg_or 158230 missing: 0 infinity: 0\n",
      "splag_wdi_sm_pop_netm 158230 missing: 0 infinity: 0\n",
      "splag_wdi_ag_lnd_frst_k2 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_5 158230 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "vdem_short\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "vdem_v2x_delibdem 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_egaldem 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_libdem 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_libdem_48 158230 missing: 15166 infinity: 0\n",
      "vdem_v2x_partip 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_partipdem 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_accountability 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_civlib 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_clphy 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_cspart 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_divparctrl 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_edcomp_thick 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_egal 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_execorr 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_frassoc_thick 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_gencs 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_gender 158230 missing: 15391 infinity: 0\n",
      "vdem_v2x_genpp 158230 missing: 15391 infinity: 0\n",
      "vdem_v2x_horacc 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_neopat 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_pubcorr 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_rule 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_veracc 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_ex_military 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_ex_party 158230 missing: 15145 infinity: 0\n",
      "vdem_v2x_freexp 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xcl_acjst 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xcl_dmove 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xcl_prpty 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xcl_rol 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xcl_slave 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xdd_dd 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xdl_delib 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xeg_eqdr 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xeg_eqprotec 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xel_frefair 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xel_regelec 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xme_altinf 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xnp_client 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xnp_regcorr 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xpe_exlecon 158230 missing: 15400 infinity: 0\n",
      "vdem_v2xpe_exlpol 158230 missing: 15400 infinity: 0\n",
      "vdem_v2xpe_exlgeo 158230 missing: 15400 infinity: 0\n",
      "vdem_v2xpe_exlgender 158230 missing: 15400 infinity: 0\n",
      "vdem_v2xpe_exlsocgr 158230 missing: 15400 infinity: 0\n",
      "vdem_v2xps_party 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xcs_ccsi 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xnp_pres 158230 missing: 15145 infinity: 0\n",
      "vdem_v2xeg_eqaccess 158230 missing: 15145 infinity: 0\n",
      "topics_002\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "wdi_sp_pop_totl 158230 missing: 0 infinity: 0\n",
      "topic_tokens_t1 158230 missing: 5 infinity: 0\n",
      "topic_tokens_t2 158230 missing: 5 infinity: 0\n",
      "topic_tokens_t13 158230 missing: 11 infinity: 0\n",
      "topic_ste_theta0_stock_t1 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta0_stock_t2 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta0_stock_t13 158230 missing: 11 infinity: 0\n",
      "topic_ste_theta1_stock_t1 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta1_stock_t2 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta1_stock_t13 158230 missing: 11 infinity: 0\n",
      "topic_ste_theta2_stock_t1 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta2_stock_t2 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta2_stock_t13 158230 missing: 11 infinity: 0\n",
      "topic_ste_theta3_stock_t1 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta3_stock_t2 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta3_stock_t13 158230 missing: 11 infinity: 0\n",
      "topic_ste_theta4_stock_t1 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta4_stock_t2 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta4_stock_t13 158230 missing: 11 infinity: 0\n",
      "topic_ste_theta5_stock_t1 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta5_stock_t2 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta5_stock_t13 158230 missing: 11 infinity: 0\n",
      "topic_ste_theta6_stock_t1 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta6_stock_t2 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta6_stock_t13 158230 missing: 11 infinity: 0\n",
      "topic_ste_theta7_stock_t1 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta7_stock_t2 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta7_stock_t13 158230 missing: 11 infinity: 0\n",
      "topic_ste_theta8_stock_t1 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta8_stock_t2 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta8_stock_t13 158230 missing: 11 infinity: 0\n",
      "topic_ste_theta9_stock_t1 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta9_stock_t2 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta9_stock_t13 158230 missing: 11 infinity: 0\n",
      "topic_ste_theta10_stock_t1 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta10_stock_t2 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta10_stock_t13 158230 missing: 11 infinity: 0\n",
      "topic_ste_theta11_stock_t1 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta11_stock_t2 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta11_stock_t13 158230 missing: 11 infinity: 0\n",
      "topic_ste_theta12_stock_t1 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta12_stock_t2 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta12_stock_t13 158230 missing: 11 infinity: 0\n",
      "topic_ste_theta13_stock_t1 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta13_stock_t2 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta13_stock_t13 158230 missing: 11 infinity: 0\n",
      "topic_ste_theta14_stock_t1 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta14_stock_t2 158230 missing: 5 infinity: 0\n",
      "topic_ste_theta14_stock_t13 158230 missing: 11 infinity: 0\n",
      "pca_all\n",
      "ln_ged_sb_dep 74507 missing: 0 infinity: 0\n",
      "ln_ged_sb 74507 missing: 0 infinity: 0\n",
      "decay_ged_sb_5 74507 missing: 0 infinity: 0\n",
      "decay_ged_os_5 74507 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 74507 missing: 0 infinity: 0\n",
      "wdi_sp_pop_totl 74507 missing: 0 infinity: 0\n",
      "pc1 74507 missing: 0 infinity: 0\n",
      "pc2 74507 missing: 0 infinity: 0\n",
      "pc3 74507 missing: 0 infinity: 0\n",
      "pc4 74507 missing: 0 infinity: 0\n",
      "pc5 74507 missing: 0 infinity: 0\n",
      "pc6 74507 missing: 0 infinity: 0\n",
      "pc7 74507 missing: 0 infinity: 0\n",
      "pc8 74507 missing: 0 infinity: 0\n",
      "pc9 74507 missing: 0 infinity: 0\n",
      "pc10 74507 missing: 0 infinity: 0\n",
      "pc11 74507 missing: 0 infinity: 0\n",
      "pc12 74507 missing: 0 infinity: 0\n",
      "pc13 74507 missing: 0 infinity: 0\n",
      "pc14 74507 missing: 0 infinity: 0\n",
      "pc15 74507 missing: 0 infinity: 0\n",
      "pc16 74507 missing: 0 infinity: 0\n",
      "pc17 74507 missing: 0 infinity: 0\n",
      "pc18 74507 missing: 0 infinity: 0\n",
      "pc19 74507 missing: 0 infinity: 0\n",
      "pc20 74507 missing: 0 infinity: 0\n",
      "pca_topics\n",
      "ln_ged_sb_dep 74507 missing: 0 infinity: 0\n",
      "ln_ged_sb 74507 missing: 0 infinity: 0\n",
      "decay_ged_sb_5 74507 missing: 0 infinity: 0\n",
      "decay_ged_os_5 74507 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 74507 missing: 0 infinity: 0\n",
      "wdi_sp_pop_totl 74507 missing: 0 infinity: 0\n",
      "pc1 74507 missing: 0 infinity: 0\n",
      "pc2 74507 missing: 0 infinity: 0\n",
      "pc3 74507 missing: 0 infinity: 0\n",
      "pc4 74507 missing: 0 infinity: 0\n",
      "pc5 74507 missing: 0 infinity: 0\n",
      "pc6 74507 missing: 0 infinity: 0\n",
      "pc7 74507 missing: 0 infinity: 0\n",
      "pc8 74507 missing: 0 infinity: 0\n",
      "pc9 74507 missing: 0 infinity: 0\n",
      "pc10 74507 missing: 0 infinity: 0\n",
      "pca_vdem\n",
      "ln_ged_sb_dep 74507 missing: 0 infinity: 0\n",
      "ln_ged_sb 74507 missing: 0 infinity: 0\n",
      "decay_ged_sb_5 74507 missing: 0 infinity: 0\n",
      "decay_ged_os_5 74507 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 74507 missing: 0 infinity: 0\n",
      "wdi_sp_pop_totl 74507 missing: 0 infinity: 0\n",
      "pc1 74507 missing: 0 infinity: 0\n",
      "pc2 74507 missing: 0 infinity: 0\n",
      "pc3 74507 missing: 0 infinity: 0\n",
      "pc4 74507 missing: 0 infinity: 0\n",
      "pc5 74507 missing: 0 infinity: 0\n",
      "pc6 74507 missing: 0 infinity: 0\n",
      "pc7 74507 missing: 0 infinity: 0\n",
      "pc8 74507 missing: 0 infinity: 0\n",
      "pc9 74507 missing: 0 infinity: 0\n",
      "pc10 74507 missing: 0 infinity: 0\n",
      "pc11 74507 missing: 0 infinity: 0\n",
      "pc12 74507 missing: 0 infinity: 0\n",
      "pc13 74507 missing: 0 infinity: 0\n",
      "pc14 74507 missing: 0 infinity: 0\n",
      "pc15 74507 missing: 0 infinity: 0\n",
      "pca_wdi\n",
      "ln_ged_sb_dep 74507 missing: 0 infinity: 0\n",
      "ln_ged_sb 74507 missing: 0 infinity: 0\n",
      "decay_ged_sb_5 74507 missing: 0 infinity: 0\n",
      "decay_ged_os_5 74507 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 74507 missing: 0 infinity: 0\n",
      "wdi_sp_pop_totl 74507 missing: 0 infinity: 0\n",
      "pc1 74507 missing: 0 infinity: 0\n",
      "pc2 74507 missing: 0 infinity: 0\n",
      "pc3 74507 missing: 0 infinity: 0\n",
      "pc4 74507 missing: 0 infinity: 0\n",
      "pc5 74507 missing: 0 infinity: 0\n",
      "pc6 74507 missing: 0 infinity: 0\n",
      "pc7 74507 missing: 0 infinity: 0\n",
      "pc8 74507 missing: 0 infinity: 0\n",
      "pc9 74507 missing: 0 infinity: 0\n",
      "pc10 74507 missing: 0 infinity: 0\n",
      "pc11 74507 missing: 0 infinity: 0\n",
      "pc12 74507 missing: 0 infinity: 0\n",
      "pc13 74507 missing: 0 infinity: 0\n",
      "pc14 74507 missing: 0 infinity: 0\n",
      "pc15 74507 missing: 0 infinity: 0\n"
     ]
    }
   ],
   "source": [
    "N=51\n",
    "for i in range(len(Datasets)):\n",
    "    df = Datasets[i]['df']\n",
    "    print(Datasets[i]['Name'])\n",
    "    for col in df.iloc[: , :N].columns:\n",
    "        print(col,len(df[col]), 'missing:', df[col].isnull().sum(), 'infinity:', np.isinf(df).values.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c761eb9c",
   "metadata": {},
   "source": [
    "# Specify models in ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "425514d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T13:38:37.259770Z",
     "start_time": "2024-03-28T13:38:37.124520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fatalities002_baseline_rf baseline002\n",
      "1 fatalities002_conflicthistory_rf conflict_ln\n",
      "2 fatalities002_conflicthistory_gbm conflict_ln\n",
      "3 fatalities002_conflicthistory_hurdle_lgb conflict_ln\n",
      "4 fatalities002_conflicthistory_long_xgb conflictlong_ln\n",
      "5 fatalities002_vdem_hurdle_xgb vdem_short\n",
      "6 fatalities002_wdi_rf wdi_short\n",
      "7 fatalities002_topics_rf topics_002\n",
      "8 fatalities002_topics_xgb topics_002\n",
      "9 fatalities002_topics_hurdle_lgb topics_002\n",
      "10 fatalities002_joint_broad_rf joint_broad\n",
      "11 fatalities002_joint_broad_hurdle_rf joint_broad\n",
      "12 fatalities002_joint_narrow_xgb joint_narrow\n",
      "13 fatalities002_joint_narrow_hurdle_xgb joint_narrow\n",
      "14 fatalities002_joint_narrow_hurdle_lgb joint_narrow\n",
      "15 fatalities002_all_pca3_xgb all_features\n",
      "16 fatalities002_aquastat_rf aquastat\n",
      "17 fatalities002_faostat_rf faostat\n",
      "18 fatalities002_faoprices_rf faoprices\n",
      "19 fatalities002_imfweo_rf imfweo\n",
      "20 fatalities002_Markov_glm joint_narrow\n",
      "21 fatalities002_Markov_rf joint_narrow\n"
     ]
    }
   ],
   "source": [
    "from ModelDefinitions import DefineEnsembleModels\n",
    "\n",
    "ModelList = DefineEnsembleModels('cm')\n",
    "    \n",
    "for imodel,model in enumerate(ModelList):\n",
    "    print(imodel, model['modelname'], model['data_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b1b6322",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T13:38:37.387976Z",
     "start_time": "2024-03-28T13:38:37.261558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'modelname': 'fatalities002_baseline_rf',\n  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n                 colsample_bylevel=None, colsample_bytree=None, device=None,\n                 early_stopping_rounds=None, enable_categorical=False,\n                 eval_metric=None, feature_types=None, gamma=None,\n                 grow_policy=None, importance_type=None,\n                 interaction_constraints=None, max_bin=None,\n                 max_cat_threshold=None, max_cat_to_onehot=None,\n                 max_delta_step=None, max_depth=None, max_leaves=None,\n                 min_child_weight=None, missing=nan, monotone_constraints=None,\n                 multi_strategy=None, n_estimators=300, n_jobs=12,\n                 num_parallel_tree=None, objective='reg:squarederror',\n                 random_state=None, reg_alpha=None, ...),\n  'depvar': 'ln_ged_sb_dep',\n  'data_train': 'baseline002',\n  'queryset': 'fatalities002_baseline',\n  'preprocessing': 'float_it',\n  'level': 'cm',\n  'description': 'Baseline model with a few conflict history features as well as log population, random forests regression model.',\n  'long_description': 'A very simple model with only five data columns (each column representing one feature): The number of fatalities in the same country at $t-1$, three decay functions of time since there was at least five fatalities in a single month, for each of the UCDP conflict types -- state-based, one-sided, or non-state conflict -- and log population size (Hegre2020RP,Pettersson2021JPR).The features in the baseline are included in all the models described below. This ensures that all models in the ensemble provides at least moderately good predictions, while guaranteeing diversity in feature sets and modelling approaches.',\n  'predstore_calib': 'cm_fatalities002_baseline_rf_calib',\n  'predstore_test': 'cm_fatalities002_baseline_rf_test'},\n {'modelname': 'fatalities002_conflicthistory_rf',\n  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n                 colsample_bylevel=None, colsample_bytree=None, device=None,\n                 early_stopping_rounds=None, enable_categorical=False,\n                 eval_metric=None, feature_types=None, gamma=None,\n                 grow_policy=None, importance_type=None,\n                 interaction_constraints=None, max_bin=None,\n                 max_cat_threshold=None, max_cat_to_onehot=None,\n                 max_delta_step=None, max_depth=None, max_leaves=None,\n                 min_child_weight=None, missing=nan, monotone_constraints=None,\n                 multi_strategy=None, n_estimators=250, n_jobs=12,\n                 num_parallel_tree=None, objective='reg:squarederror',\n                 random_state=None, reg_alpha=None, ...),\n  'depvar': 'ln_ged_sb_dep',\n  'data_train': 'conflict_ln',\n  'queryset': 'fatalities002_conflict_history',\n  'preprocessing': 'float_it',\n  'level': 'cm',\n  'description': 'A collection of variables that together map the conflict history of a country, random forests regression model.',\n  'long_description': 'A collection of variables that together map the conflict history of a country. The features include lagged dependent variables for each conflict type as coded by the UCDP (state-based, one-sided, or non-state) for up to each of the preceding six months, decay functions of time since conflict caused 5, 100, and 500 deaths in a month, for each type of violence, whether ACLED (https://doi.org/10.1177/0022343310378914 recorded similar violence, and whether there was recent violence in any neighboring countries.',\n  'predstore_calib': 'cm_fatalities002_conflicthistory_rf_calib',\n  'predstore_test': 'cm_fatalities002_conflicthistory_rf_test'},\n {'modelname': 'fatalities002_conflicthistory_gbm',\n  'algorithm': GradientBoostingRegressor(n_estimators=200),\n  'depvar': 'ln_ged_sb_dep',\n  'data_train': 'conflict_ln',\n  'queryset': 'fatalities002_conflict_history',\n  'preprocessing': 'float_it',\n  'level': 'cm',\n  'description': 'A collection of variables that together map the conflict history of a country, scikit gradient boosting regression model.',\n  'long_description': '',\n  'predstore_calib': 'cm_fatalities002_conflicthistory_gbm_calib',\n  'predstore_test': 'cm_fatalities002_conflicthistory_gbm_test'},\n {'modelname': 'fatalities002_conflicthistory_hurdle_lgb',\n  'algorithm': HurdleRegression(clf_name='LGBMClassifier', reg_name='LGBMRegressor'),\n  'depvar': 'ln_ged_sb_dep',\n  'data_train': 'conflict_ln',\n  'queryset': 'fatalities002_conflict_history',\n  'preprocessing': 'float_it',\n  'level': 'cm',\n  'description': '',\n  'long_description': '',\n  'predstore_calib': 'cm_fatalities002_conflicthistory_hurdle_lgb_calib',\n  'predstore_test': 'cm_fatalities002_conflicthistory_hurdle_lgb_test'},\n {'modelname': 'fatalities002_conflicthistory_long_xgb',\n  'algorithm': XGBRegressor(base_score=None, booster=None, callbacks=None,\n               colsample_bylevel=None, colsample_bynode=None,\n               colsample_bytree=None, device=None, early_stopping_rounds=None,\n               enable_categorical=False, eval_metric=None, feature_types=None,\n               gamma=None, grow_policy=None, importance_type=None,\n               interaction_constraints=None, learning_rate=0.05, max_bin=None,\n               max_cat_threshold=None, max_cat_to_onehot=None,\n               max_delta_step=None, max_depth=None, max_leaves=None,\n               min_child_weight=None, missing=nan, monotone_constraints=None,\n               multi_strategy=None, n_estimators=100, n_jobs=12,\n               num_parallel_tree=None, random_state=None, ...),\n  'depvar': 'ln_ged_sb_dep',\n  'data_train': 'conflictlong_ln',\n  'queryset': 'fatalities002_conflict_history_long',\n  'preprocessing': 'float_it',\n  'level': 'cm',\n  'description': '',\n  'long_description': '',\n  'predstore_calib': 'cm_fatalities002_conflicthistory_long_xgb_calib',\n  'predstore_test': 'cm_fatalities002_conflicthistory_long_xgb_test'},\n {'modelname': 'fatalities002_vdem_hurdle_xgb',\n  'algorithm': HurdleRegression(clf_name='XGBClassifier', reg_name='XGBRegressor'),\n  'depvar': 'ln_ged_sb_dep',\n  'data_train': 'vdem_short',\n  'queryset': 'fatalities002_vdem_short',\n  'preprocessing': 'float_it',\n  'level': 'cm',\n  'description': '',\n  'long_description': '',\n  'predstore_calib': 'cm_fatalities002_vdem_hurdle_xgb_calib',\n  'predstore_test': 'cm_fatalities002_vdem_hurdle_xgb_test'},\n {'modelname': 'fatalities002_wdi_rf',\n  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n                 colsample_bylevel=None, colsample_bytree=None, device=None,\n                 early_stopping_rounds=None, enable_categorical=False,\n                 eval_metric=None, feature_types=None, gamma=None,\n                 grow_policy=None, importance_type=None,\n                 interaction_constraints=None, max_bin=None,\n                 max_cat_threshold=None, max_cat_to_onehot=None,\n                 max_delta_step=None, max_depth=None, max_leaves=None,\n                 min_child_weight=None, missing=nan, monotone_constraints=None,\n                 multi_strategy=None, n_estimators=300, n_jobs=12,\n                 num_parallel_tree=None, objective='reg:squarederror',\n                 random_state=None, reg_alpha=None, ...),\n  'depvar': 'ln_ged_sb_dep',\n  'data_train': 'wdi_short',\n  'queryset': 'fatalities002_wdi_short',\n  'preprocessing': 'float_it',\n  'level': 'cm',\n  'description': '',\n  'long_description': '',\n  'predstore_calib': 'cm_fatalities002_wdi_rf_calib',\n  'predstore_test': 'cm_fatalities002_wdi_rf_test'},\n {'modelname': 'fatalities002_topics_rf',\n  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n                 colsample_bylevel=None, colsample_bytree=None, device=None,\n                 early_stopping_rounds=None, enable_categorical=False,\n                 eval_metric=None, feature_types=None, gamma=None,\n                 grow_policy=None, importance_type=None,\n                 interaction_constraints=None, max_bin=None,\n                 max_cat_threshold=None, max_cat_to_onehot=None,\n                 max_delta_step=None, max_depth=None, max_leaves=None,\n                 min_child_weight=None, missing=nan, monotone_constraints=None,\n                 multi_strategy=None, n_estimators=250, n_jobs=12,\n                 num_parallel_tree=None, objective='reg:squarederror',\n                 random_state=None, reg_alpha=None, ...),\n  'depvar': 'ln_ged_sb_dep',\n  'data_train': 'topics_002',\n  'queryset': 'fatalities002_topics',\n  'preprocessing': 'float_it',\n  'level': 'cm',\n  'description': '',\n  'long_description': '',\n  'predstore_calib': 'cm_fatalities002_topics_rf_calib',\n  'predstore_test': 'cm_fatalities002_topics_rf_test'},\n {'modelname': 'fatalities002_topics_xgb',\n  'algorithm': XGBRegressor(base_score=None, booster=None, callbacks=None,\n               colsample_bylevel=None, colsample_bynode=None,\n               colsample_bytree=None, device=None, early_stopping_rounds=None,\n               enable_categorical=False, eval_metric=None, feature_types=None,\n               gamma=None, grow_policy=None, importance_type=None,\n               interaction_constraints=None, learning_rate=0.05, max_bin=None,\n               max_cat_threshold=None, max_cat_to_onehot=None,\n               max_delta_step=None, max_depth=None, max_leaves=None,\n               min_child_weight=None, missing=nan, monotone_constraints=None,\n               multi_strategy=None, n_estimators=80, n_jobs=12,\n               num_parallel_tree=None, random_state=None, ...),\n  'depvar': 'ln_ged_sb_dep',\n  'data_train': 'topics_002',\n  'queryset': 'fatalities002_topics',\n  'preprocessing': 'float_it',\n  'level': 'cm',\n  'description': '',\n  'long_description': '',\n  'predstore_calib': 'cm_fatalities002_topics_xgb_calib',\n  'predstore_test': 'cm_fatalities002_topics_xgb_test'},\n {'modelname': 'fatalities002_topics_hurdle_lgb',\n  'algorithm': HurdleRegression(clf_name='LGBMClassifier', reg_name='LGBMRegressor'),\n  'depvar': 'ln_ged_sb_dep',\n  'data_train': 'topics_002',\n  'queryset': 'fatalities002_topics',\n  'preprocessing': 'float_it',\n  'level': 'cm',\n  'description': '',\n  'long_description': '',\n  'predstore_calib': 'cm_fatalities002_topics_hurdle_lgb_calib',\n  'predstore_test': 'cm_fatalities002_topics_hurdle_lgb_test'},\n {'modelname': 'fatalities002_joint_broad_rf',\n  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n                 colsample_bylevel=None, colsample_bytree=None, device=None,\n                 early_stopping_rounds=None, enable_categorical=False,\n                 eval_metric=None, feature_types=None, gamma=None,\n                 grow_policy=None, importance_type=None,\n                 interaction_constraints=None, max_bin=None,\n                 max_cat_threshold=None, max_cat_to_onehot=None,\n                 max_delta_step=None, max_depth=None, max_leaves=None,\n                 min_child_weight=None, missing=nan, monotone_constraints=None,\n                 multi_strategy=None, n_estimators=250, n_jobs=12,\n                 num_parallel_tree=None, objective='reg:squarederror',\n                 random_state=None, reg_alpha=None, ...),\n  'depvar': 'ln_ged_sb_dep',\n  'data_train': 'joint_broad',\n  'queryset': 'fatalities002_joint_broad',\n  'preprocessing': 'float_it',\n  'level': 'cm',\n  'description': '',\n  'long_description': '',\n  'predstore_calib': 'cm_fatalities002_joint_broad_rf_calib',\n  'predstore_test': 'cm_fatalities002_joint_broad_rf_test'},\n {'modelname': 'fatalities002_joint_broad_hurdle_rf',\n  'algorithm': HurdleRegression(clf_name='RFClassifier', reg_name='RFRegressor'),\n  'depvar': 'ln_ged_sb_dep',\n  'data_train': 'joint_broad',\n  'queryset': 'fatalities002_joint_broad',\n  'preprocessing': 'float_it',\n  'level': 'cm',\n  'description': '',\n  'long_description': '',\n  'predstore_calib': 'cm_fatalities002_joint_broad_hurdle_rf_calib',\n  'predstore_test': 'cm_fatalities002_joint_broad_hurdle_rf_test'},\n {'modelname': 'fatalities002_joint_narrow_xgb',\n  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n                 colsample_bylevel=None, colsample_bytree=None, device=None,\n                 early_stopping_rounds=None, enable_categorical=False,\n                 eval_metric=None, feature_types=None, gamma=None,\n                 grow_policy=None, importance_type=None,\n                 interaction_constraints=None, max_bin=None,\n                 max_cat_threshold=None, max_cat_to_onehot=None,\n                 max_delta_step=None, max_depth=None, max_leaves=None,\n                 min_child_weight=None, missing=nan, monotone_constraints=None,\n                 multi_strategy=None, n_estimators=250, n_jobs=12,\n                 num_parallel_tree=None, objective='reg:squarederror',\n                 random_state=None, reg_alpha=None, ...),\n  'depvar': 'ln_ged_sb_dep',\n  'data_train': 'joint_narrow',\n  'queryset': 'fatalities002_joint_narrow',\n  'preprocessing': 'float_it',\n  'level': 'cm',\n  'description': '',\n  'long_description': '',\n  'predstore_calib': 'cm_fatalities002_joint_narrow_xgb_calib',\n  'predstore_test': 'cm_fatalities002_joint_narrow_xgb_test'},\n {'modelname': 'fatalities002_joint_narrow_hurdle_xgb',\n  'algorithm': HurdleRegression(clf_name='XGBClassifier', reg_name='XGBRegressor'),\n  'depvar': 'ln_ged_sb_dep',\n  'data_train': 'joint_narrow',\n  'queryset': 'fatalities002_joint_narrow',\n  'preprocessing': 'float_it',\n  'level': 'cm',\n  'description': '',\n  'long_description': '',\n  'predstore_calib': 'cm_fatalities002_joint_narrow_hurdle_xgb_calib',\n  'predstore_test': 'cm_fatalities002_joint_narrow_hurdle_xgb_test'},\n {'modelname': 'fatalities002_joint_narrow_hurdle_lgb',\n  'algorithm': HurdleRegression(clf_name='LGBMClassifier', reg_name='LGBMRegressor'),\n  'depvar': 'ln_ged_sb_dep',\n  'data_train': 'joint_narrow',\n  'queryset': 'fatalities002_joint_narrow',\n  'preprocessing': 'float_it',\n  'level': 'cm',\n  'description': '',\n  'long_description': '',\n  'predstore_calib': 'cm_fatalities002_joint_narrow_hurdle_lgb_calib',\n  'predstore_test': 'cm_fatalities002_joint_narrow_hurdle_lgb_test'},\n {'modelname': 'fatalities002_all_pca3_xgb',\n  'algorithm': XGBRegressor(base_score=None, booster=None, callbacks=None,\n               colsample_bylevel=None, colsample_bynode=None,\n               colsample_bytree=None, device=None, early_stopping_rounds=None,\n               enable_categorical=False, eval_metric=None, feature_types=None,\n               gamma=None, grow_policy=None, importance_type=None,\n               interaction_constraints=None, learning_rate=0.05, max_bin=None,\n               max_cat_threshold=None, max_cat_to_onehot=None,\n               max_delta_step=None, max_depth=None, max_leaves=None,\n               min_child_weight=None, missing=nan, monotone_constraints=None,\n               multi_strategy=None, n_estimators=100, n_jobs=12,\n               num_parallel_tree=None, random_state=None, ...),\n  'depvar': 'ln_ged_sb_dep',\n  'data_train': 'all_features',\n  'queryset': 'fatalities002_all_features',\n  'preprocessing': 'pca_it',\n  'level': 'cm',\n  'description': '',\n  'long_description': '',\n  'predstore_calib': 'cm_fatalities002_all_pca3_xgb_calib',\n  'predstore_test': 'cm_fatalities002_all_pca3_xgb_test'},\n {'modelname': 'fatalities002_aquastat_rf',\n  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n                 colsample_bylevel=None, colsample_bytree=None, device=None,\n                 early_stopping_rounds=None, enable_categorical=False,\n                 eval_metric=None, feature_types=None, gamma=None,\n                 grow_policy=None, importance_type=None,\n                 interaction_constraints=None, max_bin=None,\n                 max_cat_threshold=None, max_cat_to_onehot=None,\n                 max_delta_step=None, max_depth=None, max_leaves=None,\n                 min_child_weight=None, missing=nan, monotone_constraints=None,\n                 multi_strategy=None, n_estimators=300, n_jobs=12,\n                 num_parallel_tree=None, objective='reg:squarederror',\n                 random_state=None, reg_alpha=None, ...),\n  'depvar': 'ln_ged_sb_dep',\n  'data_train': 'aquastat',\n  'queryset': 'fatalities002_aquastat',\n  'preprocessing': 'float_it',\n  'level': 'cm',\n  'description': '',\n  'long_description': '',\n  'predstore_calib': 'cm_fatalities002_aquastat_rf_calib',\n  'predstore_test': 'cm_fatalities002_aquastat_rf_test'},\n {'modelname': 'fatalities002_faostat_rf',\n  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n                 colsample_bylevel=None, colsample_bytree=None, device=None,\n                 early_stopping_rounds=None, enable_categorical=False,\n                 eval_metric=None, feature_types=None, gamma=None,\n                 grow_policy=None, importance_type=None,\n                 interaction_constraints=None, max_bin=None,\n                 max_cat_threshold=None, max_cat_to_onehot=None,\n                 max_delta_step=None, max_depth=None, max_leaves=None,\n                 min_child_weight=None, missing=nan, monotone_constraints=None,\n                 multi_strategy=None, n_estimators=300, n_jobs=12,\n                 num_parallel_tree=None, objective='reg:squarederror',\n                 random_state=None, reg_alpha=None, ...),\n  'depvar': 'ln_ged_sb_dep',\n  'data_train': 'faostat',\n  'queryset': 'fatalities002_faostat',\n  'preprocessing': 'float_it',\n  'level': 'cm',\n  'description': '',\n  'long_description': '',\n  'predstore_calib': 'cm_fatalities002_faostat_rf_calib',\n  'predstore_test': 'cm_fatalities002_faostat_rf_test'},\n {'modelname': 'fatalities002_faoprices_rf',\n  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n                 colsample_bylevel=None, colsample_bytree=None, device=None,\n                 early_stopping_rounds=None, enable_categorical=False,\n                 eval_metric=None, feature_types=None, gamma=None,\n                 grow_policy=None, importance_type=None,\n                 interaction_constraints=None, max_bin=None,\n                 max_cat_threshold=None, max_cat_to_onehot=None,\n                 max_delta_step=None, max_depth=None, max_leaves=None,\n                 min_child_weight=None, missing=nan, monotone_constraints=None,\n                 multi_strategy=None, n_estimators=300, n_jobs=12,\n                 num_parallel_tree=None, objective='reg:squarederror',\n                 random_state=None, reg_alpha=None, ...),\n  'depvar': 'ln_ged_sb_dep',\n  'data_train': 'faoprices',\n  'queryset': 'fatalities002_faoprices',\n  'preprocessing': 'float_it',\n  'level': 'cm',\n  'description': '',\n  'long_description': '',\n  'predstore_calib': 'cm_fatalities002_faoprices_rf_calib',\n  'predstore_test': 'cm_fatalities002_faoprices_rf_test'},\n {'modelname': 'fatalities002_imfweo_rf',\n  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n                 colsample_bylevel=None, colsample_bytree=None, device=None,\n                 early_stopping_rounds=None, enable_categorical=False,\n                 eval_metric=None, feature_types=None, gamma=None,\n                 grow_policy=None, importance_type=None,\n                 interaction_constraints=None, max_bin=None,\n                 max_cat_threshold=None, max_cat_to_onehot=None,\n                 max_delta_step=None, max_depth=None, max_leaves=None,\n                 min_child_weight=None, missing=nan, monotone_constraints=None,\n                 multi_strategy=None, n_estimators=300, n_jobs=12,\n                 num_parallel_tree=None, objective='reg:squarederror',\n                 random_state=None, reg_alpha=None, ...),\n  'depvar': 'ln_ged_sb_dep',\n  'data_train': 'imfweo',\n  'queryset': 'fatalities002_imfweo',\n  'preprocessing': 'float_it',\n  'level': 'cm',\n  'description': '',\n  'long_description': '',\n  'predstore_calib': 'cm_fatalities002_imfweo_rf_calib',\n  'predstore_test': 'cm_fatalities002_imfweo_rf_test'},\n {'modelname': 'fatalities002_Markov_glm',\n  'algorithm': 'rf',\n  'depvar': 'ln_ged_sb_dep',\n  'data_train': 'joint_narrow',\n  'queryset': 'fatalities002_joint_narrow',\n  'preprocessing': 'float_it',\n  'level': 'cm',\n  'description': '',\n  'long_description': '',\n  'predstore_calib': 'cm_fatalities002_Markov_glm_calib',\n  'predstore_test': 'cm_fatalities002_Markov_glm_test'},\n {'modelname': 'fatalities002_Markov_rf',\n  'algorithm': 'glm',\n  'depvar': 'ln_ged_sb_dep',\n  'data_train': 'joint_narrow',\n  'queryset': 'fatalities002_joint_narrow',\n  'preprocessing': 'float_it',\n  'level': 'cm',\n  'description': '',\n  'long_description': '',\n  'predstore_calib': 'cm_fatalities002_Markov_rf_calib',\n  'predstore_test': 'cm_fatalities002_Markov_rf_test'}]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "613b4f05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T13:38:37.625170Z",
     "start_time": "2024-03-28T13:38:37.390193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fatalities002_baseline_rf baseline002\n",
      "1 fatalities002_conflicthistory_rf conflict_ln\n",
      "2 fatalities002_conflicthistory_gbm conflict_ln\n",
      "3 fatalities002_conflicthistory_hurdle_lgb conflict_ln\n",
      "4 fatalities002_conflicthistory_long_xgb conflictlong_ln\n",
      "5 fatalities002_vdem_hurdle_xgb vdem_short\n",
      "6 fatalities002_wdi_rf wdi_short\n",
      "7 fatalities002_topics_rf topics_002\n",
      "8 fatalities002_topics_xgb topics_002\n",
      "9 fatalities002_topics_hurdle_lgb topics_002\n",
      "10 fatalities002_joint_broad_rf joint_broad\n",
      "11 fatalities002_joint_broad_hurdle_rf joint_broad\n",
      "12 fatalities002_joint_narrow_xgb joint_narrow\n",
      "13 fatalities002_joint_narrow_hurdle_xgb joint_narrow\n",
      "14 fatalities002_joint_narrow_hurdle_lgb joint_narrow\n",
      "15 fatalities002_all_pca3_xgb all_features\n",
      "16 fatalities002_aquastat_rf aquastat\n",
      "17 fatalities002_faostat_rf faostat\n",
      "18 fatalities002_faoprices_rf faoprices\n",
      "19 fatalities002_imfweo_rf imfweo\n",
      "20 fatalities002_Markov_glm joint_narrow\n",
      "21 fatalities002_Markov_rf joint_narrow\n"
     ]
    }
   ],
   "source": [
    "document_ensemble(ModelList,'sb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4d636ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T13:38:39.162164Z",
     "start_time": "2024-03-28T13:38:37.626821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imfweo imfweo_ngdp_rpch_tcurrent    0\n",
      "imfweo_ngdp_rpch_tmin1       0\n",
      "imfweo_ngdp_rpch_tplus1      0\n",
      "imfweo_ngdp_rpch_tplus2      0\n",
      "ln_ged_sb_dep                0\n",
      "ln_ged_sb                    0\n",
      "gleditsch_ward               0\n",
      "wdi_sp_pop_totl              0\n",
      "decay_ged_sb_5               0\n",
      "decay_ged_os_5               0\n",
      "splag_1_decay_ged_sb_5       0\n",
      "dtype: int64\n",
      "joint_narrow ln_ged_sb_dep                      0\n",
      "gleditsch_ward                     0\n",
      "ln_ged_sb                          0\n",
      "reign_tenure_months                0\n",
      "wdi_sp_pop_totl                 2242\n",
      "wdi_ag_lnd_frst_k2              2620\n",
      "wdi_nv_agr_totl_kn              5053\n",
      "wdi_sh_sta_maln_zs             30885\n",
      "wdi_sl_tlf_totl_fe_zs          11586\n",
      "wdi_sm_pop_refg_or              4664\n",
      "wdi_sp_dyn_imrt_in              2242\n",
      "wdi_sp_pop_14_fe_zs             2242\n",
      "wdi_sp_pop_grow                 2242\n",
      "vdem_v2xcl_dmove               15145\n",
      "vdem_v2xcl_rol                 15145\n",
      "vdem_v2xeg_eqdr                15145\n",
      "vdem_v2xpe_exlpol              15400\n",
      "vdem_v2xpe_exlsocgr            15400\n",
      "ln_ged_sb_tlag_1                   5\n",
      "ln_ged_sb_tlag_2                   5\n",
      "splag_wdi_ag_lnd_frst_k2           0\n",
      "splag_wdi_sl_tlf_totl_fe_zs        0\n",
      "splag_wdi_sm_pop_netm              0\n",
      "splag_vdem_v2xpe_exlsocgr          0\n",
      "splag_vdem_v2xcl_rol               0\n",
      "decay_ged_sb_5                     0\n",
      "decay_ged_os_5                     0\n",
      "decay_acled_os_5                   0\n",
      "decay_ged_sb_100                   0\n",
      "decay_ged_sb_500                   0\n",
      "splag_1_decay_ged_sb_5             0\n",
      "dtype: int64\n",
      "conflictlong_ln gleditsch_ward              0\n",
      "ln_ged_sb_dep               0\n",
      "ln_ged_sb                   0\n",
      "ln_ged_ns                   0\n",
      "ln_ged_os                   0\n",
      "                           ..\n",
      "splag_1_decay_ged_os_5      0\n",
      "splag_1_decay_ged_ns_5      0\n",
      "splag_1_decay_ged_sb_100    0\n",
      "splag_1_decay_ged_os_100    0\n",
      "splag_1_decay_ged_ns_100    0\n",
      "Length: 62, dtype: int64\n",
      "faoprices fao_wheat_price           0\n",
      "fao_mp_price              0\n",
      "fao_sugar_price           0\n",
      "fao_meat_price            0\n",
      "fao_milk_price            0\n",
      "ln_ged_sb_dep             0\n",
      "ln_ged_sb                 0\n",
      "gleditsch_ward            0\n",
      "delta_fao_wheat_price     0\n",
      "delta_fao_mp_price        0\n",
      "delta_fao_sugar_price     0\n",
      "delta_fao_meat_price      0\n",
      "delta_fao_milk_price      0\n",
      "wdi_sp_pop_totl           0\n",
      "decay_ged_sb_5            0\n",
      "decay_ged_os_5            0\n",
      "splag_1_decay_ged_sb_5    0\n",
      "dtype: int64\n",
      "baseline002 ln_ged_sb_dep             0\n",
      "ln_ged_sb                 0\n",
      "wdi_sp_pop_totl           0\n",
      "decay_ged_sb_5            0\n",
      "decay_ged_os_5            0\n",
      "splag_1_decay_ged_sb_5    0\n",
      "dtype: int64\n",
      "aquastat ln_ged_sb_dep                   0\n",
      "ln_ged_sb                       0\n",
      "wdi_sp_pop_totl                 0\n",
      "agr_withdrawal_pct_t48         32\n",
      "dam_cap_pcap_t48               32\n",
      "groundwater_export_t48         32\n",
      "fresh_withdrawal_pct_t48       32\n",
      "ind_efficiency_t48             32\n",
      "irr_agr_efficiency_t48         32\n",
      "services_efficiency_t48        32\n",
      "general_efficiency_t48         32\n",
      "water_stress_t48               32\n",
      "renewable_internal_pcap_t48    32\n",
      "renewable_pcap_t48             32\n",
      "decay_ged_sb_5                  0\n",
      "decay_ged_os_5                  0\n",
      "splag_1_decay_ged_sb_5          0\n",
      "dtype: int64\n",
      "joint_broad gleditsch_ward                     0\n",
      "ln_ged_sb_dep                      0\n",
      "ln_ged_sb                          0\n",
      "ln_ged_ns                          0\n",
      "ln_ged_os                          0\n",
      "                                  ..\n",
      "splag_1_decay_ged_sb_5             0\n",
      "splag_1_decay_ged_os_5             0\n",
      "splag_1_decay_ged_ns_5             0\n",
      "topic_ste_theta4_stock_t1_splag    0\n",
      "topic_ste_theta2_stock_t1_splag    0\n",
      "Length: 80, dtype: int64\n",
      "conflict_ln gleditsch_ward               0\n",
      "ln_ged_sb_dep                0\n",
      "ln_ged_sb                    0\n",
      "ln_ged_ns                    0\n",
      "ln_ged_os                    0\n",
      "ln_acled_sb               1437\n",
      "ln_acled_sb_count         1437\n",
      "ln_acled_os               1437\n",
      "wdi_sp_pop_totl              0\n",
      "ln_ged_sb_tlag_1             5\n",
      "ln_ged_sb_tlag_2             5\n",
      "ln_ged_sb_tlag_3             5\n",
      "ln_ged_sb_tlag_4             5\n",
      "ln_ged_sb_tlag_5             5\n",
      "ln_ged_sb_tlag_6            11\n",
      "ln_ged_sb_tsum_24            0\n",
      "ln_ged_os_tlag_1             5\n",
      "decay_ged_sb_5               0\n",
      "decay_ged_os_5               0\n",
      "decay_ged_sb_100             0\n",
      "decay_ged_sb_500             0\n",
      "decay_ged_os_100             0\n",
      "decay_ged_ns_5               0\n",
      "decay_ged_ns_100             0\n",
      "decay_acled_sb_5             0\n",
      "decay_acled_os_5             0\n",
      "decay_acled_ns_5             0\n",
      "splag_1_decay_ged_sb_5       0\n",
      "splag_1_decay_ged_os_5       0\n",
      "splag_1_decay_ged_ns_5       0\n",
      "dtype: int64\n",
      "all_features gleditsch_ward                      0\n",
      "ln_ged_sb_dep                       0\n",
      "ln_ged_sb                           0\n",
      "ln_ged_ns                           0\n",
      "ln_ged_os                           0\n",
      "                                   ..\n",
      "topic_ste_theta10_stock_t1_splag    0\n",
      "topic_ste_theta11_stock_t1_splag    0\n",
      "topic_ste_theta12_stock_t1_splag    0\n",
      "topic_ste_theta13_stock_t1_splag    0\n",
      "topic_ste_theta14_stock_t1_splag    0\n",
      "Length: 189, dtype: int64\n",
      "faostat ln_ged_sb_dep                         0\n",
      "ln_ged_sb                             0\n",
      "gleditsch_ward                        0\n",
      "consumer_prices_food_indices       1437\n",
      "consumer_prices_general_indices    1437\n",
      "food_price_inflation               1437\n",
      "avg_adequate_diet                  1437\n",
      "avg_animalprotein_pcap_day         1437\n",
      "avg_fprod_value                    1437\n",
      "avg_protein_pcap_day               1437\n",
      "gdp_pc_ppp                         1437\n",
      "kcal_pcap_day                      1437\n",
      "kcal_pcap_day_cerotu               1437\n",
      "pcap_fprod_var                     1437\n",
      "pcap_fsupply_var                   1437\n",
      "pct_arable_land                    1437\n",
      "pct_cereal_import                  1437\n",
      "pct_fimport_merch                  1437\n",
      "pct_modsevere_finsecurity          1437\n",
      "pct_pop_basicdrink                 1437\n",
      "pct_pop_basicsani                  1437\n",
      "pct_pop_safedrink                  1437\n",
      "pct_pop_safesani                   1437\n",
      "pct_severe_finsecurity             1437\n",
      "pct_und5_overweight                1437\n",
      "pct_und5_stunted                   1437\n",
      "pct_und5_wasting                   1437\n",
      "pct_undernourished                 1437\n",
      "pol_stability                      1437\n",
      "pop_modsevere_finsecurity          1437\n",
      "pop_severe_finsecurity             1437\n",
      "pop_undernourished                 1437\n",
      "prev_adult_obesity                 1437\n",
      "prev_infant_bfeed                  1437\n",
      "prev_lowbweight                    1437\n",
      "prev_repr_anemia                   1437\n",
      "rail_density                       1437\n",
      "wdi_sp_pop_totl                       0\n",
      "decay_ged_sb_5                        0\n",
      "decay_ged_os_5                        0\n",
      "splag_1_decay_ged_sb_5                0\n",
      "dtype: int64\n",
      "wdi_short ln_ged_sb_dep                      0\n",
      "ln_ged_sb                          0\n",
      "wdi_ag_lnd_frst_k2              2620\n",
      "wdi_dt_oda_odat_pc_zs          29607\n",
      "wdi_ms_mil_xpnd_gd_zs          24108\n",
      "wdi_ms_mil_xpnd_zs             28621\n",
      "wdi_nv_agr_totl_kd              6597\n",
      "wdi_nv_agr_totl_kn              5053\n",
      "wdi_ny_gdp_pcap_kd              4071\n",
      "wdi_sp_dyn_le00_in              3094\n",
      "wdi_se_enr_prim_fm_zs           3448\n",
      "wdi_se_enr_prsc_fm_zs           5152\n",
      "wdi_se_prm_nenr                 6365\n",
      "wdi_sh_sta_maln_zs             30885\n",
      "wdi_sh_sta_stnt_zs             30885\n",
      "wdi_sl_tlf_totl_fe_zs          11586\n",
      "wdi_sm_pop_refg_or              4664\n",
      "wdi_sm_pop_netm                 2242\n",
      "wdi_sm_pop_totl_zs              2641\n",
      "wdi_sp_dyn_imrt_in              2242\n",
      "wdi_sh_dyn_mort_fe              2242\n",
      "wdi_sp_pop_14_fe_zs             2242\n",
      "wdi_sp_pop_1564_fe_zs           2242\n",
      "wdi_sp_pop_65up_fe_zs           2242\n",
      "wdi_sp_pop_grow                 2242\n",
      "wdi_sp_urb_totl_in_zs           2242\n",
      "wdi_sp_pop_totl                    0\n",
      "splag_wdi_sl_tlf_totl_fe_zs        0\n",
      "splag_wdi_sm_pop_refg_or           0\n",
      "splag_wdi_sm_pop_netm              0\n",
      "splag_wdi_ag_lnd_frst_k2           0\n",
      "decay_ged_sb_5                     0\n",
      "decay_ged_os_5                     0\n",
      "splag_1_decay_ged_sb_5             0\n",
      "dtype: int64\n",
      "vdem_short ln_ged_sb_dep                    0\n",
      "ln_ged_sb                        0\n",
      "vdem_v2x_delibdem            15145\n",
      "vdem_v2x_egaldem             15145\n",
      "vdem_v2x_libdem              15145\n",
      "                             ...  \n",
      "splag_vdem_v2xpe_exlsocgr        0\n",
      "splag_vdem_v2xcl_rol             0\n",
      "decay_ged_sb_5                   0\n",
      "decay_ged_os_5                   0\n",
      "splag_1_decay_ged_sb_5           0\n",
      "Length: 64, dtype: int64\n",
      "topics_002 ln_ged_sb_dep                       0\n",
      "ln_ged_sb                           0\n",
      "wdi_sp_pop_totl                     0\n",
      "topic_tokens_t1                     5\n",
      "topic_tokens_t2                     5\n",
      "                                   ..\n",
      "topic_ste_theta10_stock_t1_splag    0\n",
      "topic_ste_theta11_stock_t1_splag    0\n",
      "topic_ste_theta12_stock_t1_splag    0\n",
      "topic_ste_theta13_stock_t1_splag    0\n",
      "topic_ste_theta14_stock_t1_splag    0\n",
      "Length: 70, dtype: int64\n",
      "pca_all ln_ged_sb_dep             0\n",
      "ln_ged_sb                 0\n",
      "decay_ged_sb_5            0\n",
      "decay_ged_os_5            0\n",
      "splag_1_decay_ged_sb_5    0\n",
      "wdi_sp_pop_totl           0\n",
      "pc1                       0\n",
      "pc2                       0\n",
      "pc3                       0\n",
      "pc4                       0\n",
      "pc5                       0\n",
      "pc6                       0\n",
      "pc7                       0\n",
      "pc8                       0\n",
      "pc9                       0\n",
      "pc10                      0\n",
      "pc11                      0\n",
      "pc12                      0\n",
      "pc13                      0\n",
      "pc14                      0\n",
      "pc15                      0\n",
      "pc16                      0\n",
      "pc17                      0\n",
      "pc18                      0\n",
      "pc19                      0\n",
      "pc20                      0\n",
      "dtype: int64\n",
      "pca_topics ln_ged_sb_dep             0\n",
      "ln_ged_sb                 0\n",
      "decay_ged_sb_5            0\n",
      "decay_ged_os_5            0\n",
      "splag_1_decay_ged_sb_5    0\n",
      "wdi_sp_pop_totl           0\n",
      "pc1                       0\n",
      "pc2                       0\n",
      "pc3                       0\n",
      "pc4                       0\n",
      "pc5                       0\n",
      "pc6                       0\n",
      "pc7                       0\n",
      "pc8                       0\n",
      "pc9                       0\n",
      "pc10                      0\n",
      "dtype: int64\n",
      "pca_vdem ln_ged_sb_dep             0\n",
      "ln_ged_sb                 0\n",
      "decay_ged_sb_5            0\n",
      "decay_ged_os_5            0\n",
      "splag_1_decay_ged_sb_5    0\n",
      "wdi_sp_pop_totl           0\n",
      "pc1                       0\n",
      "pc2                       0\n",
      "pc3                       0\n",
      "pc4                       0\n",
      "pc5                       0\n",
      "pc6                       0\n",
      "pc7                       0\n",
      "pc8                       0\n",
      "pc9                       0\n",
      "pc10                      0\n",
      "pc11                      0\n",
      "pc12                      0\n",
      "pc13                      0\n",
      "pc14                      0\n",
      "pc15                      0\n",
      "dtype: int64\n",
      "pca_wdi ln_ged_sb_dep             0\n",
      "ln_ged_sb                 0\n",
      "decay_ged_sb_5            0\n",
      "decay_ged_os_5            0\n",
      "splag_1_decay_ged_sb_5    0\n",
      "wdi_sp_pop_totl           0\n",
      "pc1                       0\n",
      "pc2                       0\n",
      "pc3                       0\n",
      "pc4                       0\n",
      "pc5                       0\n",
      "pc6                       0\n",
      "pc7                       0\n",
      "pc8                       0\n",
      "pc9                       0\n",
      "pc10                      0\n",
      "pc11                      0\n",
      "pc12                      0\n",
      "pc13                      0\n",
      "pc14                      0\n",
      "pc15                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for ds in Datasets:\n",
    "    df = ds['df']\n",
    "    print(ds['Name'],df.isna().sum())\n",
    "    ds['df']=df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10c58f37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T15:41:00.096968Z",
     "start_time": "2024-03-28T13:38:39.166175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fatalities002_baseline_rf\n",
      "Calibration partition 2024-03-28 14:38:39.265577\n",
      " * == Performing a run: \"fatalities002_baseline_rf_calib\" == * \n",
      "Model object named \"fatalities002_baseline_rf_calib\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_baseline_rf_calib\"\n",
      "Training model(s)...\n",
      "Storing \"fatalities002_baseline_rf_calib\"\n",
      "cm_fatalities002_baseline_rf_calib , run Fatalities002 force_rewrite=True, predicting\n",
      "Test partition 2024-03-28 14:39:35.819056\n",
      " * == Performing a run: \"fatalities002_baseline_rf_test\" == * \n",
      "Model object named \"fatalities002_baseline_rf_test\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_baseline_rf_test\"\n",
      "Training model(s)...\n",
      "Storing \"fatalities002_baseline_rf_test\"\n",
      "cm_fatalities002_baseline_rf_test , run Fatalities002 force_rewrite=True, predicting\n",
      "1 fatalities002_conflicthistory_rf\n",
      "Calibration partition 2024-03-28 14:40:35.909058\n",
      " * == Performing a run: \"fatalities002_conflicthistory_rf_calib\" == * \n",
      "Model object named \"fatalities002_conflicthistory_rf_calib\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_conflicthistory_rf_calib\"\n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities002_conflicthistory_rf_calib\"\n",
      "cm_fatalities002_conflicthistory_rf_calib , run Fatalities002 force_rewrite=True, predicting\n",
      "Test partition 2024-03-28 14:41:46.165731\n",
      " * == Performing a run: \"fatalities002_conflicthistory_rf_test\" == * \n",
      "Model object named \"fatalities002_conflicthistory_rf_test\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_conflicthistory_rf_test\"\n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities002_conflicthistory_rf_test\"\n",
      "cm_fatalities002_conflicthistory_rf_test , run Fatalities002 force_rewrite=True, predicting\n",
      "2 fatalities002_conflicthistory_gbm\n",
      "Calibration partition 2024-03-28 14:42:59.023648\n",
      " * == Performing a run: \"fatalities002_conflicthistory_gbm_calib\" == * \n",
      "Model object named \"fatalities002_conflicthistory_gbm_calib\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_conflicthistory_gbm_calib\"\n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities002_conflicthistory_gbm_calib\"\n",
      "cm_fatalities002_conflicthistory_gbm_calib , run Fatalities002 force_rewrite=True, predicting\n",
      "Test partition 2024-03-28 14:58:36.495449\n",
      " * == Performing a run: \"fatalities002_conflicthistory_gbm_test\" == * \n",
      "Model object named \"fatalities002_conflicthistory_gbm_test\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_conflicthistory_gbm_test\"\n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities002_conflicthistory_gbm_test\"\n",
      "cm_fatalities002_conflicthistory_gbm_test , run Fatalities002 force_rewrite=True, predicting\n",
      "3 fatalities002_conflicthistory_hurdle_lgb\n",
      "Calibration partition 2024-03-28 15:18:01.900232\n",
      " * == Performing a run: \"fatalities002_conflicthistory_hurdle_lgb_calib\" == * \n",
      "Model object named \"fatalities002_conflicthistory_hurdle_lgb_calib\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_conflicthistory_hurdle_lgb_calib\"\n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5545, number of negative: 41061\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7025\n",
      "[LightGBM] [Info] Number of data points in the train set: 46606, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118976 -> initscore=-2.002162\n",
      "[LightGBM] [Info] Start training from score -2.002162\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6260\n",
      "[LightGBM] [Info] Number of data points in the train set: 5545, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.391455\n",
      "[LightGBM] [Info] Number of positive: 5519, number of negative: 40881\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7024\n",
      "[LightGBM] [Info] Number of data points in the train set: 46400, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118944 -> initscore=-2.002469\n",
      "[LightGBM] [Info] Start training from score -2.002469\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6259\n",
      "[LightGBM] [Info] Number of data points in the train set: 5519, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.387713\n",
      "[LightGBM] [Info] Number of positive: 5488, number of negative: 40706\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7026\n",
      "[LightGBM] [Info] Number of data points in the train set: 46194, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118803 -> initscore=-2.003812\n",
      "[LightGBM] [Info] Start training from score -2.003812\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6151\n",
      "[LightGBM] [Info] Number of data points in the train set: 5488, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.386294\n",
      "[LightGBM] [Info] Number of positive: 5458, number of negative: 40531\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7026\n",
      "[LightGBM] [Info] Number of data points in the train set: 45989, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118681 -> initscore=-2.004985\n",
      "[LightGBM] [Info] Start training from score -2.004985\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6244\n",
      "[LightGBM] [Info] Number of data points in the train set: 5458, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.384750\n",
      "[LightGBM] [Info] Number of positive: 5429, number of negative: 40355\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7021\n",
      "[LightGBM] [Info] Number of data points in the train set: 45784, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118579 -> initscore=-2.005960\n",
      "[LightGBM] [Info] Start training from score -2.005960\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6255\n",
      "[LightGBM] [Info] Number of data points in the train set: 5429, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.384959\n",
      "[LightGBM] [Info] Number of positive: 5401, number of negative: 40180\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7022\n",
      "[LightGBM] [Info] Number of data points in the train set: 45581, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118492 -> initscore=-2.006785\n",
      "[LightGBM] [Info] Start training from score -2.006785\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6141\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.383308\n",
      "[LightGBM] [Info] Number of positive: 5374, number of negative: 40005\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7018\n",
      "[LightGBM] [Info] Number of data points in the train set: 45379, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118425 -> initscore=-2.007432\n",
      "[LightGBM] [Info] Start training from score -2.007432\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6144\n",
      "[LightGBM] [Info] Number of data points in the train set: 5374, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.380362\n",
      "[LightGBM] [Info] Number of positive: 5344, number of negative: 39833\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6937\n",
      "[LightGBM] [Info] Number of data points in the train set: 45177, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118290 -> initscore=-2.008721\n",
      "[LightGBM] [Info] Start training from score -2.008721\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6131\n",
      "[LightGBM] [Info] Number of data points in the train set: 5344, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.379547\n",
      "[LightGBM] [Info] Number of positive: 5311, number of negative: 39664\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6936\n",
      "[LightGBM] [Info] Number of data points in the train set: 44975, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118088 -> initscore=-2.010664\n",
      "[LightGBM] [Info] Start training from score -2.010664\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6144\n",
      "[LightGBM] [Info] Number of data points in the train set: 5311, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.380101\n",
      "[LightGBM] [Info] Number of positive: 5281, number of negative: 39492\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6929\n",
      "[LightGBM] [Info] Number of data points in the train set: 44773, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117951 -> initscore=-2.011983\n",
      "[LightGBM] [Info] Start training from score -2.011983\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6145\n",
      "[LightGBM] [Info] Number of data points in the train set: 5281, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.376092\n",
      "[LightGBM] [Info] Number of positive: 5252, number of negative: 39321\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6929\n",
      "[LightGBM] [Info] Number of data points in the train set: 44573, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117829 -> initscore=-2.013150\n",
      "[LightGBM] [Info] Start training from score -2.013150\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6135\n",
      "[LightGBM] [Info] Number of data points in the train set: 5252, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.375903\n",
      "[LightGBM] [Info] Number of positive: 5218, number of negative: 39155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6926\n",
      "[LightGBM] [Info] Number of data points in the train set: 44373, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117594 -> initscore=-2.015414\n",
      "[LightGBM] [Info] Start training from score -2.015414\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6122\n",
      "[LightGBM] [Info] Number of data points in the train set: 5218, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.375498\n",
      "[LightGBM] [Info] Number of positive: 5188, number of negative: 38985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6926\n",
      "[LightGBM] [Info] Number of data points in the train set: 44173, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117447 -> initscore=-2.016829\n",
      "[LightGBM] [Info] Start training from score -2.016829\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6128\n",
      "[LightGBM] [Info] Number of data points in the train set: 5188, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.375122\n",
      "[LightGBM] [Info] Number of positive: 5162, number of negative: 38811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002768 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6927\n",
      "[LightGBM] [Info] Number of data points in the train set: 43973, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117390 -> initscore=-2.017380\n",
      "[LightGBM] [Info] Start training from score -2.017380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6118\n",
      "[LightGBM] [Info] Number of data points in the train set: 5162, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.372283\n",
      "[LightGBM] [Info] Number of positive: 5132, number of negative: 38641\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6925\n",
      "[LightGBM] [Info] Number of data points in the train set: 43773, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117241 -> initscore=-2.018818\n",
      "[LightGBM] [Info] Start training from score -2.018818\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6111\n",
      "[LightGBM] [Info] Number of data points in the train set: 5132, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.371381\n",
      "[LightGBM] [Info] Number of positive: 5100, number of negative: 38473\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6919\n",
      "[LightGBM] [Info] Number of data points in the train set: 43573, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117045 -> initscore=-2.020716\n",
      "[LightGBM] [Info] Start training from score -2.020716\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6115\n",
      "[LightGBM] [Info] Number of data points in the train set: 5100, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.368761\n",
      "[LightGBM] [Info] Number of positive: 5069, number of negative: 38304\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6920\n",
      "[LightGBM] [Info] Number of data points in the train set: 43373, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116870 -> initscore=-2.022411\n",
      "[LightGBM] [Info] Start training from score -2.022411\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6129\n",
      "[LightGBM] [Info] Number of data points in the train set: 5069, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.366348\n",
      "[LightGBM] [Info] Number of positive: 5044, number of negative: 38129\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6917\n",
      "[LightGBM] [Info] Number of data points in the train set: 43173, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116832 -> initscore=-2.022776\n",
      "[LightGBM] [Info] Start training from score -2.022776\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6131\n",
      "[LightGBM] [Info] Number of data points in the train set: 5044, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.364531\n",
      "[LightGBM] [Info] Number of positive: 5022, number of negative: 37951\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6915\n",
      "[LightGBM] [Info] Number of data points in the train set: 42973, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116864 -> initscore=-2.022468\n",
      "[LightGBM] [Info] Start training from score -2.022468\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6122\n",
      "[LightGBM] [Info] Number of data points in the train set: 5022, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.362757\n",
      "[LightGBM] [Info] Number of positive: 4995, number of negative: 37778\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6916\n",
      "[LightGBM] [Info] Number of data points in the train set: 42773, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116779 -> initscore=-2.023290\n",
      "[LightGBM] [Info] Start training from score -2.023290\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4995, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.360102\n",
      "[LightGBM] [Info] Number of positive: 4966, number of negative: 37608\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6914\n",
      "[LightGBM] [Info] Number of data points in the train set: 42574, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116644 -> initscore=-2.024602\n",
      "[LightGBM] [Info] Start training from score -2.024602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6121\n",
      "[LightGBM] [Info] Number of data points in the train set: 4966, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.360760\n",
      "[LightGBM] [Info] Number of positive: 4939, number of negative: 37437\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6914\n",
      "[LightGBM] [Info] Number of data points in the train set: 42376, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116552 -> initscore=-2.025497\n",
      "[LightGBM] [Info] Start training from score -2.025497\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6123\n",
      "[LightGBM] [Info] Number of data points in the train set: 4939, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.358953\n",
      "[LightGBM] [Info] Number of positive: 4907, number of negative: 37271\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6914\n",
      "[LightGBM] [Info] Number of data points in the train set: 42178, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116340 -> initscore=-2.027553\n",
      "[LightGBM] [Info] Start training from score -2.027553\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6113\n",
      "[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.357955\n",
      "[LightGBM] [Info] Number of positive: 4876, number of negative: 37105\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002799 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6817\n",
      "[LightGBM] [Info] Number of data points in the train set: 41981, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116148 -> initscore=-2.029427\n",
      "[LightGBM] [Info] Start training from score -2.029427\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6112\n",
      "[LightGBM] [Info] Number of data points in the train set: 4876, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.357032\n",
      "[LightGBM] [Info] Number of positive: 4848, number of negative: 36936\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6815\n",
      "[LightGBM] [Info] Number of data points in the train set: 41784, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116025 -> initscore=-2.030620\n",
      "[LightGBM] [Info] Start training from score -2.030620\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6104\n",
      "[LightGBM] [Info] Number of data points in the train set: 4848, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.355826\n",
      "[LightGBM] [Info] Number of positive: 4818, number of negative: 36769\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6816\n",
      "[LightGBM] [Info] Number of data points in the train set: 41587, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115854 -> initscore=-2.032296\n",
      "[LightGBM] [Info] Start training from score -2.032296\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6115\n",
      "[LightGBM] [Info] Number of data points in the train set: 4818, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.356424\n",
      "[LightGBM] [Info] Number of positive: 4792, number of negative: 36598\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002986 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6817\n",
      "[LightGBM] [Info] Number of data points in the train set: 41390, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115777 -> initscore=-2.033046\n",
      "[LightGBM] [Info] Start training from score -2.033046\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6120\n",
      "[LightGBM] [Info] Number of data points in the train set: 4792, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.356996\n",
      "[LightGBM] [Info] Number of positive: 4768, number of negative: 36425\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6813\n",
      "[LightGBM] [Info] Number of data points in the train set: 41193, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115748 -> initscore=-2.033328\n",
      "[LightGBM] [Info] Start training from score -2.033328\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6124\n",
      "[LightGBM] [Info] Number of data points in the train set: 4768, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.358757\n",
      "[LightGBM] [Info] Number of positive: 4747, number of negative: 36249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6808\n",
      "[LightGBM] [Info] Number of data points in the train set: 40996, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115792 -> initscore=-2.032899\n",
      "[LightGBM] [Info] Start training from score -2.032899\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6120\n",
      "[LightGBM] [Info] Number of data points in the train set: 4747, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.357227\n",
      "[LightGBM] [Info] Number of positive: 4725, number of negative: 36074\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6807\n",
      "[LightGBM] [Info] Number of data points in the train set: 40799, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115812 -> initscore=-2.032705\n",
      "[LightGBM] [Info] Start training from score -2.032705\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6114\n",
      "[LightGBM] [Info] Number of data points in the train set: 4725, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.356150\n",
      "[LightGBM] [Info] Number of positive: 4702, number of negative: 35900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6805\n",
      "[LightGBM] [Info] Number of data points in the train set: 40602, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115807 -> initscore=-2.032749\n",
      "[LightGBM] [Info] Start training from score -2.032749\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6115\n",
      "[LightGBM] [Info] Number of data points in the train set: 4702, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.357821\n",
      "[LightGBM] [Info] Number of positive: 4676, number of negative: 35729\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6802\n",
      "[LightGBM] [Info] Number of data points in the train set: 40405, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115728 -> initscore=-2.033520\n",
      "[LightGBM] [Info] Start training from score -2.033520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000919 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6114\n",
      "[LightGBM] [Info] Number of data points in the train set: 4676, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.359241\n",
      "[LightGBM] [Info] Number of positive: 4648, number of negative: 35560\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6800\n",
      "[LightGBM] [Info] Number of data points in the train set: 40208, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115599 -> initscore=-2.034784\n",
      "[LightGBM] [Info] Start training from score -2.034784\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6103\n",
      "[LightGBM] [Info] Number of data points in the train set: 4648, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.360724\n",
      "[LightGBM] [Info] Number of positive: 4624, number of negative: 35387\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6799\n",
      "[LightGBM] [Info] Number of data points in the train set: 40011, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115568 -> initscore=-2.035084\n",
      "[LightGBM] [Info] Start training from score -2.035084\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6099\n",
      "[LightGBM] [Info] Number of data points in the train set: 4624, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.361289\n",
      "[LightGBM] [Info] Number of positive: 4602, number of negative: 35214\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6796\n",
      "[LightGBM] [Info] Number of data points in the train set: 39816, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115582 -> initscore=-2.034953\n",
      "[LightGBM] [Info] Start training from score -2.034953\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6098\n",
      "[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.361227\n",
      "[LightGBM] [Info] Number of positive: 4574, number of negative: 35047\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002748 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6798\n",
      "[LightGBM] [Info] Number of data points in the train set: 39621, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115444 -> initscore=-2.036302\n",
      "[LightGBM] [Info] Start training from score -2.036302\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6106\n",
      "[LightGBM] [Info] Number of data points in the train set: 4574, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.361714\n",
      "Storing \"fatalities002_conflicthistory_hurdle_lgb_calib\"\n",
      "cm_fatalities002_conflicthistory_hurdle_lgb_calib , run Fatalities002 force_rewrite=True, predicting\n",
      "Test partition 2024-03-28 15:18:57.231930\n",
      " * == Performing a run: \"fatalities002_conflicthistory_hurdle_lgb_test\" == * \n",
      "Model object named \"fatalities002_conflicthistory_hurdle_lgb_test\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_conflicthistory_hurdle_lgb_test\"\n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6659, number of negative: 49108\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002804 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7074\n",
      "[LightGBM] [Info] Number of data points in the train set: 55767, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.119408 -> initscore=-1.998053\n",
      "[LightGBM] [Info] Start training from score -1.998053\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6479\n",
      "[LightGBM] [Info] Number of data points in the train set: 6659, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.416581\n",
      "[LightGBM] [Info] Number of positive: 6631, number of negative: 48928\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7074\n",
      "[LightGBM] [Info] Number of data points in the train set: 55559, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.119351 -> initscore=-1.998594\n",
      "[LightGBM] [Info] Start training from score -1.998594\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6466\n",
      "[LightGBM] [Info] Number of data points in the train set: 6631, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.413810\n",
      "[LightGBM] [Info] Number of positive: 6598, number of negative: 48753\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7074\n",
      "[LightGBM] [Info] Number of data points in the train set: 55351, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.119203 -> initscore=-2.000000\n",
      "[LightGBM] [Info] Start training from score -2.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6496\n",
      "[LightGBM] [Info] Number of data points in the train set: 6598, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.412819\n",
      "[LightGBM] [Info] Number of positive: 6566, number of negative: 48578\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7071\n",
      "[LightGBM] [Info] Number of data points in the train set: 55144, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.119070 -> initscore=-2.001266\n",
      "[LightGBM] [Info] Start training from score -2.001266\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6493\n",
      "[LightGBM] [Info] Number of data points in the train set: 6566, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.411518\n",
      "[LightGBM] [Info] Number of positive: 6535, number of negative: 48402\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7070\n",
      "[LightGBM] [Info] Number of data points in the train set: 54937, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118954 -> initscore=-2.002369\n",
      "[LightGBM] [Info] Start training from score -2.002369\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6499\n",
      "[LightGBM] [Info] Number of data points in the train set: 6535, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.412013\n",
      "[LightGBM] [Info] Number of positive: 6505, number of negative: 48227\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7068\n",
      "[LightGBM] [Info] Number of data points in the train set: 54732, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118852 -> initscore=-2.003348\n",
      "[LightGBM] [Info] Start training from score -2.003348\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6495\n",
      "[LightGBM] [Info] Number of data points in the train set: 6505, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.410588\n",
      "[LightGBM] [Info] Number of positive: 6477, number of negative: 48051\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7069\n",
      "[LightGBM] [Info] Number of data points in the train set: 54528, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118783 -> initscore=-2.004006\n",
      "[LightGBM] [Info] Start training from score -2.004006\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6491\n",
      "[LightGBM] [Info] Number of data points in the train set: 6477, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.408126\n",
      "[LightGBM] [Info] Number of positive: 6446, number of negative: 47878\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7070\n",
      "[LightGBM] [Info] Number of data points in the train set: 54324, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118658 -> initscore=-2.005196\n",
      "[LightGBM] [Info] Start training from score -2.005196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6485\n",
      "[LightGBM] [Info] Number of data points in the train set: 6446, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.407298\n",
      "[LightGBM] [Info] Number of positive: 6411, number of negative: 47709\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7069\n",
      "[LightGBM] [Info] Number of data points in the train set: 54120, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118459 -> initscore=-2.007105\n",
      "[LightGBM] [Info] Start training from score -2.007105\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6480\n",
      "[LightGBM] [Info] Number of data points in the train set: 6411, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.407403\n",
      "[LightGBM] [Info] Number of positive: 6379, number of negative: 47537\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7069\n",
      "[LightGBM] [Info] Number of data points in the train set: 53916, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118314 -> initscore=-2.008497\n",
      "[LightGBM] [Info] Start training from score -2.008497\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6486\n",
      "[LightGBM] [Info] Number of data points in the train set: 6379, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.403711\n",
      "[LightGBM] [Info] Number of positive: 6348, number of negative: 47366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7069\n",
      "[LightGBM] [Info] Number of data points in the train set: 53714, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118181 -> initscore=-2.009765\n",
      "[LightGBM] [Info] Start training from score -2.009765\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6490\n",
      "[LightGBM] [Info] Number of data points in the train set: 6348, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.403675\n",
      "[LightGBM] [Info] Number of positive: 6313, number of negative: 47199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7065\n",
      "[LightGBM] [Info] Number of data points in the train set: 53512, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117974 -> initscore=-2.011762\n",
      "[LightGBM] [Info] Start training from score -2.011762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6489\n",
      "[LightGBM] [Info] Number of data points in the train set: 6313, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.403394\n",
      "[LightGBM] [Info] Number of positive: 6282, number of negative: 47028\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7066\n",
      "[LightGBM] [Info] Number of data points in the train set: 53310, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117839 -> initscore=-2.013055\n",
      "[LightGBM] [Info] Start training from score -2.013055\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6491\n",
      "[LightGBM] [Info] Number of data points in the train set: 6282, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.402993\n",
      "[LightGBM] [Info] Number of positive: 6255, number of negative: 46853\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7066\n",
      "[LightGBM] [Info] Number of data points in the train set: 53108, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117779 -> initscore=-2.013634\n",
      "[LightGBM] [Info] Start training from score -2.013634\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6395\n",
      "[LightGBM] [Info] Number of data points in the train set: 6255, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.400724\n",
      "[LightGBM] [Info] Number of positive: 6224, number of negative: 46682\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7064\n",
      "[LightGBM] [Info] Number of data points in the train set: 52906, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117643 -> initscore=-2.014946\n",
      "[LightGBM] [Info] Start training from score -2.014946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6387\n",
      "[LightGBM] [Info] Number of data points in the train set: 6224, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.399727\n",
      "[LightGBM] [Info] Number of positive: 6190, number of negative: 46514\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7063\n",
      "[LightGBM] [Info] Number of data points in the train set: 52704, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117448 -> initscore=-2.016818\n",
      "[LightGBM] [Info] Start training from score -2.016818\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6479\n",
      "[LightGBM] [Info] Number of data points in the train set: 6190, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.397924\n",
      "[LightGBM] [Info] Number of positive: 6158, number of negative: 46344\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7062\n",
      "[LightGBM] [Info] Number of data points in the train set: 52502, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117291 -> initscore=-2.018340\n",
      "[LightGBM] [Info] Start training from score -2.018340\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6386\n",
      "[LightGBM] [Info] Number of data points in the train set: 6158, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.396247\n",
      "[LightGBM] [Info] Number of positive: 6131, number of negative: 46169\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7061\n",
      "[LightGBM] [Info] Number of data points in the train set: 52300, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117228 -> initscore=-2.018951\n",
      "[LightGBM] [Info] Start training from score -2.018951\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6379\n",
      "[LightGBM] [Info] Number of data points in the train set: 6131, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.395018\n",
      "[LightGBM] [Info] Number of positive: 6108, number of negative: 45990\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7058\n",
      "[LightGBM] [Info] Number of data points in the train set: 52098, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117241 -> initscore=-2.018825\n",
      "[LightGBM] [Info] Start training from score -2.018825\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6374\n",
      "[LightGBM] [Info] Number of data points in the train set: 6108, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.393386\n",
      "[LightGBM] [Info] Number of positive: 6079, number of negative: 45817\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7057\n",
      "[LightGBM] [Info] Number of data points in the train set: 51896, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117138 -> initscore=-2.019815\n",
      "[LightGBM] [Info] Start training from score -2.019815\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6393\n",
      "[LightGBM] [Info] Number of data points in the train set: 6079, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.391456\n",
      "[LightGBM] [Info] Number of positive: 6049, number of negative: 45646\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7056\n",
      "[LightGBM] [Info] Number of data points in the train set: 51695, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117013 -> initscore=-2.021023\n",
      "[LightGBM] [Info] Start training from score -2.021023\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6389\n",
      "[LightGBM] [Info] Number of data points in the train set: 6049, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.392411\n",
      "[LightGBM] [Info] Number of positive: 6020, number of negative: 45475\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7057\n",
      "[LightGBM] [Info] Number of data points in the train set: 51495, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116905 -> initscore=-2.022075\n",
      "[LightGBM] [Info] Start training from score -2.022075\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6382\n",
      "[LightGBM] [Info] Number of data points in the train set: 6020, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.391247\n",
      "[LightGBM] [Info] Number of positive: 5986, number of negative: 45309\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003790 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7057\n",
      "[LightGBM] [Info] Number of data points in the train set: 51295, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116698 -> initscore=-2.024082\n",
      "[LightGBM] [Info] Start training from score -2.024082\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6392\n",
      "[LightGBM] [Info] Number of data points in the train set: 5986, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.390725\n",
      "[LightGBM] [Info] Number of positive: 5954, number of negative: 45142\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7053\n",
      "[LightGBM] [Info] Number of data points in the train set: 51096, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116526 -> initscore=-2.025750\n",
      "[LightGBM] [Info] Start training from score -2.025750\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6387\n",
      "[LightGBM] [Info] Number of data points in the train set: 5954, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.390477\n",
      "[LightGBM] [Info] Number of positive: 5925, number of negative: 44972\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7051\n",
      "[LightGBM] [Info] Number of data points in the train set: 50897, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116412 -> initscore=-2.026859\n",
      "[LightGBM] [Info] Start training from score -2.026859\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6381\n",
      "[LightGBM] [Info] Number of data points in the train set: 5925, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.389678\n",
      "[LightGBM] [Info] Number of positive: 5894, number of negative: 44804\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7051\n",
      "[LightGBM] [Info] Number of data points in the train set: 50698, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116257 -> initscore=-2.028363\n",
      "[LightGBM] [Info] Start training from score -2.028363\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5894, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.390507\n",
      "[LightGBM] [Info] Number of positive: 5868, number of negative: 44631\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7052\n",
      "[LightGBM] [Info] Number of data points in the train set: 50499, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116200 -> initscore=-2.028915\n",
      "[LightGBM] [Info] Start training from score -2.028915\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6383\n",
      "[LightGBM] [Info] Number of data points in the train set: 5868, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.391125\n",
      "[LightGBM] [Info] Number of positive: 5842, number of negative: 44458\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003830 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7051\n",
      "[LightGBM] [Info] Number of data points in the train set: 50300, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116143 -> initscore=-2.029472\n",
      "[LightGBM] [Info] Start training from score -2.029472\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6376\n",
      "[LightGBM] [Info] Number of data points in the train set: 5842, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.392952\n",
      "[LightGBM] [Info] Number of positive: 5820, number of negative: 44281\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003727 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7050\n",
      "[LightGBM] [Info] Number of data points in the train set: 50101, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116165 -> initscore=-2.029255\n",
      "[LightGBM] [Info] Start training from score -2.029255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 5820, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.391776\n",
      "[LightGBM] [Info] Number of positive: 5796, number of negative: 44106\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7049\n",
      "[LightGBM] [Info] Number of data points in the train set: 49902, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116148 -> initscore=-2.029428\n",
      "[LightGBM] [Info] Start training from score -2.029428\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6363\n",
      "[LightGBM] [Info] Number of data points in the train set: 5796, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.390558\n",
      "[LightGBM] [Info] Number of positive: 5771, number of negative: 43932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7048\n",
      "[LightGBM] [Info] Number of data points in the train set: 49703, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116110 -> initscore=-2.029798\n",
      "[LightGBM] [Info] Start training from score -2.029798\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6367\n",
      "[LightGBM] [Info] Number of data points in the train set: 5771, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.391638\n",
      "[LightGBM] [Info] Number of positive: 5743, number of negative: 43761\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003024 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7045\n",
      "[LightGBM] [Info] Number of data points in the train set: 49504, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116011 -> initscore=-2.030761\n",
      "[LightGBM] [Info] Start training from score -2.030761\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6367\n",
      "[LightGBM] [Info] Number of data points in the train set: 5743, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.392328\n",
      "[LightGBM] [Info] Number of positive: 5713, number of negative: 43592\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7046\n",
      "[LightGBM] [Info] Number of data points in the train set: 49305, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115871 -> initscore=-2.032129\n",
      "[LightGBM] [Info] Start training from score -2.032129\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6346\n",
      "[LightGBM] [Info] Number of data points in the train set: 5713, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.393193\n",
      "[LightGBM] [Info] Number of positive: 5687, number of negative: 43419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7045\n",
      "[LightGBM] [Info] Number of data points in the train set: 49106, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115811 -> initscore=-2.032714\n",
      "[LightGBM] [Info] Start training from score -2.032714\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000909 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6346\n",
      "[LightGBM] [Info] Number of data points in the train set: 5687, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.393366\n",
      "[LightGBM] [Info] Number of positive: 5664, number of negative: 43243\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7042\n",
      "[LightGBM] [Info] Number of data points in the train set: 48907, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115812 -> initscore=-2.032705\n",
      "[LightGBM] [Info] Start training from score -2.032705\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6236\n",
      "[LightGBM] [Info] Number of data points in the train set: 5664, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.393221\n",
      "[LightGBM] [Info] Number of positive: 5634, number of negative: 43074\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7041\n",
      "[LightGBM] [Info] Number of data points in the train set: 48708, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115669 -> initscore=-2.034100\n",
      "[LightGBM] [Info] Start training from score -2.034100\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6232\n",
      "[LightGBM] [Info] Number of data points in the train set: 5634, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 3.393677\n",
      "Storing \"fatalities002_conflicthistory_hurdle_lgb_test\"\n",
      "cm_fatalities002_conflicthistory_hurdle_lgb_test , run Fatalities002 force_rewrite=True, predicting\n",
      "4 fatalities002_conflicthistory_long_xgb\n",
      "Calibration partition 2024-03-28 15:19:54.912057\n",
      " * == Performing a run: \"fatalities002_conflicthistory_long_xgb_calib\" == * \n",
      "Model object named \"fatalities002_conflicthistory_long_xgb_calib\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_conflicthistory_long_xgb_calib\"\n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities002_conflicthistory_long_xgb_calib\"\n",
      "cm_fatalities002_conflicthistory_long_xgb_calib , run Fatalities002 force_rewrite=True, predicting\n",
      "Test partition 2024-03-28 15:20:39.725886\n",
      " * == Performing a run: \"fatalities002_conflicthistory_long_xgb_test\" == * \n",
      "Model object named \"fatalities002_conflicthistory_long_xgb_test\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_conflicthistory_long_xgb_test\"\n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities002_conflicthistory_long_xgb_test\"\n",
      "cm_fatalities002_conflicthistory_long_xgb_test , run Fatalities002 force_rewrite=True, predicting\n",
      "5 fatalities002_vdem_hurdle_xgb\n",
      "Calibration partition 2024-03-28 15:21:26.507006\n",
      " * == Performing a run: \"fatalities002_vdem_hurdle_xgb_calib\" == * \n",
      "Model object named \"fatalities002_vdem_hurdle_xgb_calib\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_vdem_hurdle_xgb_calib\"\n",
      "Training model(s)...\n",
      "Storing \"fatalities002_vdem_hurdle_xgb_calib\"\n",
      "cm_fatalities002_vdem_hurdle_xgb_calib , run Fatalities002 force_rewrite=True, predicting\n",
      "Test partition 2024-03-28 15:22:31.248758\n",
      " * == Performing a run: \"fatalities002_vdem_hurdle_xgb_test\" == * \n",
      "Model object named \"fatalities002_vdem_hurdle_xgb_test\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_vdem_hurdle_xgb_test\"\n",
      "Training model(s)...\n",
      "Storing \"fatalities002_vdem_hurdle_xgb_test\"\n",
      "cm_fatalities002_vdem_hurdle_xgb_test , run Fatalities002 force_rewrite=True, predicting\n",
      "6 fatalities002_wdi_rf\n",
      "Calibration partition 2024-03-28 15:23:41.681150\n",
      " * == Performing a run: \"fatalities002_wdi_rf_calib\" == * \n",
      "Model object named \"fatalities002_wdi_rf_calib\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_wdi_rf_calib\"\n",
      "Training model(s)...\n",
      "Storing \"fatalities002_wdi_rf_calib\"\n",
      "cm_fatalities002_wdi_rf_calib , run Fatalities002 force_rewrite=True, predicting\n",
      "Test partition 2024-03-28 15:25:13.645201\n",
      " * == Performing a run: \"fatalities002_wdi_rf_test\" == * \n",
      "Model object named \"fatalities002_wdi_rf_test\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_wdi_rf_test\"\n",
      "Training model(s)...\n",
      "Storing \"fatalities002_wdi_rf_test\"\n",
      "cm_fatalities002_wdi_rf_test , run Fatalities002 force_rewrite=True, predicting\n",
      "7 fatalities002_topics_rf\n",
      "Calibration partition 2024-03-28 15:26:52.586296\n",
      " * == Performing a run: \"fatalities002_topics_rf_calib\" == * \n",
      "Model object named \"fatalities002_topics_rf_calib\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_topics_rf_calib\"\n",
      "Training model(s)...\n",
      "Storing \"fatalities002_topics_rf_calib\"\n",
      "cm_fatalities002_topics_rf_calib , run Fatalities002 force_rewrite=True, predicting\n",
      "Test partition 2024-03-28 15:29:10.412767\n",
      " * == Performing a run: \"fatalities002_topics_rf_test\" == * \n",
      "Model object named \"fatalities002_topics_rf_test\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_topics_rf_test\"\n",
      "Training model(s)...\n",
      "Storing \"fatalities002_topics_rf_test\"\n",
      "cm_fatalities002_topics_rf_test , run Fatalities002 force_rewrite=True, predicting\n",
      "8 fatalities002_topics_xgb\n",
      "Calibration partition 2024-03-28 15:31:38.946129\n",
      " * == Performing a run: \"fatalities002_topics_xgb_calib\" == * \n",
      "Model object named \"fatalities002_topics_xgb_calib\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_topics_xgb_calib\"\n",
      "Training model(s)...\n",
      "Storing \"fatalities002_topics_xgb_calib\"\n",
      "cm_fatalities002_topics_xgb_calib , run Fatalities002 force_rewrite=True, predicting\n",
      "Test partition 2024-03-28 15:32:35.832242\n",
      " * == Performing a run: \"fatalities002_topics_xgb_test\" == * \n",
      "Model object named \"fatalities002_topics_xgb_test\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_topics_xgb_test\"\n",
      "Training model(s)...\n",
      "Storing \"fatalities002_topics_xgb_test\"\n",
      "cm_fatalities002_topics_xgb_test , run Fatalities002 force_rewrite=True, predicting\n",
      "9 fatalities002_topics_hurdle_lgb\n",
      "Calibration partition 2024-03-28 15:33:36.454411\n",
      " * == Performing a run: \"fatalities002_topics_hurdle_lgb_calib\" == * \n",
      "Model object named \"fatalities002_topics_hurdle_lgb_calib\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_topics_hurdle_lgb_calib\"\n",
      "Training model(s)...\n",
      "[LightGBM] [Info] Number of positive: 5545, number of negative: 41061\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 46606, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118976 -> initscore=-2.002162\n",
      "[LightGBM] [Info] Start training from score -2.002162\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17344\n",
      "[LightGBM] [Info] Number of data points in the train set: 5545, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.391455\n",
      "[LightGBM] [Info] Number of positive: 5519, number of negative: 40881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 46400, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118944 -> initscore=-2.002469\n",
      "[LightGBM] [Info] Start training from score -2.002469\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17346\n",
      "[LightGBM] [Info] Number of data points in the train set: 5519, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.387713\n",
      "[LightGBM] [Info] Number of positive: 5488, number of negative: 40706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 46194, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118803 -> initscore=-2.003812\n",
      "[LightGBM] [Info] Start training from score -2.003812\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17352\n",
      "[LightGBM] [Info] Number of data points in the train set: 5488, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.386294\n",
      "[LightGBM] [Info] Number of positive: 5458, number of negative: 40531\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 45989, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118681 -> initscore=-2.004985\n",
      "[LightGBM] [Info] Start training from score -2.004985\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17355\n",
      "[LightGBM] [Info] Number of data points in the train set: 5458, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.384750\n",
      "[LightGBM] [Info] Number of positive: 5429, number of negative: 40355\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17571\n",
      "[LightGBM] [Info] Number of data points in the train set: 45784, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118579 -> initscore=-2.005960\n",
      "[LightGBM] [Info] Start training from score -2.005960\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17360\n",
      "[LightGBM] [Info] Number of data points in the train set: 5429, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.384959\n",
      "[LightGBM] [Info] Number of positive: 5401, number of negative: 40180\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 45581, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118492 -> initscore=-2.006785\n",
      "[LightGBM] [Info] Start training from score -2.006785\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17364\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.383308\n",
      "[LightGBM] [Info] Number of positive: 5374, number of negative: 40005\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17570\n",
      "[LightGBM] [Info] Number of data points in the train set: 45379, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118425 -> initscore=-2.007432\n",
      "[LightGBM] [Info] Start training from score -2.007432\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17363\n",
      "[LightGBM] [Info] Number of data points in the train set: 5374, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.380362\n",
      "[LightGBM] [Info] Number of positive: 5344, number of negative: 39833\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17571\n",
      "[LightGBM] [Info] Number of data points in the train set: 45177, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118290 -> initscore=-2.008721\n",
      "[LightGBM] [Info] Start training from score -2.008721\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17365\n",
      "[LightGBM] [Info] Number of data points in the train set: 5344, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.379547\n",
      "[LightGBM] [Info] Number of positive: 5311, number of negative: 39664\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17571\n",
      "[LightGBM] [Info] Number of data points in the train set: 44975, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118088 -> initscore=-2.010664\n",
      "[LightGBM] [Info] Start training from score -2.010664\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17369\n",
      "[LightGBM] [Info] Number of data points in the train set: 5311, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.380101\n",
      "[LightGBM] [Info] Number of positive: 5281, number of negative: 39492\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014955 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17571\n",
      "[LightGBM] [Info] Number of data points in the train set: 44773, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117951 -> initscore=-2.011983\n",
      "[LightGBM] [Info] Start training from score -2.011983\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001894 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17376\n",
      "[LightGBM] [Info] Number of data points in the train set: 5281, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.376092\n",
      "[LightGBM] [Info] Number of positive: 5252, number of negative: 39321\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17570\n",
      "[LightGBM] [Info] Number of data points in the train set: 44573, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117829 -> initscore=-2.013150\n",
      "[LightGBM] [Info] Start training from score -2.013150\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17376\n",
      "[LightGBM] [Info] Number of data points in the train set: 5252, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.375903\n",
      "[LightGBM] [Info] Number of positive: 5218, number of negative: 39155\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17570\n",
      "[LightGBM] [Info] Number of data points in the train set: 44373, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117594 -> initscore=-2.015414\n",
      "[LightGBM] [Info] Start training from score -2.015414\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17373\n",
      "[LightGBM] [Info] Number of data points in the train set: 5218, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.375498\n",
      "[LightGBM] [Info] Number of positive: 5188, number of negative: 38985\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17569\n",
      "[LightGBM] [Info] Number of data points in the train set: 44173, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117447 -> initscore=-2.016829\n",
      "[LightGBM] [Info] Start training from score -2.016829\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17376\n",
      "[LightGBM] [Info] Number of data points in the train set: 5188, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.375122\n",
      "[LightGBM] [Info] Number of positive: 5162, number of negative: 38811\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17570\n",
      "[LightGBM] [Info] Number of data points in the train set: 43973, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117390 -> initscore=-2.017380\n",
      "[LightGBM] [Info] Start training from score -2.017380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17375\n",
      "[LightGBM] [Info] Number of data points in the train set: 5162, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.372283\n",
      "[LightGBM] [Info] Number of positive: 5132, number of negative: 38641\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17570\n",
      "[LightGBM] [Info] Number of data points in the train set: 43773, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117241 -> initscore=-2.018818\n",
      "[LightGBM] [Info] Start training from score -2.018818\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17378\n",
      "[LightGBM] [Info] Number of data points in the train set: 5132, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.371381\n",
      "[LightGBM] [Info] Number of positive: 5100, number of negative: 38473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17569\n",
      "[LightGBM] [Info] Number of data points in the train set: 43573, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117045 -> initscore=-2.020716\n",
      "[LightGBM] [Info] Start training from score -2.020716\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17376\n",
      "[LightGBM] [Info] Number of data points in the train set: 5100, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.368761\n",
      "[LightGBM] [Info] Number of positive: 5069, number of negative: 38304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17569\n",
      "[LightGBM] [Info] Number of data points in the train set: 43373, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116870 -> initscore=-2.022411\n",
      "[LightGBM] [Info] Start training from score -2.022411\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17384\n",
      "[LightGBM] [Info] Number of data points in the train set: 5069, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.366348\n",
      "[LightGBM] [Info] Number of positive: 5044, number of negative: 38129\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17569\n",
      "[LightGBM] [Info] Number of data points in the train set: 43173, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116832 -> initscore=-2.022776\n",
      "[LightGBM] [Info] Start training from score -2.022776\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17383\n",
      "[LightGBM] [Info] Number of data points in the train set: 5044, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.364531\n",
      "[LightGBM] [Info] Number of positive: 5022, number of negative: 37951\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17568\n",
      "[LightGBM] [Info] Number of data points in the train set: 42973, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116864 -> initscore=-2.022468\n",
      "[LightGBM] [Info] Start training from score -2.022468\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17383\n",
      "[LightGBM] [Info] Number of data points in the train set: 5022, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.362757\n",
      "[LightGBM] [Info] Number of positive: 4995, number of negative: 37778\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17569\n",
      "[LightGBM] [Info] Number of data points in the train set: 42773, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116779 -> initscore=-2.023290\n",
      "[LightGBM] [Info] Start training from score -2.023290\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17391\n",
      "[LightGBM] [Info] Number of data points in the train set: 4995, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.360102\n",
      "[LightGBM] [Info] Number of positive: 4966, number of negative: 37608\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17569\n",
      "[LightGBM] [Info] Number of data points in the train set: 42574, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116644 -> initscore=-2.024602\n",
      "[LightGBM] [Info] Start training from score -2.024602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17391\n",
      "[LightGBM] [Info] Number of data points in the train set: 4966, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.360760\n",
      "[LightGBM] [Info] Number of positive: 4939, number of negative: 37437\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17569\n",
      "[LightGBM] [Info] Number of data points in the train set: 42376, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116552 -> initscore=-2.025497\n",
      "[LightGBM] [Info] Start training from score -2.025497\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17392\n",
      "[LightGBM] [Info] Number of data points in the train set: 4939, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.358953\n",
      "[LightGBM] [Info] Number of positive: 4907, number of negative: 37271\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17569\n",
      "[LightGBM] [Info] Number of data points in the train set: 42178, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116340 -> initscore=-2.027553\n",
      "[LightGBM] [Info] Start training from score -2.027553\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17392\n",
      "[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.357955\n",
      "[LightGBM] [Info] Number of positive: 4876, number of negative: 37105\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17569\n",
      "[LightGBM] [Info] Number of data points in the train set: 41981, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116148 -> initscore=-2.029427\n",
      "[LightGBM] [Info] Start training from score -2.029427\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17389\n",
      "[LightGBM] [Info] Number of data points in the train set: 4876, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.357032\n",
      "[LightGBM] [Info] Number of positive: 4848, number of negative: 36936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17568\n",
      "[LightGBM] [Info] Number of data points in the train set: 41784, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116025 -> initscore=-2.030620\n",
      "[LightGBM] [Info] Start training from score -2.030620\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001979 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17386\n",
      "[LightGBM] [Info] Number of data points in the train set: 4848, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.355826\n",
      "[LightGBM] [Info] Number of positive: 4818, number of negative: 36769\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17569\n",
      "[LightGBM] [Info] Number of data points in the train set: 41587, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115854 -> initscore=-2.032296\n",
      "[LightGBM] [Info] Start training from score -2.032296\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17383\n",
      "[LightGBM] [Info] Number of data points in the train set: 4818, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.356424\n",
      "[LightGBM] [Info] Number of positive: 4792, number of negative: 36598\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17568\n",
      "[LightGBM] [Info] Number of data points in the train set: 41390, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115777 -> initscore=-2.033046\n",
      "[LightGBM] [Info] Start training from score -2.033046\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001964 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17387\n",
      "[LightGBM] [Info] Number of data points in the train set: 4792, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.356996\n",
      "[LightGBM] [Info] Number of positive: 4768, number of negative: 36425\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17567\n",
      "[LightGBM] [Info] Number of data points in the train set: 41193, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115748 -> initscore=-2.033328\n",
      "[LightGBM] [Info] Start training from score -2.033328\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17394\n",
      "[LightGBM] [Info] Number of data points in the train set: 4768, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.358757\n",
      "[LightGBM] [Info] Number of positive: 4747, number of negative: 36249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17565\n",
      "[LightGBM] [Info] Number of data points in the train set: 40996, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115792 -> initscore=-2.032899\n",
      "[LightGBM] [Info] Start training from score -2.032899\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17393\n",
      "[LightGBM] [Info] Number of data points in the train set: 4747, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.357227\n",
      "[LightGBM] [Info] Number of positive: 4725, number of negative: 36074\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17565\n",
      "[LightGBM] [Info] Number of data points in the train set: 40799, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115812 -> initscore=-2.032705\n",
      "[LightGBM] [Info] Start training from score -2.032705\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17393\n",
      "[LightGBM] [Info] Number of data points in the train set: 4725, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.356150\n",
      "[LightGBM] [Info] Number of positive: 4702, number of negative: 35900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17565\n",
      "[LightGBM] [Info] Number of data points in the train set: 40602, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115807 -> initscore=-2.032749\n",
      "[LightGBM] [Info] Start training from score -2.032749\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17392\n",
      "[LightGBM] [Info] Number of data points in the train set: 4702, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.357821\n",
      "[LightGBM] [Info] Number of positive: 4676, number of negative: 35729\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17564\n",
      "[LightGBM] [Info] Number of data points in the train set: 40405, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115728 -> initscore=-2.033520\n",
      "[LightGBM] [Info] Start training from score -2.033520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001844 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17389\n",
      "[LightGBM] [Info] Number of data points in the train set: 4676, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.359241\n",
      "[LightGBM] [Info] Number of positive: 4648, number of negative: 35560\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17563\n",
      "[LightGBM] [Info] Number of data points in the train set: 40208, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115599 -> initscore=-2.034784\n",
      "[LightGBM] [Info] Start training from score -2.034784\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17389\n",
      "[LightGBM] [Info] Number of data points in the train set: 4648, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.360724\n",
      "[LightGBM] [Info] Number of positive: 4624, number of negative: 35387\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17563\n",
      "[LightGBM] [Info] Number of data points in the train set: 40011, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115568 -> initscore=-2.035084\n",
      "[LightGBM] [Info] Start training from score -2.035084\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17392\n",
      "[LightGBM] [Info] Number of data points in the train set: 4624, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.361289\n",
      "[LightGBM] [Info] Number of positive: 4602, number of negative: 35214\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17562\n",
      "[LightGBM] [Info] Number of data points in the train set: 39816, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115582 -> initscore=-2.034953\n",
      "[LightGBM] [Info] Start training from score -2.034953\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17391\n",
      "[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.361227\n",
      "[LightGBM] [Info] Number of positive: 4574, number of negative: 35047\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17563\n",
      "[LightGBM] [Info] Number of data points in the train set: 39621, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115444 -> initscore=-2.036302\n",
      "[LightGBM] [Info] Start training from score -2.036302\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17390\n",
      "[LightGBM] [Info] Number of data points in the train set: 4574, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.361714\n",
      "Storing \"fatalities002_topics_hurdle_lgb_calib\"\n",
      "cm_fatalities002_topics_hurdle_lgb_calib , run Fatalities002 force_rewrite=True, predicting\n",
      "Test partition 2024-03-28 15:35:14.638593\n",
      " * == Performing a run: \"fatalities002_topics_hurdle_lgb_test\" == * \n",
      "Training model(s)...\n",
      "[LightGBM] [Info] Number of positive: 6659, number of negative: 49108\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17570\n",
      "[LightGBM] [Info] Number of data points in the train set: 55767, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.119408 -> initscore=-1.998053\n",
      "[LightGBM] [Info] Start training from score -1.998053\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17361\n",
      "[LightGBM] [Info] Number of data points in the train set: 6659, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.416581\n",
      "[LightGBM] [Info] Number of positive: 6631, number of negative: 48928\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17571\n",
      "[LightGBM] [Info] Number of data points in the train set: 55559, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.119351 -> initscore=-1.998594\n",
      "[LightGBM] [Info] Start training from score -1.998594\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17361\n",
      "[LightGBM] [Info] Number of data points in the train set: 6631, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.413810\n",
      "[LightGBM] [Info] Number of positive: 6598, number of negative: 48753\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 55351, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.119203 -> initscore=-2.000000\n",
      "[LightGBM] [Info] Start training from score -2.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17372\n",
      "[LightGBM] [Info] Number of data points in the train set: 6598, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.412819\n",
      "[LightGBM] [Info] Number of positive: 6566, number of negative: 48578\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 55144, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.119070 -> initscore=-2.001266\n",
      "[LightGBM] [Info] Start training from score -2.001266\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17378\n",
      "[LightGBM] [Info] Number of data points in the train set: 6566, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.411518\n",
      "[LightGBM] [Info] Number of positive: 6535, number of negative: 48402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 54937, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118954 -> initscore=-2.002369\n",
      "[LightGBM] [Info] Start training from score -2.002369\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17383\n",
      "[LightGBM] [Info] Number of data points in the train set: 6535, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.412013\n",
      "[LightGBM] [Info] Number of positive: 6505, number of negative: 48227\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17570\n",
      "[LightGBM] [Info] Number of data points in the train set: 54732, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118852 -> initscore=-2.003348\n",
      "[LightGBM] [Info] Start training from score -2.003348\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17387\n",
      "[LightGBM] [Info] Number of data points in the train set: 6505, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.410588\n",
      "[LightGBM] [Info] Number of positive: 6477, number of negative: 48051\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17571\n",
      "[LightGBM] [Info] Number of data points in the train set: 54528, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118783 -> initscore=-2.004006\n",
      "[LightGBM] [Info] Start training from score -2.004006\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17390\n",
      "[LightGBM] [Info] Number of data points in the train set: 6477, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.408126\n",
      "[LightGBM] [Info] Number of positive: 6446, number of negative: 47878\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 54324, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118658 -> initscore=-2.005196\n",
      "[LightGBM] [Info] Start training from score -2.005196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002000 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17393\n",
      "[LightGBM] [Info] Number of data points in the train set: 6446, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.407298\n",
      "[LightGBM] [Info] Number of positive: 6411, number of negative: 47709\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 54120, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118459 -> initscore=-2.007105\n",
      "[LightGBM] [Info] Start training from score -2.007105\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17397\n",
      "[LightGBM] [Info] Number of data points in the train set: 6411, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.407403\n",
      "[LightGBM] [Info] Number of positive: 6379, number of negative: 47537\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 53916, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118314 -> initscore=-2.008497\n",
      "[LightGBM] [Info] Start training from score -2.008497\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17405\n",
      "[LightGBM] [Info] Number of data points in the train set: 6379, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.403711\n",
      "[LightGBM] [Info] Number of positive: 6348, number of negative: 47366\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 53714, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118181 -> initscore=-2.009765\n",
      "[LightGBM] [Info] Start training from score -2.009765\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17410\n",
      "[LightGBM] [Info] Number of data points in the train set: 6348, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.403675\n",
      "[LightGBM] [Info] Number of positive: 6313, number of negative: 47199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17571\n",
      "[LightGBM] [Info] Number of data points in the train set: 53512, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117974 -> initscore=-2.011762\n",
      "[LightGBM] [Info] Start training from score -2.011762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17408\n",
      "[LightGBM] [Info] Number of data points in the train set: 6313, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.403394\n",
      "[LightGBM] [Info] Number of positive: 6282, number of negative: 47028\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 53310, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117839 -> initscore=-2.013055\n",
      "[LightGBM] [Info] Start training from score -2.013055\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17409\n",
      "[LightGBM] [Info] Number of data points in the train set: 6282, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.402993\n",
      "[LightGBM] [Info] Number of positive: 6255, number of negative: 46853\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 53108, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117779 -> initscore=-2.013634\n",
      "[LightGBM] [Info] Start training from score -2.013634\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17410\n",
      "[LightGBM] [Info] Number of data points in the train set: 6255, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.400724\n",
      "[LightGBM] [Info] Number of positive: 6224, number of negative: 46682\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 52906, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117643 -> initscore=-2.014946\n",
      "[LightGBM] [Info] Start training from score -2.014946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17414\n",
      "[LightGBM] [Info] Number of data points in the train set: 6224, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.399727\n",
      "[LightGBM] [Info] Number of positive: 6190, number of negative: 46514\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 52704, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117448 -> initscore=-2.016818\n",
      "[LightGBM] [Info] Start training from score -2.016818\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17416\n",
      "[LightGBM] [Info] Number of data points in the train set: 6190, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.397924\n",
      "[LightGBM] [Info] Number of positive: 6158, number of negative: 46344\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17571\n",
      "[LightGBM] [Info] Number of data points in the train set: 52502, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117291 -> initscore=-2.018340\n",
      "[LightGBM] [Info] Start training from score -2.018340\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17424\n",
      "[LightGBM] [Info] Number of data points in the train set: 6158, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.396247\n",
      "[LightGBM] [Info] Number of positive: 6131, number of negative: 46169\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17573\n",
      "[LightGBM] [Info] Number of data points in the train set: 52300, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117228 -> initscore=-2.018951\n",
      "[LightGBM] [Info] Start training from score -2.018951\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17425\n",
      "[LightGBM] [Info] Number of data points in the train set: 6131, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.395018\n",
      "[LightGBM] [Info] Number of positive: 6108, number of negative: 45990\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17573\n",
      "[LightGBM] [Info] Number of data points in the train set: 52098, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117241 -> initscore=-2.018825\n",
      "[LightGBM] [Info] Start training from score -2.018825\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17423\n",
      "[LightGBM] [Info] Number of data points in the train set: 6108, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.393386\n",
      "[LightGBM] [Info] Number of positive: 6079, number of negative: 45817\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17573\n",
      "[LightGBM] [Info] Number of data points in the train set: 51896, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117138 -> initscore=-2.019815\n",
      "[LightGBM] [Info] Start training from score -2.019815\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17427\n",
      "[LightGBM] [Info] Number of data points in the train set: 6079, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.391456\n",
      "[LightGBM] [Info] Number of positive: 6049, number of negative: 45646\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 51695, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117013 -> initscore=-2.021023\n",
      "[LightGBM] [Info] Start training from score -2.021023\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17427\n",
      "[LightGBM] [Info] Number of data points in the train set: 6049, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.392411\n",
      "[LightGBM] [Info] Number of positive: 6020, number of negative: 45475\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 51495, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116905 -> initscore=-2.022075\n",
      "[LightGBM] [Info] Start training from score -2.022075\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001987 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17427\n",
      "[LightGBM] [Info] Number of data points in the train set: 6020, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.391247\n",
      "[LightGBM] [Info] Number of positive: 5986, number of negative: 45309\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 51295, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116698 -> initscore=-2.024082\n",
      "[LightGBM] [Info] Start training from score -2.024082\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17428\n",
      "[LightGBM] [Info] Number of data points in the train set: 5986, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.390725\n",
      "[LightGBM] [Info] Number of positive: 5954, number of negative: 45142\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 51096, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116526 -> initscore=-2.025750\n",
      "[LightGBM] [Info] Start training from score -2.025750\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17432\n",
      "[LightGBM] [Info] Number of data points in the train set: 5954, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.390477\n",
      "[LightGBM] [Info] Number of positive: 5925, number of negative: 44972\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 50897, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116412 -> initscore=-2.026859\n",
      "[LightGBM] [Info] Start training from score -2.026859\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17429\n",
      "[LightGBM] [Info] Number of data points in the train set: 5925, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.389678\n",
      "[LightGBM] [Info] Number of positive: 5894, number of negative: 44804\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 50698, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116257 -> initscore=-2.028363\n",
      "[LightGBM] [Info] Start training from score -2.028363\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17430\n",
      "[LightGBM] [Info] Number of data points in the train set: 5894, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.390507\n",
      "[LightGBM] [Info] Number of positive: 5868, number of negative: 44631\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17573\n",
      "[LightGBM] [Info] Number of data points in the train set: 50499, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116200 -> initscore=-2.028915\n",
      "[LightGBM] [Info] Start training from score -2.028915\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17435\n",
      "[LightGBM] [Info] Number of data points in the train set: 5868, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.391125\n",
      "[LightGBM] [Info] Number of positive: 5842, number of negative: 44458\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17573\n",
      "[LightGBM] [Info] Number of data points in the train set: 50300, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116143 -> initscore=-2.029472\n",
      "[LightGBM] [Info] Start training from score -2.029472\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17424\n",
      "[LightGBM] [Info] Number of data points in the train set: 5842, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.392952\n",
      "[LightGBM] [Info] Number of positive: 5820, number of negative: 44281\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17573\n",
      "[LightGBM] [Info] Number of data points in the train set: 50101, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116165 -> initscore=-2.029255\n",
      "[LightGBM] [Info] Start training from score -2.029255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17424\n",
      "[LightGBM] [Info] Number of data points in the train set: 5820, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.391776\n",
      "[LightGBM] [Info] Number of positive: 5796, number of negative: 44106\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17574\n",
      "[LightGBM] [Info] Number of data points in the train set: 49902, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116148 -> initscore=-2.029428\n",
      "[LightGBM] [Info] Start training from score -2.029428\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17422\n",
      "[LightGBM] [Info] Number of data points in the train set: 5796, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.390558\n",
      "[LightGBM] [Info] Number of positive: 5771, number of negative: 43932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 49703, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116110 -> initscore=-2.029798\n",
      "[LightGBM] [Info] Start training from score -2.029798\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17424\n",
      "[LightGBM] [Info] Number of data points in the train set: 5771, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.391638\n",
      "[LightGBM] [Info] Number of positive: 5743, number of negative: 43761\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 49504, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116011 -> initscore=-2.030761\n",
      "[LightGBM] [Info] Start training from score -2.030761\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17425\n",
      "[LightGBM] [Info] Number of data points in the train set: 5743, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.392328\n",
      "[LightGBM] [Info] Number of positive: 5713, number of negative: 43592\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 49305, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115871 -> initscore=-2.032129\n",
      "[LightGBM] [Info] Start training from score -2.032129\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17426\n",
      "[LightGBM] [Info] Number of data points in the train set: 5713, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.393193\n",
      "[LightGBM] [Info] Number of positive: 5687, number of negative: 43419\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 49106, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115811 -> initscore=-2.032714\n",
      "[LightGBM] [Info] Start training from score -2.032714\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17423\n",
      "[LightGBM] [Info] Number of data points in the train set: 5687, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.393366\n",
      "[LightGBM] [Info] Number of positive: 5664, number of negative: 43243\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 48907, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115812 -> initscore=-2.032705\n",
      "[LightGBM] [Info] Start training from score -2.032705\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17422\n",
      "[LightGBM] [Info] Number of data points in the train set: 5664, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.393221\n",
      "[LightGBM] [Info] Number of positive: 5634, number of negative: 43074\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17572\n",
      "[LightGBM] [Info] Number of data points in the train set: 48708, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115669 -> initscore=-2.034100\n",
      "[LightGBM] [Info] Start training from score -2.034100\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17425\n",
      "[LightGBM] [Info] Number of data points in the train set: 5634, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 3.393677\n",
      "Storing \"fatalities002_topics_hurdle_lgb_test\"\n",
      "cm_fatalities002_topics_hurdle_lgb_test , run Fatalities002 force_rewrite=True, predicting\n",
      "10 fatalities002_joint_broad_rf\n",
      "Calibration partition 2024-03-28 15:37:00.456150\n",
      " * == Performing a run: \"fatalities002_joint_broad_rf_calib\" == * \n",
      "Model object named \"fatalities002_joint_broad_rf_calib\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_joint_broad_rf_calib\"\n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities002_joint_broad_rf_calib\"\n",
      "cm_fatalities002_joint_broad_rf_calib , run Fatalities002 force_rewrite=True, predicting\n",
      "Test partition 2024-03-28 15:39:09.439201\n",
      " * == Performing a run: \"fatalities002_joint_broad_rf_test\" == * \n",
      "Model object named \"fatalities002_joint_broad_rf_test\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_joint_broad_rf_test\"\n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities002_joint_broad_rf_test\"\n",
      "cm_fatalities002_joint_broad_rf_test , run Fatalities002 force_rewrite=True, predicting\n",
      "11 fatalities002_joint_broad_hurdle_rf\n",
      "Calibration partition 2024-03-28 15:41:23.943835\n",
      " * == Performing a run: \"fatalities002_joint_broad_hurdle_rf_calib\" == * \n",
      "Model object named \"fatalities002_joint_broad_hurdle_rf_calib\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_joint_broad_hurdle_rf_calib\"\n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities002_joint_broad_hurdle_rf_calib\"\n",
      "cm_fatalities002_joint_broad_hurdle_rf_calib , run Fatalities002 force_rewrite=True, predicting\n",
      "Test partition 2024-03-28 15:44:19.458694\n",
      " * == Performing a run: \"fatalities002_joint_broad_hurdle_rf_test\" == * \n",
      "Model object named \"fatalities002_joint_broad_hurdle_rf_test\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_joint_broad_hurdle_rf_test\"\n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities002_joint_broad_hurdle_rf_test\"\n",
      "cm_fatalities002_joint_broad_hurdle_rf_test , run Fatalities002 force_rewrite=True, predicting\n",
      "12 fatalities002_joint_narrow_xgb\n",
      "Calibration partition 2024-03-28 15:47:29.871456\n",
      " * == Performing a run: \"fatalities002_joint_narrow_xgb_calib\" == * \n",
      "Model object named \"fatalities002_joint_narrow_xgb_calib\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_joint_narrow_xgb_calib\"\n",
      "Training model(s)...\n",
      "Storing \"fatalities002_joint_narrow_xgb_calib\"\n",
      "cm_fatalities002_joint_narrow_xgb_calib , run Fatalities002 force_rewrite=True, predicting\n",
      "Test partition 2024-03-28 15:48:43.107608\n",
      " * == Performing a run: \"fatalities002_joint_narrow_xgb_test\" == * \n",
      "Model object named \"fatalities002_joint_narrow_xgb_test\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_joint_narrow_xgb_test\"\n",
      "Training model(s)...\n",
      "Storing \"fatalities002_joint_narrow_xgb_test\"\n",
      "cm_fatalities002_joint_narrow_xgb_test , run Fatalities002 force_rewrite=True, predicting\n",
      "13 fatalities002_joint_narrow_hurdle_xgb\n",
      "Calibration partition 2024-03-28 15:50:05.161674\n",
      " * == Performing a run: \"fatalities002_joint_narrow_hurdle_xgb_calib\" == * \n",
      "Model object named \"fatalities002_joint_narrow_hurdle_xgb_calib\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_joint_narrow_hurdle_xgb_calib\"\n",
      "Training model(s)...\n",
      "Storing \"fatalities002_joint_narrow_hurdle_xgb_calib\"\n",
      "cm_fatalities002_joint_narrow_hurdle_xgb_calib , run Fatalities002 force_rewrite=True, predicting\n",
      "Test partition 2024-03-28 15:50:50.256322\n",
      " * == Performing a run: \"fatalities002_joint_narrow_hurdle_xgb_test\" == * \n",
      "Model object named \"fatalities002_joint_narrow_hurdle_xgb_test\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_joint_narrow_hurdle_xgb_test\"\n",
      "Training model(s)...\n",
      "Storing \"fatalities002_joint_narrow_hurdle_xgb_test\"\n",
      "cm_fatalities002_joint_narrow_hurdle_xgb_test , run Fatalities002 force_rewrite=True, predicting\n",
      "14 fatalities002_joint_narrow_hurdle_lgb\n",
      "Calibration partition 2024-03-28 15:51:38.477419\n",
      " * == Performing a run: \"fatalities002_joint_narrow_hurdle_lgb_calib\" == * \n",
      "Model object named \"fatalities002_joint_narrow_hurdle_lgb_calib\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_joint_narrow_hurdle_lgb_calib\"\n",
      "Training model(s)...\n",
      "[LightGBM] [Info] Number of positive: 5545, number of negative: 41061\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46606, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118976 -> initscore=-2.002162\n",
      "[LightGBM] [Info] Start training from score -2.002162\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6737\n",
      "[LightGBM] [Info] Number of data points in the train set: 5545, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.391455\n",
      "[LightGBM] [Info] Number of positive: 5519, number of negative: 40881\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7493\n",
      "[LightGBM] [Info] Number of data points in the train set: 46400, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118944 -> initscore=-2.002469\n",
      "[LightGBM] [Info] Start training from score -2.002469\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6733\n",
      "[LightGBM] [Info] Number of data points in the train set: 5519, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.387713\n",
      "[LightGBM] [Info] Number of positive: 5488, number of negative: 40706\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7492\n",
      "[LightGBM] [Info] Number of data points in the train set: 46194, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118803 -> initscore=-2.003812\n",
      "[LightGBM] [Info] Start training from score -2.003812\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6741\n",
      "[LightGBM] [Info] Number of data points in the train set: 5488, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.386294\n",
      "[LightGBM] [Info] Number of positive: 5458, number of negative: 40531\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7494\n",
      "[LightGBM] [Info] Number of data points in the train set: 45989, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118681 -> initscore=-2.004985\n",
      "[LightGBM] [Info] Start training from score -2.004985\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6734\n",
      "[LightGBM] [Info] Number of data points in the train set: 5458, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.384750\n",
      "[LightGBM] [Info] Number of positive: 5429, number of negative: 40355\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7490\n",
      "[LightGBM] [Info] Number of data points in the train set: 45784, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118579 -> initscore=-2.005960\n",
      "[LightGBM] [Info] Start training from score -2.005960\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6738\n",
      "[LightGBM] [Info] Number of data points in the train set: 5429, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.384959\n",
      "[LightGBM] [Info] Number of positive: 5401, number of negative: 40180\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7491\n",
      "[LightGBM] [Info] Number of data points in the train set: 45581, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118492 -> initscore=-2.006785\n",
      "[LightGBM] [Info] Start training from score -2.006785\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6747\n",
      "[LightGBM] [Info] Number of data points in the train set: 5401, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.383308\n",
      "[LightGBM] [Info] Number of positive: 5374, number of negative: 40005\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7491\n",
      "[LightGBM] [Info] Number of data points in the train set: 45379, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118425 -> initscore=-2.007432\n",
      "[LightGBM] [Info] Start training from score -2.007432\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6738\n",
      "[LightGBM] [Info] Number of data points in the train set: 5374, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.380362\n",
      "[LightGBM] [Info] Number of positive: 5344, number of negative: 39833\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7492\n",
      "[LightGBM] [Info] Number of data points in the train set: 45177, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118290 -> initscore=-2.008721\n",
      "[LightGBM] [Info] Start training from score -2.008721\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6732\n",
      "[LightGBM] [Info] Number of data points in the train set: 5344, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.379547\n",
      "[LightGBM] [Info] Number of positive: 5311, number of negative: 39664\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7492\n",
      "[LightGBM] [Info] Number of data points in the train set: 44975, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118088 -> initscore=-2.010664\n",
      "[LightGBM] [Info] Start training from score -2.010664\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6737\n",
      "[LightGBM] [Info] Number of data points in the train set: 5311, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.380101\n",
      "[LightGBM] [Info] Number of positive: 5281, number of negative: 39492\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7487\n",
      "[LightGBM] [Info] Number of data points in the train set: 44773, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117951 -> initscore=-2.011983\n",
      "[LightGBM] [Info] Start training from score -2.011983\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6726\n",
      "[LightGBM] [Info] Number of data points in the train set: 5281, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.376092\n",
      "[LightGBM] [Info] Number of positive: 5252, number of negative: 39321\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7483\n",
      "[LightGBM] [Info] Number of data points in the train set: 44573, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117829 -> initscore=-2.013150\n",
      "[LightGBM] [Info] Start training from score -2.013150\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6714\n",
      "[LightGBM] [Info] Number of data points in the train set: 5252, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.375903\n",
      "[LightGBM] [Info] Number of positive: 5218, number of negative: 39155\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7479\n",
      "[LightGBM] [Info] Number of data points in the train set: 44373, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117594 -> initscore=-2.015414\n",
      "[LightGBM] [Info] Start training from score -2.015414\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6712\n",
      "[LightGBM] [Info] Number of data points in the train set: 5218, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.375498\n",
      "[LightGBM] [Info] Number of positive: 5188, number of negative: 38985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7479\n",
      "[LightGBM] [Info] Number of data points in the train set: 44173, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117447 -> initscore=-2.016829\n",
      "[LightGBM] [Info] Start training from score -2.016829\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6716\n",
      "[LightGBM] [Info] Number of data points in the train set: 5188, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.375122\n",
      "[LightGBM] [Info] Number of positive: 5162, number of negative: 38811\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7480\n",
      "[LightGBM] [Info] Number of data points in the train set: 43973, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117390 -> initscore=-2.017380\n",
      "[LightGBM] [Info] Start training from score -2.017380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6705\n",
      "[LightGBM] [Info] Number of data points in the train set: 5162, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.372283\n",
      "[LightGBM] [Info] Number of positive: 5132, number of negative: 38641\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7485\n",
      "[LightGBM] [Info] Number of data points in the train set: 43773, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117241 -> initscore=-2.018818\n",
      "[LightGBM] [Info] Start training from score -2.018818\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6706\n",
      "[LightGBM] [Info] Number of data points in the train set: 5132, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.371381\n",
      "[LightGBM] [Info] Number of positive: 5100, number of negative: 38473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7484\n",
      "[LightGBM] [Info] Number of data points in the train set: 43573, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117045 -> initscore=-2.020716\n",
      "[LightGBM] [Info] Start training from score -2.020716\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6708\n",
      "[LightGBM] [Info] Number of data points in the train set: 5100, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.368761\n",
      "[LightGBM] [Info] Number of positive: 5069, number of negative: 38304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7482\n",
      "[LightGBM] [Info] Number of data points in the train set: 43373, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116870 -> initscore=-2.022411\n",
      "[LightGBM] [Info] Start training from score -2.022411\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6721\n",
      "[LightGBM] [Info] Number of data points in the train set: 5069, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.366348\n",
      "[LightGBM] [Info] Number of positive: 5044, number of negative: 38129\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7480\n",
      "[LightGBM] [Info] Number of data points in the train set: 43173, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116832 -> initscore=-2.022776\n",
      "[LightGBM] [Info] Start training from score -2.022776\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6709\n",
      "[LightGBM] [Info] Number of data points in the train set: 5044, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.364531\n",
      "[LightGBM] [Info] Number of positive: 5022, number of negative: 37951\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7479\n",
      "[LightGBM] [Info] Number of data points in the train set: 42973, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116864 -> initscore=-2.022468\n",
      "[LightGBM] [Info] Start training from score -2.022468\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6712\n",
      "[LightGBM] [Info] Number of data points in the train set: 5022, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.362757\n",
      "[LightGBM] [Info] Number of positive: 4995, number of negative: 37778\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7482\n",
      "[LightGBM] [Info] Number of data points in the train set: 42773, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116779 -> initscore=-2.023290\n",
      "[LightGBM] [Info] Start training from score -2.023290\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000993 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6709\n",
      "[LightGBM] [Info] Number of data points in the train set: 4995, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.360102\n",
      "[LightGBM] [Info] Number of positive: 4966, number of negative: 37608\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7481\n",
      "[LightGBM] [Info] Number of data points in the train set: 42574, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116644 -> initscore=-2.024602\n",
      "[LightGBM] [Info] Start training from score -2.024602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6696\n",
      "[LightGBM] [Info] Number of data points in the train set: 4966, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.360760\n",
      "[LightGBM] [Info] Number of positive: 4939, number of negative: 37437\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7480\n",
      "[LightGBM] [Info] Number of data points in the train set: 42376, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116552 -> initscore=-2.025497\n",
      "[LightGBM] [Info] Start training from score -2.025497\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6678\n",
      "[LightGBM] [Info] Number of data points in the train set: 4939, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.358953\n",
      "[LightGBM] [Info] Number of positive: 4907, number of negative: 37271\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7479\n",
      "[LightGBM] [Info] Number of data points in the train set: 42178, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116340 -> initscore=-2.027553\n",
      "[LightGBM] [Info] Start training from score -2.027553\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6661\n",
      "[LightGBM] [Info] Number of data points in the train set: 4907, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.357955\n",
      "[LightGBM] [Info] Number of positive: 4876, number of negative: 37105\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7480\n",
      "[LightGBM] [Info] Number of data points in the train set: 41981, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116148 -> initscore=-2.029427\n",
      "[LightGBM] [Info] Start training from score -2.029427\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6648\n",
      "[LightGBM] [Info] Number of data points in the train set: 4876, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.357032\n",
      "[LightGBM] [Info] Number of positive: 4848, number of negative: 36936\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7477\n",
      "[LightGBM] [Info] Number of data points in the train set: 41784, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116025 -> initscore=-2.030620\n",
      "[LightGBM] [Info] Start training from score -2.030620\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6652\n",
      "[LightGBM] [Info] Number of data points in the train set: 4848, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.355826\n",
      "[LightGBM] [Info] Number of positive: 4818, number of negative: 36769\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7479\n",
      "[LightGBM] [Info] Number of data points in the train set: 41587, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115854 -> initscore=-2.032296\n",
      "[LightGBM] [Info] Start training from score -2.032296\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6642\n",
      "[LightGBM] [Info] Number of data points in the train set: 4818, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.356424\n",
      "[LightGBM] [Info] Number of positive: 4792, number of negative: 36598\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7481\n",
      "[LightGBM] [Info] Number of data points in the train set: 41390, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115777 -> initscore=-2.033046\n",
      "[LightGBM] [Info] Start training from score -2.033046\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6639\n",
      "[LightGBM] [Info] Number of data points in the train set: 4792, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.356996\n",
      "[LightGBM] [Info] Number of positive: 4768, number of negative: 36425\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7477\n",
      "[LightGBM] [Info] Number of data points in the train set: 41193, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115748 -> initscore=-2.033328\n",
      "[LightGBM] [Info] Start training from score -2.033328\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6651\n",
      "[LightGBM] [Info] Number of data points in the train set: 4768, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.358757\n",
      "[LightGBM] [Info] Number of positive: 4747, number of negative: 36249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7472\n",
      "[LightGBM] [Info] Number of data points in the train set: 40996, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115792 -> initscore=-2.032899\n",
      "[LightGBM] [Info] Start training from score -2.032899\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6638\n",
      "[LightGBM] [Info] Number of data points in the train set: 4747, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.357227\n",
      "[LightGBM] [Info] Number of positive: 4725, number of negative: 36074\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7472\n",
      "[LightGBM] [Info] Number of data points in the train set: 40799, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115812 -> initscore=-2.032705\n",
      "[LightGBM] [Info] Start training from score -2.032705\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6634\n",
      "[LightGBM] [Info] Number of data points in the train set: 4725, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.356150\n",
      "[LightGBM] [Info] Number of positive: 4702, number of negative: 35900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7467\n",
      "[LightGBM] [Info] Number of data points in the train set: 40602, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115807 -> initscore=-2.032749\n",
      "[LightGBM] [Info] Start training from score -2.032749\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6629\n",
      "[LightGBM] [Info] Number of data points in the train set: 4702, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.357821\n",
      "[LightGBM] [Info] Number of positive: 4676, number of negative: 35729\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7463\n",
      "[LightGBM] [Info] Number of data points in the train set: 40405, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115728 -> initscore=-2.033520\n",
      "[LightGBM] [Info] Start training from score -2.033520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6633\n",
      "[LightGBM] [Info] Number of data points in the train set: 4676, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.359241\n",
      "[LightGBM] [Info] Number of positive: 4648, number of negative: 35560\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7467\n",
      "[LightGBM] [Info] Number of data points in the train set: 40208, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115599 -> initscore=-2.034784\n",
      "[LightGBM] [Info] Start training from score -2.034784\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6615\n",
      "[LightGBM] [Info] Number of data points in the train set: 4648, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.360724\n",
      "[LightGBM] [Info] Number of positive: 4624, number of negative: 35387\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7463\n",
      "[LightGBM] [Info] Number of data points in the train set: 40011, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115568 -> initscore=-2.035084\n",
      "[LightGBM] [Info] Start training from score -2.035084\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4624, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.361289\n",
      "[LightGBM] [Info] Number of positive: 4602, number of negative: 35214\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 39816, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115582 -> initscore=-2.034953\n",
      "[LightGBM] [Info] Start training from score -2.034953\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6586\n",
      "[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.361227\n",
      "[LightGBM] [Info] Number of positive: 4574, number of negative: 35047\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7463\n",
      "[LightGBM] [Info] Number of data points in the train set: 39621, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115444 -> initscore=-2.036302\n",
      "[LightGBM] [Info] Start training from score -2.036302\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6586\n",
      "[LightGBM] [Info] Number of data points in the train set: 4574, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.361714\n",
      "Storing \"fatalities002_joint_narrow_hurdle_lgb_calib\"\n",
      "cm_fatalities002_joint_narrow_hurdle_lgb_calib , run Fatalities002 force_rewrite=True, predicting\n",
      "Test partition 2024-03-28 15:52:38.740342\n",
      " * == Performing a run: \"fatalities002_joint_narrow_hurdle_lgb_test\" == * \n",
      "Model object named \"fatalities002_joint_narrow_hurdle_lgb_test\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_joint_narrow_hurdle_lgb_test\"\n",
      "Training model(s)...\n",
      "[LightGBM] [Info] Number of positive: 6659, number of negative: 49108\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7507\n",
      "[LightGBM] [Info] Number of data points in the train set: 55767, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.119408 -> initscore=-1.998053\n",
      "[LightGBM] [Info] Start training from score -1.998053\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6906\n",
      "[LightGBM] [Info] Number of data points in the train set: 6659, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.416581\n",
      "[LightGBM] [Info] Number of positive: 6631, number of negative: 48928\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7507\n",
      "[LightGBM] [Info] Number of data points in the train set: 55559, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.119351 -> initscore=-1.998594\n",
      "[LightGBM] [Info] Start training from score -1.998594\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6898\n",
      "[LightGBM] [Info] Number of data points in the train set: 6631, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.413810\n",
      "[LightGBM] [Info] Number of positive: 6598, number of negative: 48753\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7505\n",
      "[LightGBM] [Info] Number of data points in the train set: 55351, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.119203 -> initscore=-2.000000\n",
      "[LightGBM] [Info] Start training from score -2.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6901\n",
      "[LightGBM] [Info] Number of data points in the train set: 6598, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.412819\n",
      "[LightGBM] [Info] Number of positive: 6566, number of negative: 48578\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7502\n",
      "[LightGBM] [Info] Number of data points in the train set: 55144, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.119070 -> initscore=-2.001266\n",
      "[LightGBM] [Info] Start training from score -2.001266\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6913\n",
      "[LightGBM] [Info] Number of data points in the train set: 6566, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.411518\n",
      "[LightGBM] [Info] Number of positive: 6535, number of negative: 48402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7502\n",
      "[LightGBM] [Info] Number of data points in the train set: 54937, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118954 -> initscore=-2.002369\n",
      "[LightGBM] [Info] Start training from score -2.002369\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6924\n",
      "[LightGBM] [Info] Number of data points in the train set: 6535, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.412013\n",
      "[LightGBM] [Info] Number of positive: 6505, number of negative: 48227\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7499\n",
      "[LightGBM] [Info] Number of data points in the train set: 54732, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118852 -> initscore=-2.003348\n",
      "[LightGBM] [Info] Start training from score -2.003348\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6926\n",
      "[LightGBM] [Info] Number of data points in the train set: 6505, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.410588\n",
      "[LightGBM] [Info] Number of positive: 6477, number of negative: 48051\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7499\n",
      "[LightGBM] [Info] Number of data points in the train set: 54528, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118783 -> initscore=-2.004006\n",
      "[LightGBM] [Info] Start training from score -2.004006\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6916\n",
      "[LightGBM] [Info] Number of data points in the train set: 6477, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.408126\n",
      "[LightGBM] [Info] Number of positive: 6446, number of negative: 47878\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7496\n",
      "[LightGBM] [Info] Number of data points in the train set: 54324, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118658 -> initscore=-2.005196\n",
      "[LightGBM] [Info] Start training from score -2.005196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6921\n",
      "[LightGBM] [Info] Number of data points in the train set: 6446, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.407298\n",
      "[LightGBM] [Info] Number of positive: 6411, number of negative: 47709\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7497\n",
      "[LightGBM] [Info] Number of data points in the train set: 54120, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118459 -> initscore=-2.007105\n",
      "[LightGBM] [Info] Start training from score -2.007105\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6908\n",
      "[LightGBM] [Info] Number of data points in the train set: 6411, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.407403\n",
      "[LightGBM] [Info] Number of positive: 6379, number of negative: 47537\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7500\n",
      "[LightGBM] [Info] Number of data points in the train set: 53916, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118314 -> initscore=-2.008497\n",
      "[LightGBM] [Info] Start training from score -2.008497\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6907\n",
      "[LightGBM] [Info] Number of data points in the train set: 6379, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.403711\n",
      "[LightGBM] [Info] Number of positive: 6348, number of negative: 47366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001810 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7500\n",
      "[LightGBM] [Info] Number of data points in the train set: 53714, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118181 -> initscore=-2.009765\n",
      "[LightGBM] [Info] Start training from score -2.009765\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6898\n",
      "[LightGBM] [Info] Number of data points in the train set: 6348, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.403675\n",
      "[LightGBM] [Info] Number of positive: 6313, number of negative: 47199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001751 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7497\n",
      "[LightGBM] [Info] Number of data points in the train set: 53512, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117974 -> initscore=-2.011762\n",
      "[LightGBM] [Info] Start training from score -2.011762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6891\n",
      "[LightGBM] [Info] Number of data points in the train set: 6313, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.403394\n",
      "[LightGBM] [Info] Number of positive: 6282, number of negative: 47028\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002064 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7497\n",
      "[LightGBM] [Info] Number of data points in the train set: 53310, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117839 -> initscore=-2.013055\n",
      "[LightGBM] [Info] Start training from score -2.013055\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 6282, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.402993\n",
      "[LightGBM] [Info] Number of positive: 6255, number of negative: 46853\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7493\n",
      "[LightGBM] [Info] Number of data points in the train set: 53108, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117779 -> initscore=-2.013634\n",
      "[LightGBM] [Info] Start training from score -2.013634\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6876\n",
      "[LightGBM] [Info] Number of data points in the train set: 6255, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.400724\n",
      "[LightGBM] [Info] Number of positive: 6224, number of negative: 46682\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7494\n",
      "[LightGBM] [Info] Number of data points in the train set: 52906, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117643 -> initscore=-2.014946\n",
      "[LightGBM] [Info] Start training from score -2.014946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6892\n",
      "[LightGBM] [Info] Number of data points in the train set: 6224, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.399727\n",
      "[LightGBM] [Info] Number of positive: 6190, number of negative: 46514\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7493\n",
      "[LightGBM] [Info] Number of data points in the train set: 52704, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117448 -> initscore=-2.016818\n",
      "[LightGBM] [Info] Start training from score -2.016818\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6887\n",
      "[LightGBM] [Info] Number of data points in the train set: 6190, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.397924\n",
      "[LightGBM] [Info] Number of positive: 6158, number of negative: 46344\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7489\n",
      "[LightGBM] [Info] Number of data points in the train set: 52502, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117291 -> initscore=-2.018340\n",
      "[LightGBM] [Info] Start training from score -2.018340\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6896\n",
      "[LightGBM] [Info] Number of data points in the train set: 6158, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.396247\n",
      "[LightGBM] [Info] Number of positive: 6131, number of negative: 46169\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7491\n",
      "[LightGBM] [Info] Number of data points in the train set: 52300, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117228 -> initscore=-2.018951\n",
      "[LightGBM] [Info] Start training from score -2.018951\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6893\n",
      "[LightGBM] [Info] Number of data points in the train set: 6131, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.395018\n",
      "[LightGBM] [Info] Number of positive: 6108, number of negative: 45990\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7490\n",
      "[LightGBM] [Info] Number of data points in the train set: 52098, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117241 -> initscore=-2.018825\n",
      "[LightGBM] [Info] Start training from score -2.018825\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6905\n",
      "[LightGBM] [Info] Number of data points in the train set: 6108, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.393386\n",
      "[LightGBM] [Info] Number of positive: 6079, number of negative: 45817\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7490\n",
      "[LightGBM] [Info] Number of data points in the train set: 51896, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117138 -> initscore=-2.019815\n",
      "[LightGBM] [Info] Start training from score -2.019815\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6912\n",
      "[LightGBM] [Info] Number of data points in the train set: 6079, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.391456\n",
      "[LightGBM] [Info] Number of positive: 6049, number of negative: 45646\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7489\n",
      "[LightGBM] [Info] Number of data points in the train set: 51695, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117013 -> initscore=-2.021023\n",
      "[LightGBM] [Info] Start training from score -2.021023\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6909\n",
      "[LightGBM] [Info] Number of data points in the train set: 6049, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.392411\n",
      "[LightGBM] [Info] Number of positive: 6020, number of negative: 45475\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7488\n",
      "[LightGBM] [Info] Number of data points in the train set: 51495, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116905 -> initscore=-2.022075\n",
      "[LightGBM] [Info] Start training from score -2.022075\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6886\n",
      "[LightGBM] [Info] Number of data points in the train set: 6020, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.391247\n",
      "[LightGBM] [Info] Number of positive: 5986, number of negative: 45309\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7489\n",
      "[LightGBM] [Info] Number of data points in the train set: 51295, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116698 -> initscore=-2.024082\n",
      "[LightGBM] [Info] Start training from score -2.024082\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6872\n",
      "[LightGBM] [Info] Number of data points in the train set: 5986, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.390725\n",
      "[LightGBM] [Info] Number of positive: 5954, number of negative: 45142\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7490\n",
      "[LightGBM] [Info] Number of data points in the train set: 51096, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116526 -> initscore=-2.025750\n",
      "[LightGBM] [Info] Start training from score -2.025750\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000902 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6872\n",
      "[LightGBM] [Info] Number of data points in the train set: 5954, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.390477\n",
      "[LightGBM] [Info] Number of positive: 5925, number of negative: 44972\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7488\n",
      "[LightGBM] [Info] Number of data points in the train set: 50897, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116412 -> initscore=-2.026859\n",
      "[LightGBM] [Info] Start training from score -2.026859\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6858\n",
      "[LightGBM] [Info] Number of data points in the train set: 5925, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.389678\n",
      "[LightGBM] [Info] Number of positive: 5894, number of negative: 44804\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7489\n",
      "[LightGBM] [Info] Number of data points in the train set: 50698, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116257 -> initscore=-2.028363\n",
      "[LightGBM] [Info] Start training from score -2.028363\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6859\n",
      "[LightGBM] [Info] Number of data points in the train set: 5894, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.390507\n",
      "[LightGBM] [Info] Number of positive: 5868, number of negative: 44631\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7492\n",
      "[LightGBM] [Info] Number of data points in the train set: 50499, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116200 -> initscore=-2.028915\n",
      "[LightGBM] [Info] Start training from score -2.028915\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6861\n",
      "[LightGBM] [Info] Number of data points in the train set: 5868, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.391125\n",
      "[LightGBM] [Info] Number of positive: 5842, number of negative: 44458\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7491\n",
      "[LightGBM] [Info] Number of data points in the train set: 50300, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116143 -> initscore=-2.029472\n",
      "[LightGBM] [Info] Start training from score -2.029472\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6862\n",
      "[LightGBM] [Info] Number of data points in the train set: 5842, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.392952\n",
      "[LightGBM] [Info] Number of positive: 5820, number of negative: 44281\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7490\n",
      "[LightGBM] [Info] Number of data points in the train set: 50101, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116165 -> initscore=-2.029255\n",
      "[LightGBM] [Info] Start training from score -2.029255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6864\n",
      "[LightGBM] [Info] Number of data points in the train set: 5820, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.391776\n",
      "[LightGBM] [Info] Number of positive: 5796, number of negative: 44106\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7490\n",
      "[LightGBM] [Info] Number of data points in the train set: 49902, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116148 -> initscore=-2.029428\n",
      "[LightGBM] [Info] Start training from score -2.029428\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6881\n",
      "[LightGBM] [Info] Number of data points in the train set: 5796, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.390558\n",
      "[LightGBM] [Info] Number of positive: 5771, number of negative: 43932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7488\n",
      "[LightGBM] [Info] Number of data points in the train set: 49703, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116110 -> initscore=-2.029798\n",
      "[LightGBM] [Info] Start training from score -2.029798\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 5771, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.391638\n",
      "[LightGBM] [Info] Number of positive: 5743, number of negative: 43761\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7486\n",
      "[LightGBM] [Info] Number of data points in the train set: 49504, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116011 -> initscore=-2.030761\n",
      "[LightGBM] [Info] Start training from score -2.030761\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 5743, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.392328\n",
      "[LightGBM] [Info] Number of positive: 5713, number of negative: 43592\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7484\n",
      "[LightGBM] [Info] Number of data points in the train set: 49305, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115871 -> initscore=-2.032129\n",
      "[LightGBM] [Info] Start training from score -2.032129\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6862\n",
      "[LightGBM] [Info] Number of data points in the train set: 5713, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.393193\n",
      "[LightGBM] [Info] Number of positive: 5687, number of negative: 43419\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7486\n",
      "[LightGBM] [Info] Number of data points in the train set: 49106, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115811 -> initscore=-2.032714\n",
      "[LightGBM] [Info] Start training from score -2.032714\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6853\n",
      "[LightGBM] [Info] Number of data points in the train set: 5687, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.393366\n",
      "[LightGBM] [Info] Number of positive: 5664, number of negative: 43243\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7488\n",
      "[LightGBM] [Info] Number of data points in the train set: 48907, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115812 -> initscore=-2.032705\n",
      "[LightGBM] [Info] Start training from score -2.032705\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6829\n",
      "[LightGBM] [Info] Number of data points in the train set: 5664, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.393221\n",
      "[LightGBM] [Info] Number of positive: 5634, number of negative: 43074\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7489\n",
      "[LightGBM] [Info] Number of data points in the train set: 48708, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115669 -> initscore=-2.034100\n",
      "[LightGBM] [Info] Start training from score -2.034100\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6828\n",
      "[LightGBM] [Info] Number of data points in the train set: 5634, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 3.393677\n",
      "Storing \"fatalities002_joint_narrow_hurdle_lgb_test\"\n",
      "cm_fatalities002_joint_narrow_hurdle_lgb_test , run Fatalities002 force_rewrite=True, predicting\n",
      "15 fatalities002_all_pca3_xgb\n",
      "Calibration partition 2024-03-28 15:53:42.647389\n",
      " * == Performing a run: \"fatalities002_all_pca3_xgb_calib\" == * \n",
      "Model object named \"fatalities002_all_pca3_xgb_calib\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_all_pca3_xgb_calib\"\n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities002_all_pca3_xgb_calib\"\n",
      "cm_fatalities002_all_pca3_xgb_calib , run Fatalities002 force_rewrite=True, predicting\n",
      "Test partition 2024-03-28 15:55:52.503601\n",
      " * == Performing a run: \"fatalities002_all_pca3_xgb_test\" == * \n",
      "Model object named \"fatalities002_all_pca3_xgb_test\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_all_pca3_xgb_test\"\n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities002_all_pca3_xgb_test\"\n",
      "cm_fatalities002_all_pca3_xgb_test , run Fatalities002 force_rewrite=True, predicting\n",
      "16 fatalities002_aquastat_rf\n",
      "Calibration partition 2024-03-28 15:58:08.022987\n",
      " * == Performing a run: \"fatalities002_aquastat_rf_calib\" == * \n",
      "Model object named \"fatalities002_aquastat_rf_calib\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_aquastat_rf_calib\"\n",
      "Training model(s)...\n",
      "Storing \"fatalities002_aquastat_rf_calib\"\n",
      "cm_fatalities002_aquastat_rf_calib , run Fatalities002 force_rewrite=True, predicting\n",
      "Test partition 2024-03-28 15:59:17.204642\n",
      " * == Performing a run: \"fatalities002_aquastat_rf_test\" == * \n",
      "Model object named \"fatalities002_aquastat_rf_test\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_aquastat_rf_test\"\n",
      "Training model(s)...\n",
      "Storing \"fatalities002_aquastat_rf_test\"\n",
      "cm_fatalities002_aquastat_rf_test , run Fatalities002 force_rewrite=True, predicting\n",
      "17 fatalities002_faostat_rf\n",
      "Calibration partition 2024-03-28 16:00:29.443095\n",
      " * == Performing a run: \"fatalities002_faostat_rf_calib\" == * \n",
      "Model object named \"fatalities002_faostat_rf_calib\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_faostat_rf_calib\"\n",
      "Training model(s)...\n",
      "Storing \"fatalities002_faostat_rf_calib\"\n",
      "cm_fatalities002_faostat_rf_calib , run Fatalities002 force_rewrite=True, predicting\n",
      "Test partition 2024-03-28 16:02:00.687662\n",
      " * == Performing a run: \"fatalities002_faostat_rf_test\" == * \n",
      "Model object named \"fatalities002_faostat_rf_test\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_faostat_rf_test\"\n",
      "Training model(s)...\n",
      "Storing \"fatalities002_faostat_rf_test\"\n",
      "cm_fatalities002_faostat_rf_test , run Fatalities002 force_rewrite=True, predicting\n",
      "18 fatalities002_faoprices_rf\n",
      "Calibration partition 2024-03-28 16:03:35.844921\n",
      " * == Performing a run: \"fatalities002_faoprices_rf_calib\" == * \n",
      "Model object named \"fatalities002_faoprices_rf_calib\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_faoprices_rf_calib\"\n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities002_faoprices_rf_calib\"\n",
      "cm_fatalities002_faoprices_rf_calib , run Fatalities002 force_rewrite=True, predicting\n",
      "Test partition 2024-03-28 16:04:39.156789\n",
      " * == Performing a run: \"fatalities002_faoprices_rf_test\" == * \n",
      "Model object named \"fatalities002_faoprices_rf_test\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_faoprices_rf_test\"\n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities002_faoprices_rf_test\"\n",
      "cm_fatalities002_faoprices_rf_test , run Fatalities002 force_rewrite=True, predicting\n",
      "19 fatalities002_imfweo_rf\n",
      "Calibration partition 2024-03-28 16:05:44.344149\n",
      " * == Performing a run: \"fatalities002_imfweo_rf_calib\" == * \n",
      "Model object named \"fatalities002_imfweo_rf_calib\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_imfweo_rf_calib\"\n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities002_imfweo_rf_calib\"\n",
      "cm_fatalities002_imfweo_rf_calib , run Fatalities002 force_rewrite=True, predicting\n",
      "Test partition 2024-03-28 16:06:40.382123\n",
      " * == Performing a run: \"fatalities002_imfweo_rf_test\" == * \n",
      "Model object named \"fatalities002_imfweo_rf_test\" with equivalent metadata already exists.\n",
      "Retrain is true, overwriting \"fatalities002_imfweo_rf_test\"\n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities002_imfweo_rf_test\"\n",
      "cm_fatalities002_imfweo_rf_test , run Fatalities002 force_rewrite=True, predicting\n",
      "20 fatalities002_Markov_glm\n",
      "Calibration partition 2024-03-28 16:07:40.448323\n",
      "Trying to retrieve predictions 2024-03-28 16:07:40.448323\n",
      "cm_fatalities002_Markov_glm_calib , run Fatalities002 force_retrain = True, predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3.81M/3.81M [00:01<00:00, 2.18MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_joint_narrow read successfully \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n",
      "✔ dplyr     1.1.0     ✔ readr     2.1.4\n",
      "✔ forcats   1.0.0     ✔ stringr   1.5.0\n",
      "✔ ggplot2   3.4.1     ✔ tibble    3.2.0\n",
      "✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n",
      "✔ purrr     1.0.1     \n",
      "── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ dplyr::filter() masks stats::filter()\n",
      "✖ dplyr::lag()    masks stats::lag()\n",
      "ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n",
      "\n",
      "Attaching package: ‘magrittr’\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    set_names\n",
      "\n",
      "The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    extract\n",
      "\n",
      "\n",
      "Attaching package: ‘arrow’\n",
      "\n",
      "The following object is masked from ‘package:magrittr’:\n",
      "\n",
      "    is_in\n",
      "\n",
      "The following object is masked from ‘package:lubridate’:\n",
      "\n",
      "    duration\n",
      "\n",
      "The following object is masked from ‘package:utils’:\n",
      "\n",
      "    timestamp\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " All required packages installed \n",
      "\n",
      " Packages loaded, starting script \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were 50 or more warnings (use warnings() to see the first 50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Rscript finished! \n",
      "Test partition 2024-03-28 16:18:43.238126\n",
      "cm_fatalities002_Markov_glm_test , run Fatalities002 force_retrain=True, predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3.81M/3.81M [00:01<00:00, 2.11MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_joint_narrow read successfully \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n",
      "✔ dplyr     1.1.0     ✔ readr     2.1.4\n",
      "✔ forcats   1.0.0     ✔ stringr   1.5.0\n",
      "✔ ggplot2   3.4.1     ✔ tibble    3.2.0\n",
      "✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n",
      "✔ purrr     1.0.1     \n",
      "── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ dplyr::filter() masks stats::filter()\n",
      "✖ dplyr::lag()    masks stats::lag()\n",
      "ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n",
      "\n",
      "Attaching package: ‘magrittr’\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    set_names\n",
      "\n",
      "The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    extract\n",
      "\n",
      "\n",
      "Attaching package: ‘arrow’\n",
      "\n",
      "The following object is masked from ‘package:magrittr’:\n",
      "\n",
      "    is_in\n",
      "\n",
      "The following object is masked from ‘package:lubridate’:\n",
      "\n",
      "    duration\n",
      "\n",
      "The following object is masked from ‘package:utils’:\n",
      "\n",
      "    timestamp\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " All required packages installed \n",
      "\n",
      " Packages loaded, starting script \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were 50 or more warnings (use warnings() to see the first 50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Rscript finished! \n",
      "**************************************************************\n",
      "21 fatalities002_Markov_rf\n",
      "Calibration partition 2024-03-28 16:31:23.332600\n",
      "Trying to retrieve predictions 2024-03-28 16:31:23.332600\n",
      "cm_fatalities002_Markov_rf_calib , run Fatalities002 force_retrain = True, predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3.81M/3.81M [00:01<00:00, 1.98MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_joint_narrow read successfully \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n",
      "✔ dplyr     1.1.0     ✔ readr     2.1.4\n",
      "✔ forcats   1.0.0     ✔ stringr   1.5.0\n",
      "✔ ggplot2   3.4.1     ✔ tibble    3.2.0\n",
      "✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n",
      "✔ purrr     1.0.1     \n",
      "── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ dplyr::filter() masks stats::filter()\n",
      "✖ dplyr::lag()    masks stats::lag()\n",
      "ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n",
      "\n",
      "Attaching package: ‘magrittr’\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    set_names\n",
      "\n",
      "The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    extract\n",
      "\n",
      "\n",
      "Attaching package: ‘arrow’\n",
      "\n",
      "The following object is masked from ‘package:magrittr’:\n",
      "\n",
      "    is_in\n",
      "\n",
      "The following object is masked from ‘package:lubridate’:\n",
      "\n",
      "    duration\n",
      "\n",
      "The following object is masked from ‘package:utils’:\n",
      "\n",
      "    timestamp\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " All required packages installed \n",
      "\n",
      " Packages loaded, starting script \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were 50 or more warnings (use warnings() to see the first 50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Rscript finished! \n",
      "Test partition 2024-03-28 16:36:07.426222\n",
      "cm_fatalities002_Markov_rf_test , run Fatalities002 force_retrain=True, predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3.81M/3.81M [00:01<00:00, 3.61MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queryset fatalities002_joint_narrow read successfully \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n",
      "✔ dplyr     1.1.0     ✔ readr     2.1.4\n",
      "✔ forcats   1.0.0     ✔ stringr   1.5.0\n",
      "✔ ggplot2   3.4.1     ✔ tibble    3.2.0\n",
      "✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n",
      "✔ purrr     1.0.1     \n",
      "── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ dplyr::filter() masks stats::filter()\n",
      "✖ dplyr::lag()    masks stats::lag()\n",
      "ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n",
      "\n",
      "Attaching package: ‘magrittr’\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    set_names\n",
      "\n",
      "The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    extract\n",
      "\n",
      "\n",
      "Attaching package: ‘arrow’\n",
      "\n",
      "The following object is masked from ‘package:magrittr’:\n",
      "\n",
      "    is_in\n",
      "\n",
      "The following object is masked from ‘package:lubridate’:\n",
      "\n",
      "    duration\n",
      "\n",
      "The following object is masked from ‘package:utils’:\n",
      "\n",
      "    timestamp\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " All required packages installed \n",
      "\n",
      " Packages loaded, starting script \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were 50 or more warnings (use warnings() to see the first 50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Rscript finished! \n",
      "**************************************************************\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "# Loop that checks whether the model exists, retrains if not, \n",
    "# and stores the predictions if they have not been stored before for this run.\n",
    "# To do: set the data_preprocessing to the function in the model dictionary\n",
    "\n",
    "level = 'cm'\n",
    "includeFuture = False\n",
    "force_rewrite = True\n",
    "force_retrain = True\n",
    "\n",
    "from views_runs import Storage, StepshiftedModels\n",
    "from views_partitioning.data_partitioner import DataPartitioner\n",
    "from viewser import Queryset, Column\n",
    "from views_runs import operations\n",
    "from views_runs.run_result import RunResult\n",
    "from new_markov import markov\n",
    "\n",
    "i = 0\n",
    "for model in ModelList[:]:\n",
    "    if 'Markov' not in model['modelname']:\n",
    "        \n",
    "        modelstore = storage.Storage()\n",
    "        ct = datetime.now()\n",
    "        print(i, model['modelname'])\n",
    "        print('Calibration partition', ct)\n",
    "        model['Algorithm_text'] = str(model['algorithm'])\n",
    "        model['RunResult_calib'] = RunResult.retrain_or_retrieve(\n",
    "                retrain            = force_retrain,\n",
    "                store              = modelstore,\n",
    "                partitioner        = DataPartitioner({\"calib\":calib_partitioner_dict}),\n",
    "                stepshifted_models = StepshiftedModels(model['algorithm'], steps, model['depvar']),\n",
    "                dataset            = RetrieveFromList(Datasets,model['data_train']),\n",
    "                queryset_name      = model['queryset'],\n",
    "                partition_name     = \"calib\",\n",
    "                timespan_name      = \"train\",\n",
    "                storage_name       = model['modelname'] + '_calib',\n",
    "                author_name        = \"JED\",\n",
    "        )\n",
    "\n",
    "    #    model['predstore_calib'] = level +  '_' + model['modelname'] + '_calib'\n",
    "        ct = datetime.now()\n",
    "        if force_rewrite:\n",
    "            print(model['predstore_calib'], ', run',  run_id, 'force_rewrite=True, predicting')\n",
    "            predictions_calib = model['RunResult_calib'].run.predict(\"calib\",\"predict\", model['RunResult_calib'].data)\n",
    "            predictions_calib.forecasts.set_run(run_id)\n",
    "            predictions_calib.forecasts.to_store(name=model['predstore_calib'],overwrite=True)\n",
    "        else:\n",
    "            print('Trying to retrieve predictions', ct)\n",
    "            try:\n",
    "                predictions_calib = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstore_calib'])\n",
    "            except KeyError:\n",
    "                print(model['predstore_calib'], ', run',  run_id, 'does not exist, predicting')\n",
    "                predictions_calib = model['RunResult_calib'].run.predict(\"calib\",\"predict\", model['RunResult_calib'].data)\n",
    "                predictions_calib.forecasts.set_run(run_id)\n",
    "                predictions_calib.forecasts.to_store(name=model['predstore_calib'])\n",
    "\n",
    "        ct = datetime.now()\n",
    "        print('Test partition', ct)\n",
    "        modelstore = storage.Storage()\n",
    "        model['RunResult_test'] = RunResult.retrain_or_retrieve(\n",
    "                retrain            = force_retrain,\n",
    "                store              = modelstore,\n",
    "                partitioner        = DataPartitioner({\"test\":test_partitioner_dict}),\n",
    "                stepshifted_models = StepshiftedModels(model['algorithm'], steps, model['depvar']),\n",
    "                dataset            = RetrieveFromList(Datasets,model['data_train']),\n",
    "                queryset_name      = model['queryset'],\n",
    "                partition_name     = \"test\",\n",
    "                timespan_name      = \"train\",\n",
    "                storage_name       = model['modelname'] + '_test',\n",
    "                author_name        = \"JED\",\n",
    "        )\n",
    "        ct = datetime.now()\n",
    "        \n",
    "        if force_rewrite:\n",
    "            print(model['predstore_test'], ', run',  run_id, 'force_rewrite=True, predicting')\n",
    "            predictions_test = model['RunResult_test'].run.predict(\"test\",\"predict\", model['RunResult_test'].data)\n",
    "            predictions_test.forecasts.set_run(run_id)\n",
    "            predictions_test.forecasts.to_store(name=model['predstore_test'],overwrite=True)\n",
    "        else:\n",
    "            print('Trying to retrieve predictions', ct)\n",
    "    #    model['predstore_test'] = level +  '_' + model['modelname'] + '_test'\n",
    "            try:\n",
    "                predictions_test = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstore_test'])\n",
    "            except KeyError:\n",
    "                print(model['predstore_test'], ', run', run_id, 'does not exist, predicting')\n",
    "                predictions_test = model['RunResult_test'].run.predict(\"test\",\"predict\",model['RunResult_test'].data)\n",
    "                predictions_test.forecasts.set_run(run_id)\n",
    "                predictions_test.forecasts.to_store(name=model['predstore_test'])\n",
    "        # Predictions for true future\n",
    "        if includeFuture:\n",
    "            ct = datetime.now()\n",
    "            print('Future', ct)\n",
    "            modelstore = storage.Storage()\n",
    "            model['RunResult_future'] = RunResult.retrain_or_retrieve(\n",
    "                    retrain            = force_retrain,\n",
    "                    store              = modelstore,\n",
    "                    partitioner        = DataPartitioner({\"test\":future_partitioner_dict}),\n",
    "                    stepshifted_models = StepshiftedModels(model['algorithm'], steps, model['depvar']),\n",
    "                    dataset            = RetrieveFromList(Datasets,model['data_train']),\n",
    "                    queryset_name      = model['queryset'],\n",
    "                    partition_name     = \"test\",\n",
    "                    timespan_name      = \"train\",\n",
    "                    storage_name       = model['modelname'] + '_future',\n",
    "                    author_name        = \"JED\",\n",
    "            )\n",
    "            ct = datetime.now()\n",
    "            \n",
    "            if force_rewrite:\n",
    "                print(model['predstore_future'], ', run',  run_id, 'force_rewrite=True, predicting')\n",
    "                predictions_future = model['RunResult_future'].run.predict(EndOfHistory, model['RunResult_future'].data)\n",
    "                predictions_future.forecasts.set_run(run_id)\n",
    "                predictions_future.forecasts.to_store(name=model['predstore_future'],overwrite=True)\n",
    "            else:\n",
    "                print('Trying to retrieve predictions', ct)\n",
    "                model['predstore_future'] = level +  '_' + model['modelname'] + '_f' + str(EndOfHistory)\n",
    "                predictions_future.forecasts.to_store(name=model['predstore_future'])  \n",
    "                \n",
    "    else:\n",
    "        modelstore = storage.Storage()\n",
    "        ct = datetime.now()\n",
    "        print(i, model['modelname'])\n",
    "        print('Calibration partition', ct)\n",
    "        model['Algorithm_text'] = str(model['algorithm'])\n",
    "        print('Trying to retrieve predictions', ct)\n",
    "        if force_retrain:\n",
    "            print(model['predstore_calib'], ', run',  run_id, 'force_retrain = True, predicting')\n",
    "            predictions_calib = markov.compute_markov(calib_partitioner_dict, EndOfHistory, model['depvar'], 'calib', model['algorithm'])\n",
    "            predictions_calib.forecasts.set_run(run_id)\n",
    "            predictions_calib.forecasts.to_store(name=model['predstore_calib'],overwrite=True)\n",
    "        else:\n",
    "            try:\n",
    "                predictions_calib = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstore_calib'])\n",
    "            except KeyError:\n",
    "                print(model['predstore_calib'], ', run',  run_id, 'does not exist, predicting')\n",
    "                predictions_calib = markov.compute_markov(calib_partitioner_dict, EndOfHistory, model['depvar'], 'calib', model['algorithm'])\n",
    "                predictions_calib.forecasts.set_run(run_id)\n",
    "                predictions_calib.forecasts.to_store(name=model['predstore_calib'],overwrite=True)\n",
    "                \n",
    "        ct = datetime.now()\n",
    "        print('Test partition', ct)\n",
    "        modelstore = storage.Storage()\n",
    "        if force_retrain:\n",
    "            print(model['predstore_test'], ', run', run_id, 'force_retrain=True, predicting')\n",
    "            predictions_test = markov.compute_markov(test_partitioner_dict, EndOfHistory, model['depvar'], 'test', model['algorithm'])\n",
    "            predictions_test.forecasts.set_run(run_id)\n",
    "            predictions_test.forecasts.to_store(name=model['predstore_test'],overwrite=True)\n",
    "        else:\n",
    "            try:\n",
    "                predictions_test = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstore_test'])\n",
    "            except KeyError:\n",
    "                print(model['predstore_test'], ', run', run_id, 'does not exist, predicting')\n",
    "                predictions_test = markov.compute_markov(test_partitioner_dict, EndOfHistory, model['depvar'], 'test', model['algorithm'])\n",
    "                predictions_test.forecasts.set_run(run_id)\n",
    "                predictions_test.forecasts.to_store(name=model['predstore_test'],overwrite=True)\n",
    "                \n",
    "        if includeFuture:\n",
    "            ct = datetime.now()\n",
    "            print('Future', ct)\n",
    "            modelstore = storage.Storage()\n",
    "            print('Trying to retrieve predictions', ct)\n",
    "            model['predstore_future'] = level +  '_' + model['modelname'] + '_f' + str(EndOfHistory)\n",
    "            if force_retrain:\n",
    "                print(model['predstore_future'], ', run', run_id, 'force_retrain=True, predicting')\n",
    "                predictions_future = markov.compute_markov(test_partitioner_dict, EndOfHistory, model['depvar'], 'future', model['algorithm'])\n",
    "                predictions_future.forecasts.set_run(run_id)\n",
    "                predictions_future.forecasts.to_store(name=model['predstore_future'],overwrite=True)\n",
    "            else:\n",
    "                try:\n",
    "                    predictions_future = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstore_future'])\n",
    "                except KeyError:\n",
    "                    print(model['predstore_future'], ', run', run_id, 'does not exist, predicting')\n",
    "                    predictions_future = markov.compute_markov(test_partitioner_dict, EndOfHistory, model['depvar'], 'future', model['algorithm'])\n",
    "                    predictions_future.forecasts.set_run(run_id)\n",
    "                    predictions_future.forecasts.to_store(name=model['predstore_future'],overwrite=True)  \n",
    "                            \n",
    "        print('**************************************************************')\n",
    "    i = i + 1\n",
    "\n",
    "print('All done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7164b1e-ef3f-494b-8cc1-a8434a96a871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T15:41:00.104396Z",
     "start_time": "2024-03-28T15:41:00.100448Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77b52249",
   "metadata": {},
   "source": [
    "## Notes on training time for the various algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f6b21cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T15:41:00.603106Z",
     "start_time": "2024-03-28T15:41:00.106688Z"
    }
   },
   "outputs": [],
   "source": [
    "#These are calculated in minutes for the hh20 feature set (with about 40 features), for all 36 steps, calibration (c) and test (t) partitions, also include generating predictions, and are approximate:\n",
    "\n",
    "#nj=12 (number of threads)\n",
    "#scikit random forest:        21:13 (c), 26:20 (t) RandomForestRegressor(n_estimators=200, n_jobs=nj)\n",
    "#XGB random forest:           06:02 (c), 07:51 (t) XGBRFRegressor(n_estimators=300,n_jobs=nj)\n",
    "#scikit gbm:                  13:59 (c), 15:55 (t) GradientBoostingRegressor(), \n",
    "#scikit hurdle random forest: 07:32 (c), 09:49 (t) For both clf and reg: (n_estimators=200, n_jobs=nj)\n",
    "#XGB hurdle xgb:              01:26 (c), 01:32 (t) For both clf and reg:                n_estimators=200,tree_method='hist',n_jobs=nj)\n",
    "#scikit histgbm:              01:17 (c), 01:20 (t) HistGradientBoostingRegressor(max_iter=200)\n",
    "#XGB xgb:                     01:00 (c), 01:04 (t) XGBRegressor(n_estimators=200,tree_method='hist',n_jobs=nj)\n",
    "#lightgbm gbm:                00:25 (c), --    (t) LGBMRegressor(n_estimators=100,num_threads=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71483a35",
   "metadata": {},
   "source": [
    "# Various helper functions and tools...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7570c6",
   "metadata": {},
   "source": [
    "# Retrieving external forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b30211fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T15:41:00.662384Z",
     "start_time": "2024-03-28T15:41:00.604870Z"
    }
   },
   "outputs": [],
   "source": [
    "## Retrieve David's Markov models\n",
    "## To do: rewrite the model dictionary to the new, slimmer version.\n",
    "#DRList = []\n",
    "\n",
    "\n",
    "#model = {\n",
    "#    'modelname':   'fatalities002_Markov_glm',\n",
    "#    'algorithm': [],\n",
    "#    'depvar': \"ln_ged_sb_dep\",\n",
    "#    'data_train':      'joint_narrow',\n",
    "#    'queryset': 'fatalities002_joint_narrow',\n",
    "#}\n",
    "#DRList.append(model)\n",
    "\n",
    "#model = {\n",
    "#    'modelname':   'fatalities002_Markov_rf',\n",
    "#    'algorithm': [],\n",
    "#    'depvar': \"ln_ged_sb_dep\",\n",
    "#    'data_train':      'joint_narrow',\n",
    "#    'queryset': 'fatalities002_joint_narrow',\n",
    "#}\n",
    "\n",
    "#DRList.append(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41de188d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T15:41:00.719787Z",
     "start_time": "2024-03-28T15:41:00.663566Z"
    }
   },
   "outputs": [],
   "source": [
    "#path = f'/Users/{os.getlogin()}/Dropbox (ViEWS)/ViEWS/Projects/PredictingFatalities/Predictions/cm/preds/'\n",
    "\n",
    "#DRList[0]['predictions_file_calib'] = path + 'markov_jointnarrow_ss_glm_calib.parquet'\n",
    "#DRList[0]['predictions_file_test'] = path + 'markov_jointnarrow_ss_glm_test.parquet'\n",
    "#DRList[0]['predictions_file_future'] = path + 'vmm_glm_hh20_517.csv'\n",
    "\n",
    "#DRList[1]['predictions_file_calib'] = path + 'markov_jointnarrow_ss_rf_calib.parquet'\n",
    "#DRList[1]['predictions_file_test'] = path + 'markov_jointnarrow_ss_rf_test.parquet'\n",
    "#DRList[1]['predictions_file_future'] = path + 'vmm_rf_hh20_517.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86478962",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T15:41:00.777587Z",
     "start_time": "2024-03-28T15:41:00.720892Z"
    }
   },
   "outputs": [],
   "source": [
    "## Storing Markov models in central storage\n",
    "## Retrieving dependent variable\n",
    "\n",
    "#print('Adding depvar - CHECK FILES BEING USED FROM STORAGE ARE SUITABLE!')\n",
    "#target_calib = pd.DataFrame.forecasts.read_store('cm_fatalities002_conflicthistory_rf_calib', run=run_id)['ln_ged_sb_dep']\n",
    "#target_test = pd.DataFrame.forecasts.read_store('cm_fatalities002_conflicthistory_rf_test', run=run_id)['ln_ged_sb_dep']\n",
    "#level = 'cm'\n",
    "#for model in DRList:\n",
    "#    df_calib = pd.read_parquet(model['predictions_file_calib'])\n",
    "##    df_calib.rename(columns={'target_month_id':'month_id'}, inplace=True)\n",
    "##    df_calib.set_index(['month_id', 'country_id'], inplace=True)\n",
    "\n",
    "#    df_test = pd.read_parquet(model['predictions_file_test'])\n",
    "##    df_test.rename(columns={'target_month_id':'month_id'}, inplace=True)\n",
    "##    df_calib.set_index(['month_id', 'country_id'], inplace=True)\n",
    "\n",
    "##    df_future = pd.read_csv(model['predictions_file_future'],index_col=['month_id','country_id'])\n",
    "#    df_calib['ln_ged_sb_dep'] = target_calib\n",
    "#    df_test['ln_ged_sb_dep'] = target_test\n",
    "##    df_future['ln_ged_sb_dep'] = np.nan # Empty dependent variable column for consistency/required by prediction storage function\n",
    "#    stored_modelname = level + '_' + model['modelname'] + '_calib'\n",
    "#    df_calib.forecasts.set_run(run_id)\n",
    "#    df_calib.forecasts.to_store(name=stored_modelname, overwrite=True)\n",
    "#    stored_modelname = level + '_' + model['modelname'] + '_test'\n",
    "#    df_test.forecasts.set_run(run_id)\n",
    "#    df_test.forecasts.to_store(name=stored_modelname, overwrite=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a907a4d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T15:41:00.781621Z",
     "start_time": "2024-03-28T15:41:00.779057Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
