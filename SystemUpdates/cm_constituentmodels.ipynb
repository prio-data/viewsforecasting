{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1098f7cb",
   "metadata": {},
   "source": [
    "\n",
    "# ViEWS 3 constituent models \n",
    "## ViEWS production system, cm level\n",
    "\n",
    "\n",
    "This notebook trains a set of regression models for use in the monthly updated ViEWS predicting fatalities ensemble\n",
    "\n",
    "The notebook does the following: \n",
    "1. Retrieves data through querysets and stores in DataSets, a list of dictionaries\n",
    "2. Specifies the metadata of a number of models, stores in ModelList, a list of dictionaries\n",
    "3. Trains the models in ModelList, stores the trained objects in model storage and prediction storage\n",
    "4. Saves part of ModelList as csv and the rest as pickles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f7cba",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8855fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef27dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "# sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRFRegressor, XGBRFClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "\n",
    "# Views 3\n",
    "from viewser.operations import fetch\n",
    "import views_runs\n",
    "from views_partitioning import data_partitioner, legacy\n",
    "from stepshift import views\n",
    "import views_dataviz\n",
    "from views_runs import storage\n",
    "from views_runs.storage import store, retrieve, fetch_metadata\n",
    "\n",
    "from views_forecasts.extensions import *\n",
    "\n",
    "# Other packages\n",
    "import pickle as pkl\n",
    "\n",
    "# Packages from viewsforecasting repository\n",
    "\n",
    "#from Ensembling import CalibratePredictions, RetrieveStoredPredictions, mean_sd_calibrated, gam_calibrated\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../Tools')\n",
    "sys.path.append('../Intermediates')\n",
    "from FetchData import FetchData, RetrieveFromList, document_queryset, ReturnQsList, document_ensemble\n",
    "from ViewsEstimators import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3300ea25",
   "metadata": {},
   "source": [
    "## Common parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c76adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda list | grep views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09fdc462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do:\n",
    "# find out why and where missingness occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78ae8aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Mydropbox to /Users/havardhegre1/Dropbox (ViEWS)/ViEWS\n"
     ]
    }
   ],
   "source": [
    "# Common parameters:\n",
    "dev_id = 'Fatalities002'\n",
    "run_id = dev_id\n",
    "\n",
    "# Generating a new run if necessary\n",
    "\n",
    "#try:\n",
    "#    ViewsMetadata().new_run(name=run_id,description='Developing the fatalities model for FCDO',min_month=1,max_month=999)\n",
    "#except KeyError:\n",
    "#    if 'devel' not in run_id:\n",
    "#        warnings.warn('You are overwriting a production system')\n",
    "\n",
    "RerunQuerysets = True\n",
    "\n",
    "FutureStart = 508\n",
    "steps = [*range(1, 36+1, 1)] # Which steps to train and predict for\n",
    "fi_steps = [1,3,6,12,36] # Which steps to present feature importances for\n",
    "#steps = [1,3,6,12,36]\n",
    "#fi_steps = [1,3,6,12,36]\n",
    "\n",
    "# Specifying partitions\n",
    "calib_partitioner_dict = {\"train\":(121,396),\"predict\":(397,444)}\n",
    "test_partitioner_dict = {\"train\":(121,444),\"predict\":(445,492)}\n",
    "future_partitioner_dict = {\"train\":(121,492),\"predict\":(493,504)}\n",
    "calib_partitioner =  views_runs.DataPartitioner({\"calib\":calib_partitioner_dict})\n",
    "test_partitioner =  views_runs.DataPartitioner({\"test\":test_partitioner_dict})\n",
    "future_partitioner =  views_runs.DataPartitioner({\"future\":future_partitioner_dict})\n",
    "\n",
    "Mydropbox = f'/Users/{os.getlogin()}/Dropbox (ViEWS)/ViEWS'\n",
    "print('Setting Mydropbox to',Mydropbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf0208",
   "metadata": {},
   "source": [
    "# Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a457b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " .    fatalities002_baseline; A dataset with 6 columns, with data between t 1 and 852. (213 units)\n",
      " .    fatalities002_topics_stub; A dataset with 62 columns, with data between t 1 and 852. (213 units)\n",
      " .    fatalities002_aquastat_stub; A dataset with 11 columns, with data between t 1 and 852. (213 units)\n",
      " .    fatalities002_cm_conflict_history_stub; A dataset with 24 columns, with data between t 1 and 852. (213 units)\n",
      " .    fatalities002_cm_conflict_history_ext; A dataset with 33 columns, with data between t = 1 and 852. (213 units)\n",
      " .    fatalities002_vdem_short_stub; A dataset with 57 columns, with data between t 1 and 852. (213 units)\n",
      " .    fatalities002_wdi_short_stub; A dataset with 26 columns, with data between t 1 and 852. (213 units)\n",
      " .    fatalities002_joint_narrow; A dataset with 39 columns, with data between t 1 and 852. (213 units)\n",
      " .    fatalities002_joint_broad_stub; A dataset with 102 columns, with data between t 1 and 852. (213 units)\n",
      " .    fatalities002_faostat_stub;A dataset with 35 columns, with data between t 1 and 852. (213 units)\n",
      " .    fatalities002_faoprices_stub;A dataset with 11 columns, with data between t 1 and 852. (213 units)\n",
      " .    fatalities002_imfweo_stub;A dataset with 5 columns, with data between t 1 and 852. (213 units)\n",
      " .     .     .     .     .     .     .     .     .     .    Model:  fatalities002_baseline\n",
      "Model:  fatalities002_topics\n",
      "Model:  fatalities002_aquastat\n",
      "Model:  fatalities002_conflict_history\n",
      "Model:  fatalities002_conflict_history_long\n",
      "Model:  fatalities002_vdem_short\n",
      "Model:  fatalities002_wdi_short\n",
      "Model:  fatalities002_all_features\n",
      "Model:  fatalities002_joint_narrow\n",
      "Model:  fatalities002_joint_broad\n",
      "Model:  fatalities002_faostat\n",
      "Model:  fatalities002_faoprices\n",
      "Model:  fatalities002_imfweo\n"
     ]
    }
   ],
   "source": [
    "# Create Markdown documentation of all querysets used\n",
    "level = 'cm'\n",
    "qslist = ReturnQsList(level)\n",
    "document_queryset(qslist,dev_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7e75122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " .    topics_002: A dataset with 68 columns, with data between t = 1 and 852; 213 units.\n",
      " .    conflict_ln: A dataset with 30 columns, with data between t = 1 and 852; 213 units.\n",
      " .    vdem_short: A dataset with 63 columns, with data between t = 1 and 852; 213 units.\n",
      " .    aquastat: A dataset with 17 columns, with data between t = 1 and 852; 213 units.\n",
      " .    conflictlong_ln: A dataset with 63 columns, with data between t = 1 and 852; 213 units.\n",
      " .    baseline002: A dataset with 6 columns, with data between t = 1 and 852; 213 units.\n",
      " .    all_features: A dataset with 186 columns, with data between t = 1 and 852; 213 units.\n",
      " .    faostat: A dataset with 41 columns, with data between t = 1 and 852; 213 units.\n",
      " .    faoprices: A dataset with 17 columns, with data between t = 1 and 852; 213 units.\n",
      " .    imfweo: A dataset with 11 columns, with data between t = 1 and 852; 213 units.\n",
      " .    wdi_short: A dataset with 32 columns, with data between t = 1 and 852; 213 units.\n",
      " .    joint_broad: A dataset with 108 columns, with data between t = 1 and 852; 213 units.\n",
      " .    joint_narrow: A dataset with 39 columns, with data between t = 1 and 852; 213 units.\n",
      "all_features [9.99645371e-01 3.54310985e-04 3.18303243e-07 4.63130694e-13\n",
      " 1.40426489e-15 3.54547300e-16 1.46792453e-16 1.37280606e-16\n",
      " 7.44883483e-17 2.80662423e-17 1.48022549e-18 2.68827139e-20\n",
      " 2.90646997e-21 2.50710496e-21 3.46241823e-23 2.83145336e-23\n",
      " 1.21563302e-23 3.53728541e-24 2.44949696e-24 8.91852362e-25]\n",
      "[1.77979953e+16 3.35073758e+14 1.00431197e+13 1.21143437e+10\n",
      " 6.67071867e+08 3.35185481e+08 2.15675082e+08 2.08570413e+08\n",
      " 1.53635748e+08 9.43061993e+07 2.16576857e+07 2.91866777e+06\n",
      " 9.59690128e+05 8.91321466e+05 1.04746102e+05 9.47224262e+04\n",
      " 6.20653704e+04 3.34798234e+04 2.78603494e+04 1.68110404e+04]\n",
      "topics [1.00000000e+00 3.33918055e-13 7.38887771e-14 4.16097585e-14\n",
      " 2.57854306e-14 2.24534102e-14 1.69317457e-14 1.59802075e-14\n",
      " 1.33974965e-14 1.20260680e-14]\n",
      "[3.52759832e+10 2.03844537e+04 9.58889065e+03 7.19576090e+03\n",
      " 5.66456182e+03 5.28591630e+03 4.59018295e+03 4.45933740e+03\n",
      " 4.08310880e+03 3.86848533e+03]\n",
      "vdem [9.99977132e-01 2.28676239e-05 5.46133821e-14 8.44023377e-16\n",
      " 3.07461238e-16 1.81889479e-16 1.23527508e-16 5.45541114e-17\n",
      " 4.18044667e-17 3.38903010e-17 1.69743083e-17 1.06966577e-17\n",
      " 7.49251598e-18 6.87273202e-18 5.31963821e-18]\n",
      "[3.52759963e+10 1.68692111e+08 8.24392040e+03 1.02485280e+03\n",
      " 6.18556592e+02 4.75760130e+02 3.92072240e+02 2.60554151e+02\n",
      " 2.28084408e+02 2.05362890e+02 1.45338374e+02 1.15374094e+02\n",
      " 9.65601858e+01 9.24802423e+01 8.13626907e+01]\n",
      "wdi [9.99645371e-01 3.54310985e-04 3.18303243e-07 4.63130370e-13\n",
      " 1.40417114e-15 3.54407830e-16 1.46033226e-16 1.22762347e-16\n",
      " 4.27517211e-17 2.74897051e-17 2.67647609e-23 1.86738315e-24\n",
      " 7.02353806e-25 9.10074333e-26 3.02073571e-26]\n",
      "[1.77979953e+16 3.35073758e+14 1.00431197e+13 1.21143394e+10\n",
      " 6.67049601e+08 3.35119548e+08 2.15116611e+08 1.97233508e+08\n",
      " 1.16392476e+08 9.33325534e+07 9.20936724e+04 2.43256708e+04\n",
      " 1.49185316e+04 5.37015153e+03 3.09388718e+03]\n"
     ]
    }
   ],
   "source": [
    "from FetchData import fetch_cm_data_from_model_def\n",
    "\n",
    "Datasets=fetch_cm_data_from_model_def(qslist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a925bdb3",
   "metadata": {},
   "source": [
    "# Generating predictions\n",
    "Using the ViEWS3 partitioning/stepshifting syntax. Training models for A: calibration partition and B: test partition, to test out some calibration routines. Most models trained with ln_ged_sb_best as outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6424da7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fatalities002'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4b379f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ln_ged_sb_dep</th>\n",
       "      <th>ln_ged_sb</th>\n",
       "      <th>wdi_sp_pop_totl</th>\n",
       "      <th>topic0_religion_t1</th>\n",
       "      <th>topic0_religion_t13</th>\n",
       "      <th>topic1_politics_t1</th>\n",
       "      <th>topic1_politics_t13</th>\n",
       "      <th>topic2_sanctions_t1</th>\n",
       "      <th>topic2_sanctions_t13</th>\n",
       "      <th>topic3_life_t1</th>\n",
       "      <th>...</th>\n",
       "      <th>splag_topic5_media_t1_stock</th>\n",
       "      <th>splag_topic6_economics_t1_stock</th>\n",
       "      <th>splag_topic7_health_t1_stock</th>\n",
       "      <th>splag_topic8_china_t1_stock</th>\n",
       "      <th>splag_topic9_foreign_t1_stock</th>\n",
       "      <th>splag_topic10_conflict_t1_stock</th>\n",
       "      <th>splag_topic11_diplomacy_t1_stock</th>\n",
       "      <th>splag_topic12_power_t1_stock</th>\n",
       "      <th>splag_topic13_sports_t1_stock</th>\n",
       "      <th>splag_topic14_judiciary_t1_stock</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_id</th>\n",
       "      <th>country_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>780153.0</td>\n",
       "      <td>0.88053</td>\n",
       "      <td>0.88053</td>\n",
       "      <td>0.541010</td>\n",
       "      <td>0.541010</td>\n",
       "      <td>0.26324</td>\n",
       "      <td>0.26324</td>\n",
       "      <td>14.33693</td>\n",
       "      <td>...</td>\n",
       "      <td>8.86444</td>\n",
       "      <td>48.831049</td>\n",
       "      <td>3.92519</td>\n",
       "      <td>0.47482</td>\n",
       "      <td>10.191550</td>\n",
       "      <td>6.36659</td>\n",
       "      <td>6.56443</td>\n",
       "      <td>21.17166</td>\n",
       "      <td>5.590610</td>\n",
       "      <td>6.18842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>359531.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.70923</td>\n",
       "      <td>21.028550</td>\n",
       "      <td>6.43111</td>\n",
       "      <td>0.47872</td>\n",
       "      <td>11.422680</td>\n",
       "      <td>4.79998</td>\n",
       "      <td>5.64878</td>\n",
       "      <td>11.31565</td>\n",
       "      <td>63.384621</td>\n",
       "      <td>3.38971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1084744.0</td>\n",
       "      <td>0.85479</td>\n",
       "      <td>0.85479</td>\n",
       "      <td>32.893841</td>\n",
       "      <td>32.893841</td>\n",
       "      <td>0.85479</td>\n",
       "      <td>0.85479</td>\n",
       "      <td>9.31762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15182611.0</td>\n",
       "      <td>0.05139</td>\n",
       "      <td>0.05139</td>\n",
       "      <td>17.967770</td>\n",
       "      <td>17.967770</td>\n",
       "      <td>0.39640</td>\n",
       "      <td>0.39640</td>\n",
       "      <td>5.85506</td>\n",
       "      <td>...</td>\n",
       "      <td>5.14827</td>\n",
       "      <td>34.749929</td>\n",
       "      <td>8.96491</td>\n",
       "      <td>0.92614</td>\n",
       "      <td>19.777639</td>\n",
       "      <td>19.63530</td>\n",
       "      <td>12.29964</td>\n",
       "      <td>27.63594</td>\n",
       "      <td>65.078121</td>\n",
       "      <td>13.85060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155525.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ln_ged_sb_dep  ln_ged_sb  wdi_sp_pop_totl  \\\n",
       "month_id country_id                                              \n",
       "1        1                     0.0        0.0         780153.0   \n",
       "         2                     0.0        0.0         359531.0   \n",
       "         3                     0.0        0.0        1084744.0   \n",
       "         4                     0.0        0.0       15182611.0   \n",
       "         5                     0.0        0.0         155525.0   \n",
       "\n",
       "                     topic0_religion_t1  topic0_religion_t13  \\\n",
       "month_id country_id                                            \n",
       "1        1                      0.88053              0.88053   \n",
       "         2                      0.00000              0.00000   \n",
       "         3                      0.85479              0.85479   \n",
       "         4                      0.05139              0.05139   \n",
       "         5                      0.00000              0.00000   \n",
       "\n",
       "                     topic1_politics_t1  topic1_politics_t13  \\\n",
       "month_id country_id                                            \n",
       "1        1                     0.541010             0.541010   \n",
       "         2                     0.000000             0.000000   \n",
       "         3                    32.893841            32.893841   \n",
       "         4                    17.967770            17.967770   \n",
       "         5                     0.000000             0.000000   \n",
       "\n",
       "                     topic2_sanctions_t1  topic2_sanctions_t13  \\\n",
       "month_id country_id                                              \n",
       "1        1                       0.26324               0.26324   \n",
       "         2                       0.00000               0.00000   \n",
       "         3                       0.85479               0.85479   \n",
       "         4                       0.39640               0.39640   \n",
       "         5                       0.00000               0.00000   \n",
       "\n",
       "                     topic3_life_t1  ...  splag_topic5_media_t1_stock  \\\n",
       "month_id country_id                  ...                                \n",
       "1        1                 14.33693  ...                      8.86444   \n",
       "         2                  0.00000  ...                      4.70923   \n",
       "         3                  9.31762  ...                      0.00000   \n",
       "         4                  5.85506  ...                      5.14827   \n",
       "         5                  0.00000  ...                      0.00000   \n",
       "\n",
       "                     splag_topic6_economics_t1_stock  \\\n",
       "month_id country_id                                    \n",
       "1        1                                 48.831049   \n",
       "         2                                 21.028550   \n",
       "         3                                  0.000000   \n",
       "         4                                 34.749929   \n",
       "         5                                  0.000000   \n",
       "\n",
       "                     splag_topic7_health_t1_stock  \\\n",
       "month_id country_id                                 \n",
       "1        1                                3.92519   \n",
       "         2                                6.43111   \n",
       "         3                                0.00000   \n",
       "         4                                8.96491   \n",
       "         5                                0.00000   \n",
       "\n",
       "                     splag_topic8_china_t1_stock  \\\n",
       "month_id country_id                                \n",
       "1        1                               0.47482   \n",
       "         2                               0.47872   \n",
       "         3                               0.00000   \n",
       "         4                               0.92614   \n",
       "         5                               0.00000   \n",
       "\n",
       "                     splag_topic9_foreign_t1_stock  \\\n",
       "month_id country_id                                  \n",
       "1        1                               10.191550   \n",
       "         2                               11.422680   \n",
       "         3                                0.000000   \n",
       "         4                               19.777639   \n",
       "         5                                0.000000   \n",
       "\n",
       "                     splag_topic10_conflict_t1_stock  \\\n",
       "month_id country_id                                    \n",
       "1        1                                   6.36659   \n",
       "         2                                   4.79998   \n",
       "         3                                   0.00000   \n",
       "         4                                  19.63530   \n",
       "         5                                   0.00000   \n",
       "\n",
       "                     splag_topic11_diplomacy_t1_stock  \\\n",
       "month_id country_id                                     \n",
       "1        1                                    6.56443   \n",
       "         2                                    5.64878   \n",
       "         3                                    0.00000   \n",
       "         4                                   12.29964   \n",
       "         5                                    0.00000   \n",
       "\n",
       "                     splag_topic12_power_t1_stock  \\\n",
       "month_id country_id                                 \n",
       "1        1                               21.17166   \n",
       "         2                               11.31565   \n",
       "         3                                0.00000   \n",
       "         4                               27.63594   \n",
       "         5                                0.00000   \n",
       "\n",
       "                     splag_topic13_sports_t1_stock  \\\n",
       "month_id country_id                                  \n",
       "1        1                                5.590610   \n",
       "         2                               63.384621   \n",
       "         3                                0.000000   \n",
       "         4                               65.078121   \n",
       "         5                                0.000000   \n",
       "\n",
       "                     splag_topic14_judiciary_t1_stock  \n",
       "month_id country_id                                    \n",
       "1        1                                    6.18842  \n",
       "         2                                    3.38971  \n",
       "         3                                    0.00000  \n",
       "         4                                   13.85060  \n",
       "         5                                    0.00000  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Datasets[0]['df'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "990574dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ModelMetadata in module views_schema.models:\n",
      "\n",
      "class ModelMetadata(pydantic.main.BaseModel)\n",
      " |  ModelMetadata(*, author: str, queryset_name: str, train_start: int, train_end: int, steps: List[int] = None, training_date: datetime.datetime) -> None\n",
      " |  \n",
      " |  ModelMetadata\n",
      " |  =============\n",
      " |  \n",
      " |  Data used to organize model objects.\n",
      " |  \n",
      " |  parameters:\n",
      " |      author (str): Name of the user that authored the model object.\n",
      " |      queryset_name (str): Name of the queryset used to train the model\n",
      " |      train_start (int): Month identifier for training start date\n",
      " |      train_start (int): Month identifier for training end date\n",
      " |      training_date (datetime.datetime): Timestamp for training date (use datetime.datetime.now())\n",
      " |  \n",
      " |  example:\n",
      " |  \n",
      " |      # Instantiate the class with values\n",
      " |  \n",
      " |      my_metadata = ModelMetadata(\n",
      " |          author = \"my_name\",\n",
      " |          queryset_name = \"my_queryset\",\n",
      " |          train_start = 1,\n",
      " |          train_end = 300,\n",
      " |          steps = [1,2,3],\n",
      " |          training_date = datetime.datetime.now())\n",
      " |  \n",
      " |      # Create metadata with a views_runs.ViewsRun object. This fetches\n",
      " |      # values from the associated StepshiftedModels and DataPartitioner\n",
      " |      # objects.\n",
      " |  \n",
      " |      my_metadata = my_run.create_model_metadata(\n",
      " |              author = \"me\",\n",
      " |              queryset_name = \"my_queryset\",\n",
      " |              training_partition_name = \"A\",\n",
      " |              )\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ModelMetadata\n",
      " |      pydantic.main.BaseModel\n",
      " |      pydantic.utils.Representation\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'author': <class 'str'>, 'queryset_name': <class 's...\n",
      " |  \n",
      " |  __class_vars__ = set()\n",
      " |  \n",
      " |  __config__ = <class 'views_schema.models.Config'>\n",
      " |  \n",
      " |  __custom_root_type__ = False\n",
      " |  \n",
      " |  __exclude_fields__ = None\n",
      " |  \n",
      " |  __fields__ = {'author': ModelField(name='author', type=str, required=T...\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __include_fields__ = None\n",
      " |  \n",
      " |  __post_root_validators__ = []\n",
      " |  \n",
      " |  __pre_root_validators__ = []\n",
      " |  \n",
      " |  __private_attributes__ = {}\n",
      " |  \n",
      " |  __schema_cache__ = {}\n",
      " |  \n",
      " |  __signature__ = <Signature (*, author: str, queryset_name: str, ... No...\n",
      " |  \n",
      " |  __validators__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __eq__(self, other: Any) -> bool\n",
      " |  \n",
      " |  __getstate__(self) -> 'DictAny'\n",
      " |  \n",
      " |  __init__(__pydantic_self__, **data: Any) -> None\n",
      " |      Create a new model by parsing and validating input data from keyword arguments.\n",
      " |      \n",
      " |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      " |  \n",
      " |  __iter__(self) -> 'TupleGenerator'\n",
      " |      so `dict(model)` works\n",
      " |  \n",
      " |  __repr_args__(self) -> 'ReprArgs'\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |  \n",
      " |  __setstate__(self, state: 'DictAny') -> None\n",
      " |  \n",
      " |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny')] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny')] = None, update: 'DictStrAny' = None, deep: bool = False) -> 'Model'\n",
      " |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      " |      \n",
      " |      :param include: fields to include in new model\n",
      " |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      " |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      " |          the new model: you should trust this data\n",
      " |      :param deep: set to `True` to make a deep copy of the model\n",
      " |      :return: new model instance\n",
      " |  \n",
      " |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny')] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny')] = None, by_alias: bool = False, skip_defaults: bool = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      " |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      " |  \n",
      " |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny')] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny')] = None, by_alias: bool = False, skip_defaults: bool = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      " |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      " |      \n",
      " |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      " |      Same as update_forward_refs but will not raise exception\n",
      " |      when forward references are not defined.\n",
      " |  \n",
      " |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      " |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      " |      Default values are respected, but no other validation is performed.\n",
      " |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      " |  \n",
      " |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      " |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      " |  \n",
      " |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __fields_set__\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  Config = <class 'pydantic.config.BaseConfig'>\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pydantic.utils.Representation:\n",
      " |  \n",
      " |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      " |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      " |  \n",
      " |  __repr__(self) -> 'unicode'\n",
      " |  \n",
      " |  __repr_name__(self) -> 'unicode'\n",
      " |      Name of the instance's class, used in __repr__.\n",
      " |  \n",
      " |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      " |  \n",
      " |  __str__(self) -> 'unicode'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from views_runs import ModelMetadata \n",
    "help(ModelMetadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf49bd2",
   "metadata": {},
   "source": [
    "## Checking missingness and infinity values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfe61e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topics_002\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "wdi_sp_pop_totl 158230 missing: 11 infinity: 0\n",
      "topic0_religion_t1 158230 missing: 5 infinity: 0\n",
      "topic0_religion_t13 158230 missing: 11 infinity: 0\n",
      "topic1_politics_t1 158230 missing: 5 infinity: 0\n",
      "topic1_politics_t13 158230 missing: 11 infinity: 0\n",
      "topic2_sanctions_t1 158230 missing: 5 infinity: 0\n",
      "topic2_sanctions_t13 158230 missing: 11 infinity: 0\n",
      "topic3_life_t1 158230 missing: 5 infinity: 0\n",
      "topic3_life_t13 158230 missing: 11 infinity: 0\n",
      "topic4_energy_t1 158230 missing: 5 infinity: 0\n",
      "topic4_energy_t13 158230 missing: 11 infinity: 0\n",
      "topic5_media_t1 158230 missing: 5 infinity: 0\n",
      "topic5_media_t13 158230 missing: 11 infinity: 0\n",
      "topic6_economics_t1 158230 missing: 5 infinity: 0\n",
      "topic6_economics_t13 158230 missing: 11 infinity: 0\n",
      "topic7_health_t1 158230 missing: 5 infinity: 0\n",
      "topic7_health_t13 158230 missing: 11 infinity: 0\n",
      "topic8_china_t1 158230 missing: 5 infinity: 0\n",
      "topic8_china_t13 158230 missing: 11 infinity: 0\n",
      "topic9_foreign_t1 158230 missing: 5 infinity: 0\n",
      "topic9_foreign_t13 158230 missing: 11 infinity: 0\n",
      "topic10_conflict_t1 158230 missing: 5 infinity: 0\n",
      "topic10_conflict_t2 158230 missing: 5 infinity: 0\n",
      "topic10_conflict_t3 158230 missing: 5 infinity: 0\n",
      "topic10_conflict_t13 158230 missing: 11 infinity: 0\n",
      "topic11_diplomacy_t1 158230 missing: 5 infinity: 0\n",
      "topic11_diplomacy_t13 158230 missing: 11 infinity: 0\n",
      "topic12_power_t1 158230 missing: 5 infinity: 0\n",
      "topic12_power_t13 158230 missing: 11 infinity: 0\n",
      "topic13_sports_t1 158230 missing: 5 infinity: 0\n",
      "topic13_sports_t13 158230 missing: 11 infinity: 0\n",
      "topic14_judiciary_t1 158230 missing: 5 infinity: 0\n",
      "topic14_judiciary_t13 158230 missing: 11 infinity: 0\n",
      "decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_5 158230 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "topic0_religion_t1_stock 158230 missing: 5 infinity: 0\n",
      "topic1_politics_t1_stock 158230 missing: 5 infinity: 0\n",
      "topic2_sanctions_t1_stock 158230 missing: 5 infinity: 0\n",
      "topic3_life_t1_stock 158230 missing: 5 infinity: 0\n",
      "topic4_energy_t1_stock 158230 missing: 5 infinity: 0\n",
      "topic5_media_t1_stock 158230 missing: 5 infinity: 0\n",
      "topic6_economics_t1_stock 158230 missing: 5 infinity: 0\n",
      "topic7_health_t1_stock 158230 missing: 5 infinity: 0\n",
      "topic8_china_t1_stock 158230 missing: 5 infinity: 0\n",
      "topic9_foreign_t1_stock 158230 missing: 5 infinity: 0\n",
      "topic10_conflict_t1_stock 158230 missing: 5 infinity: 0\n",
      "topic11_diplomacy_t1_stock 158230 missing: 5 infinity: 0\n",
      "topic12_power_t1_stock 158230 missing: 5 infinity: 0\n",
      "conflict_ln\n",
      "gleditsch_ward 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "ln_ged_ns 158230 missing: 0 infinity: 0\n",
      "ln_ged_os 158230 missing: 0 infinity: 0\n",
      "ln_acled_sb 158230 missing: 1437 infinity: 0\n",
      "ln_acled_sb_count 158230 missing: 1437 infinity: 0\n",
      "ln_acled_os 158230 missing: 1437 infinity: 0\n",
      "wdi_sp_pop_totl 158230 missing: 11 infinity: 0\n",
      "ln_ged_sb_tlag_1 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_2 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_3 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_4 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_5 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_6 158230 missing: 11 infinity: 0\n",
      "ln_ged_sb_tsum_24 158230 missing: 0 infinity: 0\n",
      "ln_ged_os_tlag_1 158230 missing: 5 infinity: 0\n",
      "decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_100 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_500 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_100 158230 missing: 0 infinity: 0\n",
      "decay_ged_ns_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_ns_100 158230 missing: 0 infinity: 0\n",
      "decay_acled_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_acled_os_5 158230 missing: 0 infinity: 0\n",
      "decay_acled_ns_5 158230 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_os_5 158230 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_ns_5 158230 missing: 0 infinity: 0\n",
      "vdem_short\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "wdi_sp_pop_totl 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_delibdem 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_egaldem 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_libdem 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_libdem_48 158230 missing: 32 infinity: 0\n",
      "vdem_v2x_partip 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_partipdem 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_accountability 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_clphy 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_cspart 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_divparctrl 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_edcomp_thick 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_egal 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_execorr 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_frassoc_thick 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_gencs 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_gender 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_genpp 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_horacc 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_neopat 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_pubcorr 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_rule 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_veracc 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_ex_military 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_ex_party 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_freexp 158230 missing: 11 infinity: 0\n",
      "vdem_v2xcl_acjst 158230 missing: 11 infinity: 0\n",
      "vdem_v2xcl_dmove 158230 missing: 11 infinity: 0\n",
      "vdem_v2xcl_prpty 158230 missing: 11 infinity: 0\n",
      "vdem_v2xcl_rol 158230 missing: 11 infinity: 0\n",
      "vdem_v2xcl_slave 158230 missing: 11 infinity: 0\n",
      "vdem_v2xdd_dd 158230 missing: 11 infinity: 0\n",
      "vdem_v2xdl_delib 158230 missing: 11 infinity: 0\n",
      "vdem_v2xeg_eqdr 158230 missing: 11 infinity: 0\n",
      "vdem_v2xeg_eqprotec 158230 missing: 11 infinity: 0\n",
      "vdem_v2xel_frefair 158230 missing: 11 infinity: 0\n",
      "vdem_v2xel_regelec 158230 missing: 11 infinity: 0\n",
      "vdem_v2xme_altinf 158230 missing: 11 infinity: 0\n",
      "vdem_v2xnp_client 158230 missing: 11 infinity: 0\n",
      "vdem_v2xnp_regcorr 158230 missing: 11 infinity: 0\n",
      "vdem_v2xpe_exlecon 158230 missing: 266 infinity: 0\n",
      "vdem_v2xpe_exlpol 158230 missing: 266 infinity: 0\n",
      "vdem_v2xpe_exlgeo 158230 missing: 266 infinity: 0\n",
      "vdem_v2xpe_exlgender 158230 missing: 266 infinity: 0\n",
      "vdem_v2xpe_exlsocgr 158230 missing: 266 infinity: 0\n",
      "vdem_v2xps_party 158230 missing: 11 infinity: 0\n",
      "vdem_v2xcs_ccsi 158230 missing: 11 infinity: 0\n",
      "vdem_v2xnp_pres 158230 missing: 11 infinity: 0\n",
      "vdem_v2xeg_eqaccess 158230 missing: 11 infinity: 0\n",
      "aquastat\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "wdi_sp_pop_totl 158230 missing: 11 infinity: 0\n",
      "agr_withdrawal_pct_t48 158230 missing: 32 infinity: 0\n",
      "dam_cap_pcap_t48 158230 missing: 32 infinity: 0\n",
      "groundwater_export_t48 158230 missing: 32 infinity: 0\n",
      "fresh_withdrawal_pct_t48 158230 missing: 32 infinity: 0\n",
      "ind_efficiency_t48 158230 missing: 32 infinity: 0\n",
      "irr_agr_efficiency_t48 158230 missing: 32 infinity: 0\n",
      "services_efficiency_t48 158230 missing: 32 infinity: 0\n",
      "general_efficiency_t48 158230 missing: 32 infinity: 0\n",
      "water_stress_t48 158230 missing: 32 infinity: 0\n",
      "renewable_internal_pcap_t48 158230 missing: 32 infinity: 0\n",
      "renewable_pcap_t48 158230 missing: 32 infinity: 0\n",
      "decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_5 158230 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "conflictlong_ln\n",
      "gleditsch_ward 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "ln_ged_ns 158230 missing: 0 infinity: 0\n",
      "ln_ged_os 158230 missing: 0 infinity: 0\n",
      "ln_acled_sb 158230 missing: 1437 infinity: 0\n",
      "ln_acled_sb_count 158230 missing: 1437 infinity: 0\n",
      "ln_acled_os 158230 missing: 1437 infinity: 0\n",
      "splag_1_ged_sb 158230 missing: 0 infinity: 0\n",
      "splag_2_ged_sb 158230 missing: 0 infinity: 0\n",
      "splag_1_ged_os 158230 missing: 0 infinity: 0\n",
      "splag_1_ged_ns 158230 missing: 0 infinity: 0\n",
      "ln_acled_prx_count 158230 missing: 1437 infinity: 0\n",
      "ln_acled_pr_count 158230 missing: 1437 infinity: 0\n",
      "ln_acled_prx_fat 158230 missing: 1437 infinity: 0\n",
      "ln_acled_sb_gov 158230 missing: 1437 infinity: 0\n",
      "ln_acled_sb_reb 158230 missing: 1437 infinity: 0\n",
      "ln_acled_ns 158230 missing: 1437 infinity: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wdi_sp_pop_totl 158230 missing: 11 infinity: 0\n",
      "ln_ged_sb_tlag_1 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_2 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_3 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_4 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_5 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_6 158230 missing: 11 infinity: 0\n",
      "ln_ged_sb_tsum_24 158230 missing: 0 infinity: 0\n",
      "ln_ged_os_tlag_1 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tsum_12 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb_tsum_48 158230 missing: 0 infinity: 0\n",
      "ln_ged_ns_tlag_1 158230 missing: 5 infinity: 0\n",
      "ln_ged_ns_tlag_2 158230 missing: 5 infinity: 0\n",
      "ln_ged_os_tlag_2 158230 missing: 5 infinity: 0\n",
      "ln_acled_sb_tlag_1 158230 missing: 1437 infinity: 0\n",
      "ln_acled_sb_tlag_2 158230 missing: 1437 infinity: 0\n",
      "ln_acled_os_tlag_1 158230 missing: 1437 infinity: 0\n",
      "ln_acled_os_tlag_2 158230 missing: 1437 infinity: 0\n",
      "ln_acled_ns_tlag_1 158230 missing: 1437 infinity: 0\n",
      "ln_acled_ns_tlag_2 158230 missing: 1437 infinity: 0\n",
      "decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_100 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_500 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_100 158230 missing: 0 infinity: 0\n",
      "decay_ged_ns_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_ns_100 158230 missing: 0 infinity: 0\n",
      "decay_acled_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_acled_os_5 158230 missing: 0 infinity: 0\n",
      "decay_acled_ns_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_1 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_25 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_1 158230 missing: 0 infinity: 0\n",
      "baseline002\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "wdi_sp_pop_totl 158230 missing: 11 infinity: 0\n",
      "decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_5 158230 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "all_features\n",
      "wdi_ag_lnd_frst_k2 158230 missing: 11 infinity: 0\n",
      "wdi_dt_oda_odat_pc_zs 158230 missing: 11 infinity: 0\n",
      "wdi_ms_mil_xpnd_gd_zs 158230 missing: 11 infinity: 0\n",
      "wdi_ms_mil_xpnd_zs 158230 missing: 11 infinity: 0\n",
      "wdi_nv_agr_totl_kd 158230 missing: 11 infinity: 0\n",
      "wdi_nv_agr_totl_kn 158230 missing: 11 infinity: 0\n",
      "wdi_ny_gdp_mktp_kd 158230 missing: 11 infinity: 0\n",
      "wdi_se_enr_prim_fm_zs 158230 missing: 11 infinity: 0\n",
      "wdi_se_enr_prsc_fm_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sh_sta_maln_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sh_sta_stnt_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sl_tlf_totl_fe_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sm_pop_refg_or 158230 missing: 11 infinity: 0\n",
      "wdi_sm_pop_netm 158230 missing: 11 infinity: 0\n",
      "wdi_sm_pop_totl_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sp_dyn_imrt_in 158230 missing: 11 infinity: 0\n",
      "wdi_sh_dyn_mort_fe 158230 missing: 11 infinity: 0\n",
      "wdi_sp_pop_14_fe_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sp_pop_1564_fe_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sp_pop_65up_fe_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sp_pop_grow 158230 missing: 11 infinity: 0\n",
      "wdi_sp_urb_totl_in_zs 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_delibdem 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_egaldem 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_libdem 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_libdem_48 158230 missing: 32 infinity: 0\n",
      "vdem_v2x_partip 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_partipdem 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_accountability 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_clphy 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_cspart 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_divparctrl 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_edcomp_thick 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_egal 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_execorr 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_frassoc_thick 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_gencs 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_gender 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_genpp 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_horacc 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_neopat 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_pubcorr 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_rule 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_veracc 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_ex_military 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_ex_party 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_freexp 158230 missing: 11 infinity: 0\n",
      "vdem_v2xcl_acjst 158230 missing: 11 infinity: 0\n",
      "vdem_v2xcl_dmove 158230 missing: 11 infinity: 0\n",
      "vdem_v2xcl_prpty 158230 missing: 11 infinity: 0\n",
      "vdem_v2xcl_rol 158230 missing: 11 infinity: 0\n",
      "faostat\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "gleditsch_ward 158230 missing: 0 infinity: 0\n",
      "wdi_sp_pop_totl 158230 missing: 11 infinity: 0\n",
      "consumer_prices_food_indices 158230 missing: 1437 infinity: 0\n",
      "consumer_prices_general_indices 158230 missing: 1437 infinity: 0\n",
      "food_price_inflation 158230 missing: 1437 infinity: 0\n",
      "avg_adequate_diet 158230 missing: 1437 infinity: 0\n",
      "avg_animalprotein_pcap_day 158230 missing: 1437 infinity: 0\n",
      "avg_fprod_value 158230 missing: 1437 infinity: 0\n",
      "avg_protein_pcap_day 158230 missing: 1437 infinity: 0\n",
      "gdp_pc_ppp 158230 missing: 1437 infinity: 0\n",
      "kcal_pcap_day 158230 missing: 1437 infinity: 0\n",
      "kcal_pcap_day_cerotu 158230 missing: 1437 infinity: 0\n",
      "pcap_fprod_var 158230 missing: 1437 infinity: 0\n",
      "pcap_fsupply_var 158230 missing: 1437 infinity: 0\n",
      "pct_arable_land 158230 missing: 1437 infinity: 0\n",
      "pct_cereal_import 158230 missing: 1437 infinity: 0\n",
      "pct_fimport_merch 158230 missing: 1437 infinity: 0\n",
      "pct_modsevere_finsecurity 158230 missing: 1437 infinity: 0\n",
      "pct_pop_basicdrink 158230 missing: 1437 infinity: 0\n",
      "pct_pop_basicsani 158230 missing: 1437 infinity: 0\n",
      "pct_pop_safedrink 158230 missing: 1437 infinity: 0\n",
      "pct_pop_safesani 158230 missing: 1437 infinity: 0\n",
      "pct_severe_finsecurity 158230 missing: 1437 infinity: 0\n",
      "pct_und5_overweight 158230 missing: 1437 infinity: 0\n",
      "pct_und5_stunted 158230 missing: 1437 infinity: 0\n",
      "pct_und5_wasting 158230 missing: 1437 infinity: 0\n",
      "pct_undernourished 158230 missing: 1437 infinity: 0\n",
      "pol_stability 158230 missing: 1437 infinity: 0\n",
      "pop_modsevere_finsecurity 158230 missing: 1437 infinity: 0\n",
      "pop_severe_finsecurity 158230 missing: 1437 infinity: 0\n",
      "pop_undernourished 158230 missing: 1437 infinity: 0\n",
      "prev_adult_obesity 158230 missing: 1437 infinity: 0\n",
      "prev_infant_bfeed 158230 missing: 1437 infinity: 0\n",
      "prev_lowbweight 158230 missing: 1437 infinity: 0\n",
      "prev_repr_anemia 158230 missing: 1437 infinity: 0\n",
      "rail_density 158230 missing: 1437 infinity: 0\n",
      "decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_5 158230 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "faoprices\n",
      "fao_wheat_price 158230 missing: 0 infinity: 0\n",
      "fao_mp_price 158230 missing: 0 infinity: 0\n",
      "fao_sugar_price 158230 missing: 0 infinity: 0\n",
      "fao_meat_price 158230 missing: 0 infinity: 0\n",
      "fao_milk_price 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "gleditsch_ward 158230 missing: 0 infinity: 0\n",
      "delta_fao_wheat_price 158230 missing: 0 infinity: 0\n",
      "delta_fao_mp_price 158230 missing: 0 infinity: 0\n",
      "delta_fao_sugar_price 158230 missing: 0 infinity: 0\n",
      "delta_fao_meat_price 158230 missing: 0 infinity: 0\n",
      "delta_fao_milk_price 158230 missing: 0 infinity: 0\n",
      "wdi_sp_pop_totl 158230 missing: 11 infinity: 0\n",
      "decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_5 158230 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "imfweo\n",
      "imfweo_ngdp_rpch_tcurrent 158230 missing: 0 infinity: 0\n",
      "imfweo_ngdp_rpch_tmin1 158230 missing: 0 infinity: 0\n",
      "imfweo_ngdp_rpch_tplus1 158230 missing: 0 infinity: 0\n",
      "imfweo_ngdp_rpch_tplus2 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "gleditsch_ward 158230 missing: 0 infinity: 0\n",
      "wdi_sp_pop_totl 158230 missing: 11 infinity: 0\n",
      "decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_5 158230 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "wdi_short\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "wdi_sp_pop_totl 158230 missing: 11 infinity: 0\n",
      "wdi_ag_lnd_frst_k2 158230 missing: 11 infinity: 0\n",
      "wdi_dt_oda_odat_pc_zs 158230 missing: 11 infinity: 0\n",
      "wdi_ms_mil_xpnd_gd_zs 158230 missing: 11 infinity: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wdi_ms_mil_xpnd_zs 158230 missing: 11 infinity: 0\n",
      "wdi_nv_agr_totl_kd 158230 missing: 11 infinity: 0\n",
      "wdi_nv_agr_totl_kn 158230 missing: 11 infinity: 0\n",
      "wdi_ny_gdp_mktp_kd 158230 missing: 11 infinity: 0\n",
      "wdi_se_enr_prim_fm_zs 158230 missing: 11 infinity: 0\n",
      "wdi_se_enr_prsc_fm_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sh_sta_maln_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sh_sta_stnt_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sl_tlf_totl_fe_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sm_pop_refg_or 158230 missing: 11 infinity: 0\n",
      "wdi_sm_pop_netm 158230 missing: 11 infinity: 0\n",
      "wdi_sm_pop_totl_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sp_dyn_imrt_in 158230 missing: 11 infinity: 0\n",
      "wdi_sh_dyn_mort_fe 158230 missing: 11 infinity: 0\n",
      "wdi_sp_pop_14_fe_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sp_pop_1564_fe_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sp_pop_65up_fe_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sp_pop_grow 158230 missing: 11 infinity: 0\n",
      "wdi_sp_urb_totl_in_zs 158230 missing: 11 infinity: 0\n",
      "splag_wdi_sl_tlf_totl_fe_zs 158230 missing: 0 infinity: 0\n",
      "splag_wdi_sm_pop_refg_or 158230 missing: 0 infinity: 0\n",
      "splag_wdi_sm_pop_netm 158230 missing: 0 infinity: 0\n",
      "splag_wdi_ag_lnd_frst_k2 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_5 158230 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "joint_broad\n",
      "gleditsch_ward 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "ln_ged_ns 158230 missing: 0 infinity: 0\n",
      "ln_ged_os 158230 missing: 0 infinity: 0\n",
      "ln_acled_sb 158230 missing: 1437 infinity: 0\n",
      "ln_acled_sb_count 158230 missing: 1437 infinity: 0\n",
      "ln_acled_os 158230 missing: 1437 infinity: 0\n",
      "wdi_sp_pop_totl 158230 missing: 11 infinity: 0\n",
      "wdi_sm_pop_netm 158230 missing: 11 infinity: 0\n",
      "wdi_sm_pop_refg_or 158230 missing: 11 infinity: 0\n",
      "wdi_dt_oda_odat_pc_zs 158230 missing: 11 infinity: 0\n",
      "wdi_ms_mil_xpnd_gd_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sl_tlf_totl_fe_zs 158230 missing: 11 infinity: 0\n",
      "wdi_nv_agr_totl_kn 158230 missing: 11 infinity: 0\n",
      "wdi_sp_pop_grow 158230 missing: 11 infinity: 0\n",
      "wdi_se_enr_prim_fm_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sp_urb_totl_in_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sh_sta_maln_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sp_dyn_imrt_fe_in 158230 missing: 11 infinity: 0\n",
      "wdi_ny_gdp_mktp_kd 158230 missing: 11 infinity: 0\n",
      "wdi_sh_sta_stnt_zs 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_horacc 158230 missing: 11 infinity: 0\n",
      "vdem_v2xnp_client 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_veracc 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_divparctrl 158230 missing: 11 infinity: 0\n",
      "vdem_v2xpe_exlpol 158230 missing: 266 infinity: 0\n",
      "vdem_v2x_diagacc 158230 missing: 11 infinity: 0\n",
      "vdem_v2xpe_exlgeo 158230 missing: 266 infinity: 0\n",
      "vdem_v2xpe_exlgender 158230 missing: 266 infinity: 0\n",
      "vdem_v2xpe_exlsocgr 158230 missing: 266 infinity: 0\n",
      "vdem_v2x_ex_party 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_genpp 158230 missing: 11 infinity: 0\n",
      "vdem_v2xeg_eqdr 158230 missing: 11 infinity: 0\n",
      "vdem_v2xcl_prpty 158230 missing: 11 infinity: 0\n",
      "vdem_v2xeg_eqprotec 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_ex_military 158230 missing: 11 infinity: 0\n",
      "vdem_v2xcl_dmove 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_clphy 158230 missing: 11 infinity: 0\n",
      "vdem_v2x_hosabort 158230 missing: 11 infinity: 0\n",
      "vdem_v2xnp_regcorr 158230 missing: 11 infinity: 0\n",
      "ln_ged_sb_tlag_1 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_2 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_3 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_4 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_5 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_6 158230 missing: 11 infinity: 0\n",
      "ln_ged_os_tlag_1 158230 missing: 5 infinity: 0\n",
      "topic0_religion_t1 158230 missing: 5 infinity: 0\n",
      "topic0_religion_t13 158230 missing: 11 infinity: 0\n",
      "topic1_politics_t1 158230 missing: 5 infinity: 0\n",
      "joint_narrow\n",
      "ln_ged_sb_dep 158230 missing: 0 infinity: 0\n",
      "gleditsch_ward 158230 missing: 0 infinity: 0\n",
      "ln_ged_sb 158230 missing: 0 infinity: 0\n",
      "reign_tenure_months 158230 missing: 0 infinity: 0\n",
      "wdi_sp_pop_totl 158230 missing: 11 infinity: 0\n",
      "wdi_ag_lnd_frst_k2 158230 missing: 11 infinity: 0\n",
      "wdi_nv_agr_totl_kn 158230 missing: 11 infinity: 0\n",
      "wdi_sh_sta_maln_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sl_tlf_totl_fe_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sm_pop_refg_or 158230 missing: 11 infinity: 0\n",
      "wdi_sp_dyn_imrt_in 158230 missing: 11 infinity: 0\n",
      "wdi_sp_pop_14_fe_zs 158230 missing: 11 infinity: 0\n",
      "wdi_sp_pop_grow 158230 missing: 11 infinity: 0\n",
      "vdem_v2xcl_dmove 158230 missing: 11 infinity: 0\n",
      "vdem_v2xcl_rol 158230 missing: 11 infinity: 0\n",
      "vdem_v2xeg_eqdr 158230 missing: 11 infinity: 0\n",
      "vdem_v2xpe_exlpol 158230 missing: 266 infinity: 0\n",
      "vdem_v2xpe_exlsocgr 158230 missing: 266 infinity: 0\n",
      "ln_ged_sb_tlag_1 158230 missing: 5 infinity: 0\n",
      "ln_ged_sb_tlag_2 158230 missing: 5 infinity: 0\n",
      "ste_theta2_stock 158230 missing: 5 infinity: 0\n",
      "splag_wdi_ag_lnd_frst_k2 158230 missing: 0 infinity: 0\n",
      "splag_wdi_sl_tlf_totl_fe_zs 158230 missing: 0 infinity: 0\n",
      "splag_wdi_sm_pop_netm 158230 missing: 0 infinity: 0\n",
      "splag_vdem_v2xpe_exlsocgr 158230 missing: 0 infinity: 0\n",
      "splag_vdem_v2xcl_rol 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_os_5 158230 missing: 0 infinity: 0\n",
      "decay_acled_os_5 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_100 158230 missing: 0 infinity: 0\n",
      "decay_ged_sb_500 158230 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 158230 missing: 0 infinity: 0\n",
      "ste_theta3_stock 158230 missing: 5 infinity: 0\n",
      "ste_theta11_stock 158230 missing: 5 infinity: 0\n",
      "ste_theta13_stock 158230 missing: 5 infinity: 0\n",
      "ste_theta14_stock 158230 missing: 5 infinity: 0\n",
      "splag_ste_theta2_stock 158230 missing: 0 infinity: 0\n",
      "splag_ste_theta11_stock 158230 missing: 0 infinity: 0\n",
      "splag_ste_theta13_stock 158230 missing: 0 infinity: 0\n",
      "pca_all\n",
      "ln_ged_sb_dep 74316 missing: 0 infinity: 0\n",
      "ln_ged_sb 74316 missing: 0 infinity: 0\n",
      "decay_ged_sb_5 74316 missing: 0 infinity: 0\n",
      "decay_ged_os_5 74316 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 74316 missing: 0 infinity: 0\n",
      "wdi_sp_pop_totl 74316 missing: 11 infinity: 0\n",
      "pc1 74316 missing: 0 infinity: 0\n",
      "pc2 74316 missing: 0 infinity: 0\n",
      "pc3 74316 missing: 0 infinity: 0\n",
      "pc4 74316 missing: 0 infinity: 0\n",
      "pc5 74316 missing: 0 infinity: 0\n",
      "pc6 74316 missing: 0 infinity: 0\n",
      "pc7 74316 missing: 0 infinity: 0\n",
      "pc8 74316 missing: 0 infinity: 0\n",
      "pc9 74316 missing: 0 infinity: 0\n",
      "pc10 74316 missing: 0 infinity: 0\n",
      "pc11 74316 missing: 0 infinity: 0\n",
      "pc12 74316 missing: 0 infinity: 0\n",
      "pc13 74316 missing: 0 infinity: 0\n",
      "pc14 74316 missing: 0 infinity: 0\n",
      "pc15 74316 missing: 0 infinity: 0\n",
      "pc16 74316 missing: 0 infinity: 0\n",
      "pc17 74316 missing: 0 infinity: 0\n",
      "pc18 74316 missing: 0 infinity: 0\n",
      "pc19 74316 missing: 0 infinity: 0\n",
      "pc20 74316 missing: 0 infinity: 0\n",
      "pca_topics\n",
      "ln_ged_sb_dep 74316 missing: 0 infinity: 0\n",
      "ln_ged_sb 74316 missing: 0 infinity: 0\n",
      "decay_ged_sb_5 74316 missing: 0 infinity: 0\n",
      "decay_ged_os_5 74316 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 74316 missing: 0 infinity: 0\n",
      "wdi_sp_pop_totl 74316 missing: 11 infinity: 0\n",
      "pc1 74316 missing: 0 infinity: 0\n",
      "pc2 74316 missing: 0 infinity: 0\n",
      "pc3 74316 missing: 0 infinity: 0\n",
      "pc4 74316 missing: 0 infinity: 0\n",
      "pc5 74316 missing: 0 infinity: 0\n",
      "pc6 74316 missing: 0 infinity: 0\n",
      "pc7 74316 missing: 0 infinity: 0\n",
      "pc8 74316 missing: 0 infinity: 0\n",
      "pc9 74316 missing: 0 infinity: 0\n",
      "pc10 74316 missing: 0 infinity: 0\n",
      "pca_vdem\n",
      "ln_ged_sb_dep 74316 missing: 0 infinity: 0\n",
      "ln_ged_sb 74316 missing: 0 infinity: 0\n",
      "decay_ged_sb_5 74316 missing: 0 infinity: 0\n",
      "decay_ged_os_5 74316 missing: 0 infinity: 0\n",
      "splag_1_decay_ged_sb_5 74316 missing: 0 infinity: 0\n",
      "wdi_sp_pop_totl 74316 missing: 11 infinity: 0\n",
      "pc1 74316 missing: 0 infinity: 0\n",
      "pc2 74316 missing: 0 infinity: 0\n",
      "pc3 74316 missing: 0 infinity: 0\n",
      "pc4 74316 missing: 0 infinity: 0\n",
      "pc5 74316 missing: 0 infinity: 0\n",
      "pc6 74316 missing: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N=51\n",
    "for i in range(len(Datasets)):\n",
    "    df = Datasets[i]['df']\n",
    "    print(Datasets[i]['Name'])\n",
    "    for col in df.iloc[: , :N].columns:\n",
    "        print(col,len(df[col]), 'missing:', df[col].isnull().sum(), 'infinity:', np.isinf(df).values.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c761eb9c",
   "metadata": {},
   "source": [
    "# Specify models in ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "425514d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fatalities002_baseline_rf baseline002\n",
      "1 fatalities002_conflicthistory_rf conflict_ln\n",
      "2 fatalities002_conflicthistory_gbm conflict_ln\n",
      "3 fatalities002_conflicthistory_hurdle_lgb conflict_ln\n",
      "4 fatalities002_conflicthistory_long_xgb conflictlong_ln\n",
      "5 fatalities002_vdem_hurdle_xgb vdem_short\n",
      "6 fatalities002_wdi_rf wdi_short\n",
      "7 fatalities002_topics_rf topics_002\n",
      "8 fatalities002_topics_xgb topics_002\n",
      "9 fatalities002_topics_hurdle_lgb topics_002\n",
      "10 fatalities002_joint_broad_rf joint_broad\n",
      "11 fatalities002_joint_broad_hurdle_rf joint_broad\n",
      "12 fatalities002_joint_narrow_xgb joint_narrow\n",
      "13 fatalities002_joint_narrow_hurdle_xgb joint_narrow\n",
      "14 fatalities002_joint_narrow_hurdle_lgb joint_narrow\n",
      "15 fatalities002_all_pca3_xgb all_features\n",
      "16 fatalities002_aquastat_rf aquastat\n",
      "17 fatalities002_faostat_rf faostat\n",
      "18 fatalities002_faoprices_rf faoprices\n",
      "19 fatalities002_imfweo_rf imfweo\n",
      "20 fat_hh20_Markov_glm joint_narrow\n",
      "21 fat_hh20_Markov_rf joint_narrow\n"
     ]
    }
   ],
   "source": [
    "from ModelDefinitions import DefineEnsembleModels\n",
    "\n",
    "ModelList = DefineEnsembleModels('cm')\n",
    "    \n",
    "for imodel,model in enumerate(ModelList):\n",
    "    print(imodel, model['modelname'], model['data_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b1b6322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'modelname': 'fatalities002_baseline_rf',\n",
       "  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                 colsample_bylevel=None, colsample_bytree=None,\n",
       "                 early_stopping_rounds=None, enable_categorical=False,\n",
       "                 eval_metric=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                 importance_type=None, interaction_constraints=None, max_bin=None,\n",
       "                 max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                 max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                 monotone_constraints=None, n_estimators=300, n_jobs=12,\n",
       "                 num_parallel_tree=None, objective='reg:squarederror',\n",
       "                 predictor=None, random_state=None, reg_alpha=None,\n",
       "                 sampling_method=None, scale_pos_weight=None, ...),\n",
       "  'depvar': 'ln_ged_sb_dep',\n",
       "  'data_train': 'baseline002',\n",
       "  'queryset': 'fatalities002_baseline',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': 'Baseline model with a few conflict history features as well as log population, random forests regression model.',\n",
       "  'long_description': 'A very simple model with only five data columns (each column representing one feature): The number of fatalities in the same country at $t-1$, three decay functions of time since there was at least five fatalities in a single month, for each of the UCDP conflict types -- state-based, one-sided, or non-state conflict -- and log population size (Hegre2020RP,Pettersson2021JPR).The features in the baseline are included in all the models described below. This ensures that all models in the ensemble provides at least moderately good predictions, while guaranteeing diversity in feature sets and modelling approaches.',\n",
       "  'predstore_calib': 'cm_fatalities002_baseline_rf_calib',\n",
       "  'predstore_test': 'cm_fatalities002_baseline_rf_test'},\n",
       " {'modelname': 'fatalities002_conflicthistory_rf',\n",
       "  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                 colsample_bylevel=None, colsample_bytree=None,\n",
       "                 early_stopping_rounds=None, enable_categorical=False,\n",
       "                 eval_metric=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                 importance_type=None, interaction_constraints=None, max_bin=None,\n",
       "                 max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                 max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                 monotone_constraints=None, n_estimators=250, n_jobs=12,\n",
       "                 num_parallel_tree=None, objective='reg:squarederror',\n",
       "                 predictor=None, random_state=None, reg_alpha=None,\n",
       "                 sampling_method=None, scale_pos_weight=None, ...),\n",
       "  'depvar': 'ln_ged_sb_dep',\n",
       "  'data_train': 'conflict_ln',\n",
       "  'queryset': 'fatalities002_conflict_history',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': 'A collection of variables that together map the conflict history of a country, random forests regression model.',\n",
       "  'long_description': 'A collection of variables that together map the conflict history of a country. The features include lagged dependent variables for each conflict type as coded by the UCDP (state-based, one-sided, or non-state) for up to each of the preceding six months, decay functions of time since conflict caused 5, 100, and 500 deaths in a month, for each type of violence, whether ACLED (https://doi.org/10.1177/0022343310378914 recorded similar violence, and whether there was recent violence in any neighboring countries.',\n",
       "  'predstore_calib': 'cm_fatalities002_conflicthistory_rf_calib',\n",
       "  'predstore_test': 'cm_fatalities002_conflicthistory_rf_test'},\n",
       " {'modelname': 'fatalities002_conflicthistory_gbm',\n",
       "  'algorithm': GradientBoostingRegressor(n_estimators=200),\n",
       "  'depvar': 'ln_ged_sb_dep',\n",
       "  'data_train': 'conflict_ln',\n",
       "  'queryset': 'fatalities002_conflict_history',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': 'A collection of variables that together map the conflict history of a country, scikit gradient boosting regression model.',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities002_conflicthistory_gbm_calib',\n",
       "  'predstore_test': 'cm_fatalities002_conflicthistory_gbm_test'},\n",
       " {'modelname': 'fatalities002_conflicthistory_hurdle_lgb',\n",
       "  'algorithm': HurdleRegression(clf_name='LGBMClassifier', reg_name='LGBMRegressor'),\n",
       "  'depvar': 'ln_ged_sb_dep',\n",
       "  'data_train': 'conflict_ln',\n",
       "  'queryset': 'fatalities002_conflict_history',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities002_conflicthistory_hurdle_lgb_calib',\n",
       "  'predstore_test': 'cm_fatalities002_conflicthistory_hurdle_lgb_test'},\n",
       " {'modelname': 'fatalities002_conflicthistory_long_xgb',\n",
       "  'algorithm': XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric=None, gamma=None,\n",
       "               gpu_id=None, grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "               max_leaves=None, min_child_weight=None, missing=nan,\n",
       "               monotone_constraints=None, n_estimators=100, n_jobs=12,\n",
       "               num_parallel_tree=None, predictor=None, random_state=None,\n",
       "               reg_alpha=None, reg_lambda=None, ...),\n",
       "  'depvar': 'ln_ged_sb_dep',\n",
       "  'data_train': 'conflictlong_ln',\n",
       "  'queryset': 'fatalities002_conflict_history_long',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities002_conflicthistory_long_xgb_calib',\n",
       "  'predstore_test': 'cm_fatalities002_conflicthistory_long_xgb_test'},\n",
       " {'modelname': 'fatalities002_vdem_hurdle_xgb',\n",
       "  'algorithm': HurdleRegression(clf_name='XGBClassifier', reg_name='XGBRegressor'),\n",
       "  'depvar': 'ln_ged_sb_dep',\n",
       "  'data_train': 'vdem_short',\n",
       "  'queryset': 'fatalities002_vdem_short',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities002_vdem_hurdle_xgb_calib',\n",
       "  'predstore_test': 'cm_fatalities002_vdem_hurdle_xgb_test'},\n",
       " {'modelname': 'fatalities002_wdi_rf',\n",
       "  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                 colsample_bylevel=None, colsample_bytree=None,\n",
       "                 early_stopping_rounds=None, enable_categorical=False,\n",
       "                 eval_metric=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                 importance_type=None, interaction_constraints=None, max_bin=None,\n",
       "                 max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                 max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                 monotone_constraints=None, n_estimators=300, n_jobs=12,\n",
       "                 num_parallel_tree=None, objective='reg:squarederror',\n",
       "                 predictor=None, random_state=None, reg_alpha=None,\n",
       "                 sampling_method=None, scale_pos_weight=None, ...),\n",
       "  'depvar': 'ln_ged_sb_dep',\n",
       "  'data_train': 'wdi_short',\n",
       "  'queryset': 'fatalities002_wdi_short',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities002_wdi_rf_calib',\n",
       "  'predstore_test': 'cm_fatalities002_wdi_rf_test'},\n",
       " {'modelname': 'fatalities002_topics_rf',\n",
       "  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                 colsample_bylevel=None, colsample_bytree=None,\n",
       "                 early_stopping_rounds=None, enable_categorical=False,\n",
       "                 eval_metric=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                 importance_type=None, interaction_constraints=None, max_bin=None,\n",
       "                 max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                 max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                 monotone_constraints=None, n_estimators=250, n_jobs=12,\n",
       "                 num_parallel_tree=None, objective='reg:squarederror',\n",
       "                 predictor=None, random_state=None, reg_alpha=None,\n",
       "                 sampling_method=None, scale_pos_weight=None, ...),\n",
       "  'depvar': 'ln_ged_sb_dep',\n",
       "  'data_train': 'topics_002',\n",
       "  'queryset': 'fatalities002_topics',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities002_topics_rf_calib',\n",
       "  'predstore_test': 'cm_fatalities002_topics_rf_test'},\n",
       " {'modelname': 'fatalities002_topics_xgb',\n",
       "  'algorithm': XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric=None, gamma=None,\n",
       "               gpu_id=None, grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "               max_leaves=None, min_child_weight=None, missing=nan,\n",
       "               monotone_constraints=None, n_estimators=80, n_jobs=12,\n",
       "               num_parallel_tree=None, predictor=None, random_state=None,\n",
       "               reg_alpha=None, reg_lambda=None, ...),\n",
       "  'depvar': 'ln_ged_sb_dep',\n",
       "  'data_train': 'topics_002',\n",
       "  'queryset': 'fatalities002_topics',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities002_topics_xgb_calib',\n",
       "  'predstore_test': 'cm_fatalities002_topics_xgb_test'},\n",
       " {'modelname': 'fatalities002_topics_hurdle_lgb',\n",
       "  'algorithm': HurdleRegression(clf_name='LGBMClassifier', reg_name='LGBMRegressor'),\n",
       "  'depvar': 'ln_ged_sb_dep',\n",
       "  'data_train': 'topics_002',\n",
       "  'queryset': 'fatalities002_topics',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities002_topics_hurdle_lgb_calib',\n",
       "  'predstore_test': 'cm_fatalities002_topics_hurdle_lgb_test'},\n",
       " {'modelname': 'fatalities002_joint_broad_rf',\n",
       "  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                 colsample_bylevel=None, colsample_bytree=None,\n",
       "                 early_stopping_rounds=None, enable_categorical=False,\n",
       "                 eval_metric=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                 importance_type=None, interaction_constraints=None, max_bin=None,\n",
       "                 max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                 max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                 monotone_constraints=None, n_estimators=250, n_jobs=12,\n",
       "                 num_parallel_tree=None, objective='reg:squarederror',\n",
       "                 predictor=None, random_state=None, reg_alpha=None,\n",
       "                 sampling_method=None, scale_pos_weight=None, ...),\n",
       "  'depvar': 'ln_ged_sb_dep',\n",
       "  'data_train': 'joint_broad',\n",
       "  'queryset': 'fatalities002_joint_broad',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities002_joint_broad_rf_calib',\n",
       "  'predstore_test': 'cm_fatalities002_joint_broad_rf_test'},\n",
       " {'modelname': 'fatalities002_joint_broad_hurdle_rf',\n",
       "  'algorithm': HurdleRegression(clf_name='RFClassifier', reg_name='RFRegressor'),\n",
       "  'depvar': 'ln_ged_sb_dep',\n",
       "  'data_train': 'joint_broad',\n",
       "  'queryset': 'fatalities002_joint_broad',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities002_joint_broad_hurdle_rf_calib',\n",
       "  'predstore_test': 'cm_fatalities002_joint_broad_hurdle_rf_test'},\n",
       " {'modelname': 'fatalities002_joint_narrow_xgb',\n",
       "  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                 colsample_bylevel=None, colsample_bytree=None,\n",
       "                 early_stopping_rounds=None, enable_categorical=False,\n",
       "                 eval_metric=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                 importance_type=None, interaction_constraints=None, max_bin=None,\n",
       "                 max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                 max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                 monotone_constraints=None, n_estimators=250, n_jobs=12,\n",
       "                 num_parallel_tree=None, objective='reg:squarederror',\n",
       "                 predictor=None, random_state=None, reg_alpha=None,\n",
       "                 sampling_method=None, scale_pos_weight=None, ...),\n",
       "  'depvar': 'ln_ged_sb_dep',\n",
       "  'data_train': 'joint_narrow',\n",
       "  'queryset': 'fatalities002_joint_narrow',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities002_joint_narrow_xgb_calib',\n",
       "  'predstore_test': 'cm_fatalities002_joint_narrow_xgb_test'},\n",
       " {'modelname': 'fatalities002_joint_narrow_hurdle_xgb',\n",
       "  'algorithm': HurdleRegression(clf_name='XGBClassifier', reg_name='XGBRegressor'),\n",
       "  'depvar': 'ln_ged_sb_dep',\n",
       "  'data_train': 'joint_narrow',\n",
       "  'queryset': 'fatalities002_joint_narrow',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities002_joint_narrow_hurdle_xgb_calib',\n",
       "  'predstore_test': 'cm_fatalities002_joint_narrow_hurdle_xgb_test'},\n",
       " {'modelname': 'fatalities002_joint_narrow_hurdle_lgb',\n",
       "  'algorithm': HurdleRegression(clf_name='LGBMClassifier', reg_name='LGBMRegressor'),\n",
       "  'depvar': 'ln_ged_sb_dep',\n",
       "  'data_train': 'joint_narrow',\n",
       "  'queryset': 'fatalities002_joint_narrow',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities002_joint_narrow_hurdle_lgb_calib',\n",
       "  'predstore_test': 'cm_fatalities002_joint_narrow_hurdle_lgb_test'},\n",
       " {'modelname': 'fatalities002_all_pca3_xgb',\n",
       "  'algorithm': XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric=None, gamma=None,\n",
       "               gpu_id=None, grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "               max_leaves=None, min_child_weight=None, missing=nan,\n",
       "               monotone_constraints=None, n_estimators=100, n_jobs=12,\n",
       "               num_parallel_tree=None, predictor=None, random_state=None,\n",
       "               reg_alpha=None, reg_lambda=None, ...),\n",
       "  'depvar': 'ln_ged_sb_dep',\n",
       "  'data_train': 'all_features',\n",
       "  'queryset': 'fatalities002_all_features',\n",
       "  'preprocessing': 'pca_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities002_all_pca3_xgb_calib',\n",
       "  'predstore_test': 'cm_fatalities002_all_pca3_xgb_test'},\n",
       " {'modelname': 'fatalities002_aquastat_rf',\n",
       "  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                 colsample_bylevel=None, colsample_bytree=None,\n",
       "                 early_stopping_rounds=None, enable_categorical=False,\n",
       "                 eval_metric=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                 importance_type=None, interaction_constraints=None, max_bin=None,\n",
       "                 max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                 max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                 monotone_constraints=None, n_estimators=300, n_jobs=12,\n",
       "                 num_parallel_tree=None, objective='reg:squarederror',\n",
       "                 predictor=None, random_state=None, reg_alpha=None,\n",
       "                 sampling_method=None, scale_pos_weight=None, ...),\n",
       "  'depvar': 'ln_ged_sb_dep',\n",
       "  'data_train': 'aquastat',\n",
       "  'queryset': 'fatalities002_aquastat',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities002_aquastat_rf_calib',\n",
       "  'predstore_test': 'cm_fatalities002_aquastat_rf_test'},\n",
       " {'modelname': 'fatalities002_faostat_rf',\n",
       "  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                 colsample_bylevel=None, colsample_bytree=None,\n",
       "                 early_stopping_rounds=None, enable_categorical=False,\n",
       "                 eval_metric=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                 importance_type=None, interaction_constraints=None, max_bin=None,\n",
       "                 max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                 max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                 monotone_constraints=None, n_estimators=300, n_jobs=12,\n",
       "                 num_parallel_tree=None, objective='reg:squarederror',\n",
       "                 predictor=None, random_state=None, reg_alpha=None,\n",
       "                 sampling_method=None, scale_pos_weight=None, ...),\n",
       "  'depvar': 'ln_ged_sb_dep',\n",
       "  'data_train': 'faostat',\n",
       "  'queryset': 'fatalities002_faostat',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities002_faostat_rf_calib',\n",
       "  'predstore_test': 'cm_fatalities002_faostat_rf_test'},\n",
       " {'modelname': 'fatalities002_faoprices_rf',\n",
       "  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                 colsample_bylevel=None, colsample_bytree=None,\n",
       "                 early_stopping_rounds=None, enable_categorical=False,\n",
       "                 eval_metric=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                 importance_type=None, interaction_constraints=None, max_bin=None,\n",
       "                 max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                 max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                 monotone_constraints=None, n_estimators=300, n_jobs=12,\n",
       "                 num_parallel_tree=None, objective='reg:squarederror',\n",
       "                 predictor=None, random_state=None, reg_alpha=None,\n",
       "                 sampling_method=None, scale_pos_weight=None, ...),\n",
       "  'depvar': 'ln_ged_sb_dep',\n",
       "  'data_train': 'faoprices',\n",
       "  'queryset': 'fatalities002_faoprices',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities002_faoprices_rf_calib',\n",
       "  'predstore_test': 'cm_fatalities002_faoprices_rf_test'},\n",
       " {'modelname': 'fatalities002_imfweo_rf',\n",
       "  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                 colsample_bylevel=None, colsample_bytree=None,\n",
       "                 early_stopping_rounds=None, enable_categorical=False,\n",
       "                 eval_metric=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                 importance_type=None, interaction_constraints=None, max_bin=None,\n",
       "                 max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                 max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                 monotone_constraints=None, n_estimators=300, n_jobs=12,\n",
       "                 num_parallel_tree=None, objective='reg:squarederror',\n",
       "                 predictor=None, random_state=None, reg_alpha=None,\n",
       "                 sampling_method=None, scale_pos_weight=None, ...),\n",
       "  'depvar': 'ln_ged_sb_dep',\n",
       "  'data_train': 'imfweo',\n",
       "  'queryset': 'fatalities002_imfweo',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities002_imfweo_rf_calib',\n",
       "  'predstore_test': 'cm_fatalities002_imfweo_rf_test'},\n",
       " {'modelname': 'fat_hh20_Markov_glm',\n",
       "  'algorithm': 'Rscript',\n",
       "  'depvar': 'ln_ged_sb_dep',\n",
       "  'data_train': 'joint_narrow',\n",
       "  'queryset': 'fatalities002_joint_narrow',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fat_hh20_Markov_glm_calib',\n",
       "  'predstore_test': 'cm_fat_hh20_Markov_glm_test'},\n",
       " {'modelname': 'fat_hh20_Markov_rf',\n",
       "  'algorithm': 'Rscript',\n",
       "  'depvar': 'ln_ged_sb_dep',\n",
       "  'data_train': 'joint_narrow',\n",
       "  'queryset': 'fatalities002_joint_narrow',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fat_hh20_Markov_rf_calib',\n",
       "  'predstore_test': 'cm_fat_hh20_Markov_rf_test'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "613b4f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fatalities002_baseline_rf baseline002\n",
      "1 fatalities002_conflicthistory_rf conflict_ln\n",
      "2 fatalities002_conflicthistory_gbm conflict_ln\n",
      "3 fatalities002_conflicthistory_hurdle_lgb conflict_ln\n",
      "4 fatalities002_conflicthistory_long_xgb conflictlong_ln\n",
      "5 fatalities002_vdem_hurdle_xgb vdem_short\n",
      "6 fatalities002_wdi_rf wdi_short\n",
      "7 fatalities002_topics_rf topics_002\n",
      "8 fatalities002_topics_xgb topics_002\n",
      "9 fatalities002_topics_hurdle_lgb topics_002\n",
      "10 fatalities002_joint_broad_rf joint_broad\n",
      "11 fatalities002_joint_broad_hurdle_rf joint_broad\n",
      "12 fatalities002_joint_narrow_xgb joint_narrow\n",
      "13 fatalities002_joint_narrow_hurdle_xgb joint_narrow\n",
      "14 fatalities002_joint_narrow_hurdle_lgb joint_narrow\n",
      "15 fatalities002_all_pca3_xgb all_features\n",
      "16 fatalities002_aquastat_rf aquastat\n",
      "17 fatalities002_faostat_rf faostat\n",
      "18 fatalities002_faoprices_rf faoprices\n",
      "19 fatalities002_imfweo_rf imfweo\n",
      "20 fat_hh20_Markov_glm joint_narrow\n",
      "21 fat_hh20_Markov_rf joint_narrow\n"
     ]
    }
   ],
   "source": [
    "document_ensemble(ModelList,'sb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10c58f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fatalities002_baseline_rf\n",
      "Calibration partition 2022-09-21 07:44:43.702963\n",
      " * == Performing a run: \"fatalities002_baseline_rf_calib\" == * \n",
      "Model object named \"fatalities002_baseline_rf_calib\" with equivalent metadata already exists.\n",
      "Fetching \"fatalities002_baseline_rf_calib\" from storage\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:55] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:55] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:55] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:55] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:55] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:55] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:55] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[07:44:55] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[07:44:55] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1660208952489/work/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "Trying to retrieve predictions 2022-09-21 07:44:55.091553\n",
      "pr_49_cm_fatalities002_baseline_rf_calib.parquet\n",
      "cm_fatalities002_baseline_rf_calib , run Fatalities002 does not exist, predicting\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'XGBModel' object has no attribute 'callbacks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/views_storage/key_value_store.py:38\u001b[0m, in \u001b[0;36mKeyValueStore.read\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     raw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m raw \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/views_storage/backends/azure.py:47\u001b[0m, in \u001b[0;36mAzureBlobStorageBackend.retrieve\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pr_49_cm_fatalities002_baseline_rf_calib.parquet does not exist'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 40\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     predictions_calib \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforecasts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredstore_calib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/views_forecasts/extensions.py:224\u001b[0m, in \u001b[0;36mForecastAccessor.read_store\u001b[0;34m(cls, name, run)\u001b[0m\n\u001b[1;32m    223\u001b[0m run \u001b[38;5;241m=\u001b[39m ViewsMetadata()\u001b[38;5;241m.\u001b[39mrun_to_run_id(run)\n\u001b[0;32m--> 224\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mForecastsStore\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(df, run\u001b[38;5;241m=\u001b[39mrun)\u001b[38;5;241m.\u001b[39mas_df\n",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/views_forecasts/file_ops.py:48\u001b[0m, in \u001b[0;36mForecastsStore.read\u001b[0;34m(self, name, run)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(key)\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/views_storage/key_value_store.py:41\u001b[0m, in \u001b[0;36mKeyValueStore.read\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m):\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserializer\u001b[38;5;241m.\u001b[39mdeserialize(raw)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pr_49_cm_fatalities002_baseline_rf_calib.parquet does not exist'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredstore_calib\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, run\u001b[39m\u001b[38;5;124m'\u001b[39m,  run_id, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoes not exist, predicting\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m     predictions_calib \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRunResult_calib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcalib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRunResult_calib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     predictions_calib\u001b[38;5;241m.\u001b[39mforecasts\u001b[38;5;241m.\u001b[39mset_run(run_id)\n\u001b[1;32m     45\u001b[0m     predictions_calib\u001b[38;5;241m.\u001b[39mforecasts\u001b[38;5;241m.\u001b[39mto_store(name\u001b[38;5;241m=\u001b[39mmodel[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredstore_calib\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/views_runs/validation.py:23\u001b[0m, in \u001b[0;36mviews_validate.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m     dataframe_is_right_format(args[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/views_runs/run.py:69\u001b[0m, in \u001b[0;36mViewsRun.predict\u001b[0;34m(self, partition_name, timespan_name, data)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;129m@validation\u001b[39m\u001b[38;5;241m.\u001b[39mviews_validate\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, partition_name: \u001b[38;5;28mstr\u001b[39m, timespan_name: \u001b[38;5;28mstr\u001b[39m, data: pd\u001b[38;5;241m.\u001b[39mDataFrame)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    predict\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m    =======\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    timespan.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shifted_partitioner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartition_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimespan_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcombine\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames\n\u001b[1;32m     73\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mmerge(predictions, how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, left_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, right_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/stepshift/views.py:130\u001b[0m, in \u001b[0;36mStepshiftedModels.predict\u001b[0;34m(self, data, combine)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, combine: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    predict\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    =======\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    \"step_pred_{i}\" with predictions for each step.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/stepshift/views.py:247\u001b[0m, in \u001b[0;36mStepshiftedModels._predict\u001b[0;34m(self, data, combine, kind)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step_column_name, (step, model) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(preds\u001b[38;5;241m.\u001b[39mcoords[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m\"\u001b[39m],\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_models\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[1;32m    244\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaking predictions for model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep_column_name\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    246\u001b[0m     raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_predictions_shape(\n\u001b[0;32m--> 247\u001b[0m             \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_independent_variables\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    249\u001b[0m     mat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([\n\u001b[1;32m    250\u001b[0m                 raw_idx[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mstep,\n\u001b[1;32m    251\u001b[0m                 raw_idx[:,\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    252\u001b[0m                 raw_predictions,\n\u001b[1;32m    253\u001b[0m             ], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    255\u001b[0m     cube \u001b[38;5;241m=\u001b[39m cast\u001b[38;5;241m.\u001b[39mtime_unit_feature_cube(\n\u001b[1;32m    256\u001b[0m             xa\u001b[38;5;241m.\u001b[39mDataArray(mat, dims \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrows\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    257\u001b[0m             )\n",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/xgboost/sklearn.py:1047\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1043\u001b[0m iteration_range \u001b[38;5;241m=\u001b[39m _convert_ntree_limit(\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_booster(), ntree_limit, iteration_range\n\u001b[1;32m   1045\u001b[0m )\n\u001b[1;32m   1046\u001b[0m iteration_range \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iteration_range(iteration_range)\n\u001b[0;32m-> 1047\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_can_use_inplace_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1048\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1049\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_booster()\u001b[38;5;241m.\u001b[39minplace_predict(\n\u001b[1;32m   1050\u001b[0m             data\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   1051\u001b[0m             iteration_range\u001b[38;5;241m=\u001b[39miteration_range,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1055\u001b[0m             validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[1;32m   1056\u001b[0m         )\n",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/xgboost/sklearn.py:983\u001b[0m, in \u001b[0;36mXGBModel._can_use_inplace_predict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_can_use_inplace_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;66;03m# When predictor is explicitly set, using `inplace_predict` might result into\u001b[39;00m\n\u001b[1;32m    980\u001b[0m     \u001b[38;5;66;03m# error with incompatible data type.\u001b[39;00m\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;66;03m# Inplace predict doesn't handle as many data types as DMatrix, but it's\u001b[39;00m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;66;03m# sufficient for dask interface where input is simpiler.\u001b[39;00m\n\u001b[0;32m--> 983\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m predictor \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbooster \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/xgboost/sklearn.py:636\u001b[0m, in \u001b[0;36mXGBModel.get_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    634\u001b[0m cp \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    635\u001b[0m cp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__bases__\u001b[39m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 636\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    637\u001b[0m \u001b[38;5;66;03m# if kwargs is a dict, update params accordingly\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/xgboost/sklearn.py:636\u001b[0m, in \u001b[0;36mXGBModel.get_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    634\u001b[0m cp \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    635\u001b[0m cp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__bases__\u001b[39m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 636\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    637\u001b[0m \u001b[38;5;66;03m# if kwargs is a dict, update params accordingly\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/xgboost/sklearn.py:633\u001b[0m, in \u001b[0;36mXGBModel.get_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;124;03m\"\"\"Get parameters.\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;66;03m# Based on: https://stackoverflow.com/questions/59248211\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;66;03m# The basic flow in `get_params` is:\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;66;03m# 0. Return parameters in subclass first, by using inspect.\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# 1. Return parameters in `XGBModel` (the base class).\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# 2. Return whatever in `**kwargs`.\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# 3. Merge them.\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m cp \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    635\u001b[0m cp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__bases__\u001b[39m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/sklearn/base.py:211\u001b[0m, in \u001b[0;36mBaseEstimator.get_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    209\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_param_names():\n\u001b[0;32m--> 211\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mtype\u001b[39m):\n\u001b[1;32m    213\u001b[0m         deep_items \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mget_params()\u001b[38;5;241m.\u001b[39mitems()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'XGBModel' object has no attribute 'callbacks'"
     ]
    }
   ],
   "source": [
    "# Loop that checks whether the model exists, retrains if not, \n",
    "# and stores the predictions if they have not been stored before for this run.\n",
    "# To do: set the data_preprocessing to the function in the model dictionary\n",
    "\n",
    "level = 'cm'\n",
    "includeFuture = False\n",
    "\n",
    "from views_runs import Storage, StepshiftedModels\n",
    "from views_partitioning.data_partitioner import DataPartitioner\n",
    "from viewser import Queryset, Column\n",
    "from views_runs import operations\n",
    "from views_runs.run_result import RunResult\n",
    "\n",
    "i = 0\n",
    "for model in ModelList:\n",
    "    if model['algorithm'] != 'Rscript':\n",
    "        force_retrain = False\n",
    "        modelstore = storage.Storage()\n",
    "        ct = datetime.now()\n",
    "        print(i, model['modelname'])\n",
    "        print('Calibration partition', ct)\n",
    "        model['Algorithm_text'] = str(model['algorithm'])\n",
    "        model['RunResult_calib'] = RunResult.retrain_or_retrieve(\n",
    "                retrain            = force_retrain,\n",
    "                store              = modelstore,\n",
    "                partitioner        = DataPartitioner({\"calib\":calib_partitioner_dict}),\n",
    "                stepshifted_models = StepshiftedModels(model['algorithm'], steps, model['depvar']),\n",
    "                dataset            = RetrieveFromList(Datasets,model['data_train']),\n",
    "                queryset_name      = model['queryset'],\n",
    "                partition_name     = \"calib\",\n",
    "                timespan_name      = \"train\",\n",
    "                storage_name       = model['modelname'] + '_calib',\n",
    "                author_name        = \"HH\",\n",
    "        )\n",
    "\n",
    "    #    model['predstore_calib'] = level +  '_' + model['modelname'] + '_calib'\n",
    "        ct = datetime.now()\n",
    "        print('Trying to retrieve predictions', ct)\n",
    "        try:\n",
    "            predictions_calib = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstore_calib'])\n",
    "        except KeyError:\n",
    "            print(model['predstore_calib'], ', run',  run_id, 'does not exist, predicting')\n",
    "            predictions_calib = model['RunResult_calib'].run.predict(\"calib\",\"predict\", model['RunResult_calib'].data)\n",
    "            predictions_calib.forecasts.set_run(run_id)\n",
    "            predictions_calib.forecasts.to_store(name=model['predstore_calib'])\n",
    "\n",
    "        ct = datetime.now()\n",
    "        print('Test partition', ct)\n",
    "        modelstore = storage.Storage()\n",
    "        model['RunResult_test'] = RunResult.retrain_or_retrieve(\n",
    "                retrain            = force_retrain,\n",
    "                store              = modelstore,\n",
    "                partitioner        = DataPartitioner({\"test\":test_partitioner_dict}),\n",
    "                stepshifted_models = StepshiftedModels(model['algorithm'], steps, model['depvar']),\n",
    "                dataset            = RetrieveFromList(Datasets,model['data_train']),\n",
    "                queryset_name      = model['queryset'],\n",
    "                partition_name     = \"test\",\n",
    "                timespan_name      = \"train\",\n",
    "                storage_name       = model['modelname'] + '_test',\n",
    "                author_name        = \"HH\",\n",
    "        )\n",
    "        ct = datetime.now()\n",
    "        print('Trying to retrieve predictions', ct)\n",
    "    #    model['predstore_test'] = level +  '_' + model['modelname'] + '_test'\n",
    "        try:\n",
    "            predictions_test = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstore_test'])\n",
    "        except KeyError:\n",
    "            print(model['predstore_test'], ', run', run_id, 'does not exist, predicting')\n",
    "            predictions_test = model['RunResult_test'].run.predict(\"test\",\"predict\",model['RunResult_test'].data)\n",
    "            predictions_test.forecasts.set_run(run_id)\n",
    "            predictions_test.forecasts.to_store(name=model['predstore_test'])\n",
    "        # Predictions for true future\n",
    "        if includeFuture:\n",
    "            ct = datetime.now()\n",
    "            print('Future', ct)\n",
    "            modelstore = storage.Storage()\n",
    "            model['RunResult_future'] = RunResult.retrain_or_retrieve(\n",
    "                    retrain            = force_retrain,\n",
    "                    store              = modelstore,\n",
    "                    partitioner        = DataPartitioner({\"test\":future_partitioner_dict}),\n",
    "                    stepshifted_models = StepshiftedModels(model['algorithm'], steps, model['depvar']),\n",
    "                    dataset            = RetrieveFromList(Datasets,model['data_train']),\n",
    "                    queryset_name      = model['queryset'],\n",
    "                    partition_name     = \"test\",\n",
    "                    timespan_name      = \"train\",\n",
    "                    storage_name       = model['modelname'] + '_future',\n",
    "                    author_name        = \"HH\",\n",
    "            )\n",
    "            ct = datetime.now()\n",
    "            print('Trying to retrieve predictions', ct)\n",
    "            model['predstore_future'] = level +  '_' + model['modelname'] + '_f' + str(FutureStart)\n",
    "            try:\n",
    "                predictions_future = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstore_future'])\n",
    "            except KeyError:\n",
    "                print(model['predstore_future'], ', run', run_id, 'does not exist, predicting')\n",
    "                predictions_future = model['RunResult_future'].run.future_point_predict(FutureStart,model['RunResult_future'].data)\n",
    "                predictions_future.forecasts.set_run(run_id)\n",
    "                predictions_future.forecasts.to_store(name=model['predstore_future'])  \n",
    "        print('**************************************************************')\n",
    "    i = i + 1\n",
    "\n",
    "print('All done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9bb08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the future predictions\n",
    "\n",
    "\n",
    "predictions_test.xs(246,level=1).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b52249",
   "metadata": {},
   "source": [
    "## Notes on training time for the various algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6b21cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are calculated in minutes for the hh20 feature set (with about 40 features), for all 36 steps, calibration (c) and test (t) partitions, also include generating predictions, and are approximate:\n",
    "\n",
    "#nj=12 (number of threads)\n",
    "#scikit random forest:        21:13 (c), 26:20 (t) RandomForestRegressor(n_estimators=200, n_jobs=nj)\n",
    "#XGB random forest:           06:02 (c), 07:51 (t) XGBRFRegressor(n_estimators=300,n_jobs=nj)\n",
    "#scikit gbm:                  13:59 (c), 15:55 (t) GradientBoostingRegressor(), \n",
    "#scikit hurdle random forest: 07:32 (c), 09:49 (t) For both clf and reg: (n_estimators=200, n_jobs=nj)\n",
    "#XGB hurdle xgb:              01:26 (c), 01:32 (t) For both clf and reg:                n_estimators=200,tree_method='hist',n_jobs=nj)\n",
    "#scikit histgbm:              01:17 (c), 01:20 (t) HistGradientBoostingRegressor(max_iter=200)\n",
    "#XGB xgb:                     01:00 (c), 01:04 (t) XGBRegressor(n_estimators=200,tree_method='hist',n_jobs=nj)\n",
    "#lightgbm gbm:                00:25 (c), --    (t) LGBMRegressor(n_estimators=100,num_threads=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71483a35",
   "metadata": {},
   "source": [
    "# Various helper functions and tools...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f053fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda list | grep views-forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7570c6",
   "metadata": {},
   "source": [
    "# Retrieving external forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30211fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve David's Markov models\n",
    "# To do: rewrite the model dictionary to the new, slimmer version.\n",
    "DRList = []\n",
    "\n",
    "\n",
    "model = {\n",
    "    'modelname':   'fat_hh20_Markov_glm',\n",
    "    'algorithm': [],\n",
    "    'depvar': \"ln_ged_sb_dep\",\n",
    "    'data_train':      'hh20',\n",
    "    'queryset': 'hh_20_features',\n",
    "}\n",
    "DRList.append(model)\n",
    "\n",
    "model = {\n",
    "    'modelname':   'fat_hh20_Markov_rf',\n",
    "    'algorithm': [],\n",
    "    'depvar': \"ln_ged_sb_dep\",\n",
    "    'data_train':      'hh20',\n",
    "    'queryset': 'hh_20_features',\n",
    "}\n",
    "\n",
    "DRList.append(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41de188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'/Users/{os.getlogin()}/Dropbox (ViEWS)/ViEWS/Projects/PredictingFatalities/Predictions/cm/preds/'\n",
    "\n",
    "DRList[0]['predictions_file_calib'] = path + 'vmm_glm_hh20_0125_alt_calib.csv'\n",
    "DRList[0]['predictions_file_test'] = path + 'vmm_glm_hh20_0125_alt_test.csv'\n",
    "DRList[0]['predictions_file_future'] = path + 'vmm_glm_hh20_506.csv'\n",
    "\n",
    "DRList[1]['predictions_file_calib'] = path + 'vmm_rf_hh20_0125_alt_calib.csv'\n",
    "DRList[1]['predictions_file_test'] = path + 'vmm_rf_hh20_0125_alt_test.csv'\n",
    "DRList[1]['predictions_file_future'] = path + 'vmm_rf_hh20_505.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7162915",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea1e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model in ModelList:\n",
    "    print(model['modelname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86478962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing Markov models in central storage\n",
    "# Retrieving dependent variable\n",
    "target_calib = pd.DataFrame.forecasts.read_store('cm_fat_conflicthistory_rf_calib', run=run_id)['ln_ged_sb_dep']\n",
    "target_test = pd.DataFrame.forecasts.read_store('cm_fat_conflicthistory_rf_test', run=run_id)['ln_ged_sb_dep']\n",
    "level = 'cm'\n",
    "for model in DRList:\n",
    "    df_calib = pd.read_csv(model['predictions_file_calib'],index_col=['month_id','country_id'])\n",
    "    df_test = pd.read_csv(model['predictions_file_test'],index_col=['month_id','country_id'])\n",
    "    df_future = pd.read_csv(model['predictions_file_future'],index_col=['month_id','country_id'])\n",
    "    df_calib['ln_ged_sb_dep'] = target_calib\n",
    "    df_test['ln_ged_sb_dep'] = target_test\n",
    "    df_future['ln_ged_sb_dep'] = np.nan # Empty dependent variable column for consistency/required by prediction storage function\n",
    "    stored_modelname = level + '_' + model['modelname'] + '_calib'\n",
    "    df_calib.forecasts.set_run(run_id)\n",
    "    df_calib.forecasts.to_store(name=stored_modelname, overwrite=True)\n",
    "    stored_modelname = level + '_' + model['modelname'] + '_test'\n",
    "    df_test.forecasts.set_run(run_id)\n",
    "    df_test.forecasts.to_store(name=stored_modelname, overwrite=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8be93",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ce44d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
