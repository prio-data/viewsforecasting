{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1098f7cb",
   "metadata": {},
   "source": [
    "\n",
    "# ViEWS 3 constituent models \n",
    "## ViEWS production system, cm level\n",
    "\n",
    "\n",
    "This notebook trains a set of regression models for use in the monthly updated ViEWS predicting fatalities ensemble\n",
    "\n",
    "The notebook does the following: \n",
    "1. Retrieves data through querysets and stores in DataSets, a list of dictionaries\n",
    "2. Specifies the metadata of a number of models, stores in ModelList, a list of dictionaries\n",
    "3. Trains the models in ModelList, stores the trained objects in model storage and prediction storage\n",
    "4. Saves part of ModelList as csv and the rest as pickles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f7cba",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8855fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef27dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.cbook as cbook\n",
    "# sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRFRegressor, XGBRFClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "\n",
    "# Views 3\n",
    "from viewser.operations import fetch\n",
    "import views_runs\n",
    "from views_partitioning import data_partitioner, legacy\n",
    "from stepshift import views\n",
    "from views_runs import storage\n",
    "from views_runs.storage import store, retrieve, fetch_metadata\n",
    "\n",
    "from views_forecasts.extensions import *\n",
    "\n",
    "# Other packages\n",
    "import pickle as pkl\n",
    "\n",
    "# Packages from viewsforecasting repository\n",
    "\n",
    "#from Ensembling import CalibratePredictions, RetrieveStoredPredictions, mean_sd_calibrated, gam_calibrated\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../Tools')\n",
    "sys.path.append('../Intermediates')\n",
    "from FetchData import FetchData, RetrieveFromList, document_queryset, ReturnQsList, document_ensemble\n",
    "from ViewsEstimators import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda6692757e9c224",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3300ea25",
   "metadata": {},
   "source": [
    "## Common parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae8aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common parameters:\n",
    "dev_id = 'Fatalities002'\n",
    "run_id = dev_id\n",
    "\n",
    "# Generating a new run if necessary\n",
    "\n",
    "#try:\n",
    "#    ViewsMetadata().new_run(name=run_id,description='Developing the fatalities model for FCDO',min_month=1,max_month=999)\n",
    "#except KeyError:\n",
    "#    if 'devel' not in run_id:\n",
    "#        warnings.warn('You are overwriting a production system')\n",
    "\n",
    "RerunQuerysets = True\n",
    "\n",
    "EndOfHistory = 540 # Please NOTE: Changed to last month of GED data, 2024-12 (540). Used to be last month of GED +1, unsure why. \n",
    "steps = [*range(1, 36+1, 1)] # Which steps to train and predict for\n",
    "fi_steps = [1,3,6,12,36] # Which steps to present feature importances for\n",
    "#steps = [1,3,6,12,36]\n",
    "#fi_steps = [1,3,6,12,36]\n",
    "\n",
    "# Specifying partitions - new for 2025\n",
    "calib_partitioner_dict = {\"train\":(121,432),\"predict\":(433,480)}\n",
    "test_partitioner_dict = {\"train\":(121,480),\"predict\":(481,528)}\n",
    "future_partitioner_dict = {\"train\":(121,528),\"predict\":(529,540)}\n",
    "\n",
    "calib_partitioner =  views_runs.DataPartitioner({\"calib\":calib_partitioner_dict})\n",
    "test_partitioner =  views_runs.DataPartitioner({\"test\":test_partitioner_dict})\n",
    "future_partitioner =  views_runs.DataPartitioner({\"future\":future_partitioner_dict})\n",
    "\n",
    "Mydropbox = f'/Users/{os.getlogin()}/Dropbox (ViEWS)/ViEWS'\n",
    "print('Setting Mydropbox to',Mydropbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf0208",
   "metadata": {},
   "source": [
    "# Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a0acf1-ede9-463b-bfe5-2e5a274c7bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "! which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a457b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Markdown documentation of all querysets used\n",
    "level = 'cm'\n",
    "qslist = ReturnQsList(level)\n",
    "document_queryset(qslist,dev_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e75122",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from FetchData import fetch_cm_data_from_model_def\n",
    "\n",
    "Datasets=fetch_cm_data_from_model_def(qslist, EndOfHistory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a925bdb3",
   "metadata": {},
   "source": [
    "# Generating predictions\n",
    "Using the ViEWS3 partitioning/stepshifting syntax. Training models for A: calibration partition and B: test partition, to test out some calibration routines. Most models trained with ln_ged_sb_best as outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990574dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in Datasets:\n",
    "    if 'topics' in ds['Name']:\n",
    "        print(ds['df'].columns)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf49bd2",
   "metadata": {},
   "source": [
    "## Checking missingness and infinity values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe61e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=51\n",
    "for i in range(len(Datasets)):\n",
    "    df = Datasets[i]['df']\n",
    "    print(Datasets[i]['Name'])\n",
    "    for col in df.iloc[: , :N].columns:\n",
    "        print(col,len(df[col]), 'missing:', df[col].isnull().sum(), 'infinity:', np.isinf(df).values.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c761eb9c",
   "metadata": {},
   "source": [
    "# Specify models in ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425514d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ModelDefinitions import DefineEnsembleModels\n",
    "\n",
    "ModelList = DefineEnsembleModels('cm')\n",
    "    \n",
    "for imodel,model in enumerate(ModelList):\n",
    "    print(imodel, model['modelname'], model['data_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b6322",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b4f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_ensemble(ModelList,'sb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d636ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in Datasets:\n",
    "    df = ds['df']\n",
    "    print(ds['Name'],df.isna().sum())\n",
    "    ds['df']=df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c58f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop that checks whether the model exists, retrains if not, \n",
    "# and stores the predictions if they have not been stored before for this run.\n",
    "# To do: set the data_preprocessing to the function in the model dictionary\n",
    "\n",
    "level = 'cm'\n",
    "includeFuture = False\n",
    "force_rewrite = True\n",
    "force_retrain = True\n",
    "\n",
    "from views_runs import Storage, StepshiftedModels\n",
    "from views_partitioning.data_partitioner import DataPartitioner\n",
    "from viewser import Queryset, Column\n",
    "from views_runs import operations\n",
    "from views_runs.run_result import RunResult\n",
    "from new_markov import markov\n",
    "\n",
    "i = 0\n",
    "for model in ModelList[:]:\n",
    "    if 'Markov' not in model['modelname']:\n",
    "        \n",
    "        modelstore = storage.Storage()\n",
    "        ct = datetime.now()\n",
    "        print(i, model['modelname'])\n",
    "        print('Calibration partition', ct)\n",
    "        model['Algorithm_text'] = str(model['algorithm'])\n",
    "        model['RunResult_calib'] = RunResult.retrain_or_retrieve(\n",
    "                retrain            = force_retrain,\n",
    "                store              = modelstore,\n",
    "                partitioner        = DataPartitioner({\"calib\":calib_partitioner_dict}),\n",
    "                stepshifted_models = StepshiftedModels(model['algorithm'], steps, model['depvar']),\n",
    "                dataset            = RetrieveFromList(Datasets,model['data_train']),\n",
    "                queryset_name      = model['queryset'],\n",
    "                partition_name     = \"calib\",\n",
    "                timespan_name      = \"train\",\n",
    "                storage_name       = model['modelname'] + '_calib',\n",
    "                author_name        = \"JED\",\n",
    "        )\n",
    "\n",
    "    #    model['predstore_calib'] = level +  '_' + model['modelname'] + '_calib'\n",
    "        ct = datetime.now()\n",
    "        if force_rewrite:\n",
    "            print(model['predstore_calib'], ', run',  run_id, 'force_rewrite=True, predicting')\n",
    "            predictions_calib = model['RunResult_calib'].run.predict(\"calib\",\"predict\", model['RunResult_calib'].data)\n",
    "            predictions_calib.forecasts.set_run(run_id)\n",
    "            predictions_calib.forecasts.to_store(name=model['predstore_calib'],overwrite=True)\n",
    "        else:\n",
    "            print('Trying to retrieve predictions', ct)\n",
    "            try:\n",
    "                predictions_calib = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstore_calib'])\n",
    "            except KeyError:\n",
    "                print(model['predstore_calib'], ', run',  run_id, 'does not exist, predicting')\n",
    "                predictions_calib = model['RunResult_calib'].run.predict(\"calib\",\"predict\", model['RunResult_calib'].data)\n",
    "                predictions_calib.forecasts.set_run(run_id)\n",
    "                predictions_calib.forecasts.to_store(name=model['predstore_calib'])\n",
    "\n",
    "        ct = datetime.now()\n",
    "        print('Test partition', ct)\n",
    "        modelstore = storage.Storage()\n",
    "        model['RunResult_test'] = RunResult.retrain_or_retrieve(\n",
    "                retrain            = force_retrain,\n",
    "                store              = modelstore,\n",
    "                partitioner        = DataPartitioner({\"test\":test_partitioner_dict}),\n",
    "                stepshifted_models = StepshiftedModels(model['algorithm'], steps, model['depvar']),\n",
    "                dataset            = RetrieveFromList(Datasets,model['data_train']),\n",
    "                queryset_name      = model['queryset'],\n",
    "                partition_name     = \"test\",\n",
    "                timespan_name      = \"train\",\n",
    "                storage_name       = model['modelname'] + '_test',\n",
    "                author_name        = \"JED\",\n",
    "        )\n",
    "        ct = datetime.now()\n",
    "        \n",
    "        if force_rewrite:\n",
    "            print(model['predstore_test'], ', run',  run_id, 'force_rewrite=True, predicting')\n",
    "            predictions_test = model['RunResult_test'].run.predict(\"test\",\"predict\", model['RunResult_test'].data)\n",
    "            predictions_test.forecasts.set_run(run_id)\n",
    "            predictions_test.forecasts.to_store(name=model['predstore_test'],overwrite=True)\n",
    "        else:\n",
    "            print('Trying to retrieve predictions', ct)\n",
    "    #    model['predstore_test'] = level +  '_' + model['modelname'] + '_test'\n",
    "            try:\n",
    "                predictions_test = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstore_test'])\n",
    "            except KeyError:\n",
    "                print(model['predstore_test'], ', run', run_id, 'does not exist, predicting')\n",
    "                predictions_test = model['RunResult_test'].run.predict(\"test\",\"predict\",model['RunResult_test'].data)\n",
    "                predictions_test.forecasts.set_run(run_id)\n",
    "                predictions_test.forecasts.to_store(name=model['predstore_test'])\n",
    "        # Predictions for true future\n",
    "        if includeFuture:\n",
    "            ct = datetime.now()\n",
    "            print('Future', ct)\n",
    "            modelstore = storage.Storage()\n",
    "            model['RunResult_future'] = RunResult.retrain_or_retrieve(\n",
    "                    retrain            = force_retrain,\n",
    "                    store              = modelstore,\n",
    "                    partitioner        = DataPartitioner({\"test\":future_partitioner_dict}),\n",
    "                    stepshifted_models = StepshiftedModels(model['algorithm'], steps, model['depvar']),\n",
    "                    dataset            = RetrieveFromList(Datasets,model['data_train']),\n",
    "                    queryset_name      = model['queryset'],\n",
    "                    partition_name     = \"test\",\n",
    "                    timespan_name      = \"train\",\n",
    "                    storage_name       = model['modelname'] + '_future',\n",
    "                    author_name        = \"JED\",\n",
    "            )\n",
    "            ct = datetime.now()\n",
    "            \n",
    "            if force_rewrite:\n",
    "                print(model['predstore_future'], ', run',  run_id, 'force_rewrite=True, predicting')\n",
    "                predictions_future = model['RunResult_future'].run.predict(EndOfHistory, model['RunResult_future'].data)\n",
    "                predictions_future.forecasts.set_run(run_id)\n",
    "                predictions_future.forecasts.to_store(name=model['predstore_future'],overwrite=True)\n",
    "            else:\n",
    "                print('Trying to retrieve predictions', ct)\n",
    "                model['predstore_future'] = level +  '_' + model['modelname'] + '_f' + str(EndOfHistory)\n",
    "                predictions_future.forecasts.to_store(name=model['predstore_future'])  \n",
    "                \n",
    "    else:\n",
    "        modelstore = storage.Storage()\n",
    "        ct = datetime.now()\n",
    "        print(i, model['modelname'])\n",
    "        print('Calibration partition', ct)\n",
    "        model['Algorithm_text'] = str(model['algorithm'])\n",
    "        print('Trying to retrieve predictions', ct)\n",
    "        if force_retrain:\n",
    "            print(model['predstore_calib'], ', run',  run_id, 'force_retrain = True, predicting')\n",
    "            predictions_calib = markov.compute_markov(calib_partitioner_dict, EndOfHistory, model['depvar'], 'calib', model['algorithm'])\n",
    "            predictions_calib.forecasts.set_run(run_id)\n",
    "            predictions_calib.forecasts.to_store(name=model['predstore_calib'],overwrite=True)\n",
    "        else:\n",
    "            try:\n",
    "                predictions_calib = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstore_calib'])\n",
    "            except KeyError:\n",
    "                print(model['predstore_calib'], ', run',  run_id, 'does not exist, predicting')\n",
    "                predictions_calib = markov.compute_markov(calib_partitioner_dict, EndOfHistory, model['depvar'], 'calib', model['algorithm'])\n",
    "                predictions_calib.forecasts.set_run(run_id)\n",
    "                predictions_calib.forecasts.to_store(name=model['predstore_calib'],overwrite=True)\n",
    "                \n",
    "        ct = datetime.now()\n",
    "        print('Test partition', ct)\n",
    "        modelstore = storage.Storage()\n",
    "        if force_retrain:\n",
    "            print(model['predstore_test'], ', run', run_id, 'force_retrain=True, predicting')\n",
    "            predictions_test = markov.compute_markov(test_partitioner_dict, EndOfHistory, model['depvar'], 'test', model['algorithm'])\n",
    "            predictions_test.forecasts.set_run(run_id)\n",
    "            predictions_test.forecasts.to_store(name=model['predstore_test'],overwrite=True)\n",
    "        else:\n",
    "            try:\n",
    "                predictions_test = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstore_test'])\n",
    "            except KeyError:\n",
    "                print(model['predstore_test'], ', run', run_id, 'does not exist, predicting')\n",
    "                predictions_test = markov.compute_markov(test_partitioner_dict, EndOfHistory, model['depvar'], 'test', model['algorithm'])\n",
    "                predictions_test.forecasts.set_run(run_id)\n",
    "                predictions_test.forecasts.to_store(name=model['predstore_test'],overwrite=True)\n",
    "                \n",
    "        if includeFuture:\n",
    "            ct = datetime.now()\n",
    "            print('Future', ct)\n",
    "            modelstore = storage.Storage()\n",
    "            print('Trying to retrieve predictions', ct)\n",
    "            model['predstore_future'] = level +  '_' + model['modelname'] + '_f' + str(EndOfHistory)\n",
    "            if force_retrain:\n",
    "                print(model['predstore_future'], ', run', run_id, 'force_retrain=True, predicting')\n",
    "                predictions_future = markov.compute_markov(test_partitioner_dict, EndOfHistory, model['depvar'], 'future', model['algorithm'])\n",
    "                predictions_future.forecasts.set_run(run_id)\n",
    "                predictions_future.forecasts.to_store(name=model['predstore_future'],overwrite=True)\n",
    "            else:\n",
    "                try:\n",
    "                    predictions_future = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstore_future'])\n",
    "                except KeyError:\n",
    "                    print(model['predstore_future'], ', run', run_id, 'does not exist, predicting')\n",
    "                    predictions_future = markov.compute_markov(test_partitioner_dict, EndOfHistory, model['depvar'], 'future', model['algorithm'])\n",
    "                    predictions_future.forecasts.set_run(run_id)\n",
    "                    predictions_future.forecasts.to_store(name=model['predstore_future'],overwrite=True)  \n",
    "                            \n",
    "        print('**************************************************************')\n",
    "    i = i + 1\n",
    "\n",
    "print('All done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b52249",
   "metadata": {},
   "source": [
    "## Notes on training time for the various algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6b21cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are calculated in minutes for the hh20 feature set (with about 40 features), for all 36 steps, calibration (c) and test (t) partitions, also include generating predictions, and are approximate:\n",
    "\n",
    "#nj=12 (number of threads)\n",
    "#scikit random forest:        21:13 (c), 26:20 (t) RandomForestRegressor(n_estimators=200, n_jobs=nj)\n",
    "#XGB random forest:           06:02 (c), 07:51 (t) XGBRFRegressor(n_estimators=300,n_jobs=nj)\n",
    "#scikit gbm:                  13:59 (c), 15:55 (t) GradientBoostingRegressor(), \n",
    "#scikit hurdle random forest: 07:32 (c), 09:49 (t) For both clf and reg: (n_estimators=200, n_jobs=nj)\n",
    "#XGB hurdle xgb:              01:26 (c), 01:32 (t) For both clf and reg:                n_estimators=200,tree_method='hist',n_jobs=nj)\n",
    "#scikit histgbm:              01:17 (c), 01:20 (t) HistGradientBoostingRegressor(max_iter=200)\n",
    "#XGB xgb:                     01:00 (c), 01:04 (t) XGBRegressor(n_estimators=200,tree_method='hist',n_jobs=nj)\n",
    "#lightgbm gbm:                00:25 (c), --    (t) LGBMRegressor(n_estimators=100,num_threads=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71483a35",
   "metadata": {},
   "source": [
    "# Various helper functions and tools...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7570c6",
   "metadata": {},
   "source": [
    "# Retrieving external forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30211fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve David's Markov models\n",
    "## To do: rewrite the model dictionary to the new, slimmer version.\n",
    "#DRList = []\n",
    "\n",
    "\n",
    "#model = {\n",
    "#    'modelname':   'fatalities002_Markov_glm',\n",
    "#    'algorithm': [],\n",
    "#    'depvar': \"ln_ged_sb_dep\",\n",
    "#    'data_train':      'joint_narrow',\n",
    "#    'queryset': 'fatalities002_joint_narrow',\n",
    "#}\n",
    "#DRList.append(model)\n",
    "\n",
    "#model = {\n",
    "#    'modelname':   'fatalities002_Markov_rf',\n",
    "#    'algorithm': [],\n",
    "#    'depvar': \"ln_ged_sb_dep\",\n",
    "#    'data_train':      'joint_narrow',\n",
    "#    'queryset': 'fatalities002_joint_narrow',\n",
    "#}\n",
    "\n",
    "#DRList.append(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41de188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = f'/Users/{os.getlogin()}/Dropbox (ViEWS)/ViEWS/Projects/PredictingFatalities/Predictions/cm/preds/'\n",
    "\n",
    "#DRList[0]['predictions_file_calib'] = path + 'markov_jointnarrow_ss_glm_calib.parquet'\n",
    "#DRList[0]['predictions_file_test'] = path + 'markov_jointnarrow_ss_glm_test.parquet'\n",
    "#DRList[0]['predictions_file_future'] = path + 'vmm_glm_hh20_517.csv'\n",
    "\n",
    "#DRList[1]['predictions_file_calib'] = path + 'markov_jointnarrow_ss_rf_calib.parquet'\n",
    "#DRList[1]['predictions_file_test'] = path + 'markov_jointnarrow_ss_rf_test.parquet'\n",
    "#DRList[1]['predictions_file_future'] = path + 'vmm_rf_hh20_517.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86478962",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Storing Markov models in central storage\n",
    "## Retrieving dependent variable\n",
    "\n",
    "#print('Adding depvar - CHECK FILES BEING USED FROM STORAGE ARE SUITABLE!')\n",
    "#target_calib = pd.DataFrame.forecasts.read_store('cm_fatalities002_conflicthistory_rf_calib', run=run_id)['ln_ged_sb_dep']\n",
    "#target_test = pd.DataFrame.forecasts.read_store('cm_fatalities002_conflicthistory_rf_test', run=run_id)['ln_ged_sb_dep']\n",
    "#level = 'cm'\n",
    "#for model in DRList:\n",
    "#    df_calib = pd.read_parquet(model['predictions_file_calib'])\n",
    "##    df_calib.rename(columns={'target_month_id':'month_id'}, inplace=True)\n",
    "##    df_calib.set_index(['month_id', 'country_id'], inplace=True)\n",
    "\n",
    "#    df_test = pd.read_parquet(model['predictions_file_test'])\n",
    "##    df_test.rename(columns={'target_month_id':'month_id'}, inplace=True)\n",
    "##    df_calib.set_index(['month_id', 'country_id'], inplace=True)\n",
    "\n",
    "##    df_future = pd.read_csv(model['predictions_file_future'],index_col=['month_id','country_id'])\n",
    "#    df_calib['ln_ged_sb_dep'] = target_calib\n",
    "#    df_test['ln_ged_sb_dep'] = target_test\n",
    "##    df_future['ln_ged_sb_dep'] = np.nan # Empty dependent variable column for consistency/required by prediction storage function\n",
    "#    stored_modelname = level + '_' + model['modelname'] + '_calib'\n",
    "#    df_calib.forecasts.set_run(run_id)\n",
    "#    df_calib.forecasts.to_store(name=stored_modelname, overwrite=True)\n",
    "#    stored_modelname = level + '_' + model['modelname'] + '_test'\n",
    "#    df_test.forecasts.set_run(run_id)\n",
    "#    df_test.forecasts.to_store(name=stored_modelname, overwrite=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a907a4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viewser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
